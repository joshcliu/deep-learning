{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Analysis - Hidden State Probing\n",
    "\n",
    "This notebook runs the layer analysis experiment on Google Colab with GPU acceleration.\n",
    "\n",
    "**Before running**: Make sure to set Runtime > Change runtime type > GPU (T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU is available\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch transformers accelerate bitsandbytes datasets scikit-learn tqdm loguru matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your repository\n",
    "!git clone https://github.com/joshcliu/deep-learning.git\n",
    "%cd deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src to path\n",
    "import sys\n",
    "sys.path.insert(0, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Login to HuggingFace for gated models (Llama)\n",
    "# Uncomment and add your token if you have Llama access\n",
    "# from huggingface_hub import login\n",
    "# login(token=\"your_token_here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"  # or \"meta-llama/Llama-3.1-8B\" if you have access\n",
    "NUM_SAMPLES = 100\n",
    "QUICK_MODE = True  # True = quartile layers only, False = all layers\n",
    "QUANTIZATION = \"8bit\"  # \"8bit\", \"4bit\", or \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.models import ModelLoader, HiddenStateExtractor\n",
    "from src.data import MMLUDataset\n",
    "from src.probes import LinearProbe\n",
    "from src.evaluation import compute_ece, compute_auroc\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "loader = ModelLoader(model_name=MODEL_NAME)\n",
    "quantization = None if QUANTIZATION == \"none\" else QUANTIZATION\n",
    "model, tokenizer = loader.load(quantization=quantization, device_map=\"auto\")\n",
    "\n",
    "model_info = loader.get_model_info()\n",
    "num_layers = model_info[\"num_layers\"]\n",
    "hidden_dim = model_info[\"hidden_dim\"]\n",
    "print(f\"Model loaded: {num_layers} layers, hidden_dim={hidden_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine layers to analyze\n",
    "if QUICK_MODE:\n",
    "    # Quartile layers: 0%, 25%, 50%, 75%, ~100%\n",
    "    layers = [\n",
    "        0,\n",
    "        num_layers // 4,\n",
    "        num_layers // 2,\n",
    "        3 * num_layers // 4,\n",
    "        num_layers - 1,\n",
    "    ]\n",
    "    layers = sorted(set(layers))  # Remove duplicates\n",
    "else:\n",
    "    layers = list(range(num_layers))\n",
    "\n",
    "print(f\"Analyzing {len(layers)} layers: {layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "print(\"Loading MMLU dataset...\")\n",
    "dataset = MMLUDataset(split=\"test\")\n",
    "print(f\"Dataset size: {len(dataset)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate examples (correct/incorrect pairs)\n",
    "def generate_examples(dataset, num_samples):\n",
    "    \"\"\"Generate text examples with binary labels (correct=1, incorrect=0).\"\"\"\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    indices = np.random.choice(len(dataset), min(num_samples, len(dataset)), replace=False)\n",
    "    \n",
    "    for idx in tqdm(indices, desc=\"Generating examples\"):\n",
    "        example = dataset[idx]\n",
    "        question = example[\"question\"]\n",
    "        choices = example[\"choices\"]\n",
    "        correct_idx = example[\"answer\"]\n",
    "        \n",
    "        # Correct answer\n",
    "        correct_text = f\"Question: {question}\\nAnswer: {choices[correct_idx]}\"\n",
    "        texts.append(correct_text)\n",
    "        labels.append(1)\n",
    "        \n",
    "        # Random incorrect answer\n",
    "        incorrect_indices = [i for i in range(len(choices)) if i != correct_idx]\n",
    "        incorrect_idx = np.random.choice(incorrect_indices)\n",
    "        incorrect_text = f\"Question: {question}\\nAnswer: {choices[incorrect_idx]}\"\n",
    "        texts.append(incorrect_text)\n",
    "        labels.append(0)\n",
    "    \n",
    "    return texts, np.array(labels)\n",
    "\n",
    "texts, labels = generate_examples(dataset, NUM_SAMPLES)\n",
    "print(f\"Generated {len(texts)} examples (label distribution: {np.bincount(labels)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hidden states\n",
    "print(f\"\\nExtracting hidden states from {len(layers)} layers...\")\n",
    "extractor = HiddenStateExtractor(model, tokenizer)\n",
    "\n",
    "all_hiddens = {}\n",
    "for layer in tqdm(layers, desc=\"Extracting layers\"):\n",
    "    hiddens = extractor.extract(\n",
    "        texts=texts,\n",
    "        layers=[layer],\n",
    "        max_length=512,\n",
    "        token_position=\"last\",\n",
    "        batch_size=16,\n",
    "    )\n",
    "    all_hiddens[layer] = hiddens[:, 0, :]  # Remove layer dimension\n",
    "    print(f\"Layer {layer}: shape {all_hiddens[layer].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "print(\"\\nSplitting data (70% train, 30% val)...\")\n",
    "indices = np.arange(len(labels))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.3, random_state=42, stratify=labels)\n",
    "print(f\"Train: {len(train_idx)}, Val: {len(val_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train probes for each layer\n",
    "print(f\"\\nTraining probes for {len(layers)} layers...\")\n",
    "results = {}\n",
    "\n",
    "for layer in tqdm(layers, desc=\"Training probes\"):\n",
    "    hiddens = all_hiddens[layer]\n",
    "    \n",
    "    X_train, X_val = hiddens[train_idx], hiddens[val_idx]\n",
    "    y_train, y_val = labels[train_idx], labels[val_idx]\n",
    "    \n",
    "    # Train probe\n",
    "    probe = LinearProbe(input_dim=hidden_dim, dropout=0.1)\n",
    "    history = probe.fit(\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        epochs=50,\n",
    "        lr=1e-3,\n",
    "        batch_size=32,\n",
    "        early_stopping_patience=5,\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_probs = probe.predict(X_val)\n",
    "    val_preds = (val_probs > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = (val_preds == y_val).mean()\n",
    "    ece, _ = compute_ece(val_probs, val_preds, y_val)\n",
    "    auroc = compute_auroc(val_probs, y_val)\n",
    "    \n",
    "    results[layer] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"ece\": ece,\n",
    "        \"auroc\": auroc,\n",
    "        \"best_epoch\": len(history[\"train_loss\"]),\n",
    "    }\n",
    "    \n",
    "    print(f\"Layer {layer:2d}: Acc={accuracy:.3f}, ECE={ece:.3f}, AUROC={auroc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "layer_list = sorted(results.keys())\n",
    "accuracies = [results[l][\"accuracy\"] for l in layer_list]\n",
    "eces = [results[l][\"ece\"] for l in layer_list]\n",
    "aurocs = [results[l][\"auroc\"] for l in layer_list]\n",
    "\n",
    "axes[0].plot(layer_list, accuracies, 'o-', color='blue')\n",
    "axes[0].set_xlabel(\"Layer\")\n",
    "axes[0].set_ylabel(\"Accuracy\")\n",
    "axes[0].set_title(\"Probe Accuracy by Layer\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(layer_list, eces, 'o-', color='red')\n",
    "axes[1].set_xlabel(\"Layer\")\n",
    "axes[1].set_ylabel(\"ECE (lower is better)\")\n",
    "axes[1].set_title(\"Expected Calibration Error by Layer\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(layer_list, aurocs, 'o-', color='green')\n",
    "axes[2].set_xlabel(\"Layer\")\n",
    "axes[2].set_ylabel(\"AUROC\")\n",
    "axes[2].set_title(\"AUROC by Layer\")\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"layer_analysis_results.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nResults saved to layer_analysis_results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LAYER ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_acc_layer = max(results.keys(), key=lambda l: results[l][\"accuracy\"])\n",
    "best_ece_layer = min(results.keys(), key=lambda l: results[l][\"ece\"])\n",
    "best_auroc_layer = max(results.keys(), key=lambda l: results[l][\"auroc\"])\n",
    "\n",
    "print(f\"\\nBest Accuracy:  Layer {best_acc_layer} ({results[best_acc_layer]['accuracy']:.3f})\")\n",
    "print(f\"Best ECE:       Layer {best_ece_layer} ({results[best_ece_layer]['ece']:.3f})\")\n",
    "print(f\"Best AUROC:     Layer {best_auroc_layer} ({results[best_auroc_layer]['auroc']:.3f})\")\n",
    "\n",
    "# Check if middle layers are better (research hypothesis)\n",
    "middle_layer = num_layers // 2\n",
    "final_layer = num_layers - 1\n",
    "\n",
    "if middle_layer in results and final_layer in results:\n",
    "    print(f\"\\nMiddle vs Final Layer Comparison:\")\n",
    "    print(f\"  Layer {middle_layer} (middle): Acc={results[middle_layer]['accuracy']:.3f}, ECE={results[middle_layer]['ece']:.3f}\")\n",
    "    print(f\"  Layer {final_layer} (final):  Acc={results[final_layer]['accuracy']:.3f}, ECE={results[final_layer]['ece']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results\n",
    "from google.colab import files\n",
    "files.download(\"layer_analysis_results.png\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
