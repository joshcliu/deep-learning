{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg2TDPdRMejX"
   },
   "source": [
    "# Probe Architecture Comparison\n",
    "\n",
    "This notebook compares 9 novel probe architectures for predicting model confidence.\n",
    "\n",
    "**Architectures tested:**\n",
    "1. Default MLP (baseline)\n",
    "2. AttentionProbe - Self-attention over hidden state chunks\n",
    "3. ResidualProbe - Deep MLP with skip connections\n",
    "4. BottleneckProbe - Compression to low-rank representation\n",
    "5. MultiHeadProbe - Multiple experts with learned aggregation\n",
    "6. GatedProbe - GLU-style gating\n",
    "7. SparseProbe - Top-k dimension selection\n",
    "8. HeteroscedasticProbe - Per-example uncertainty\n",
    "9. BilinearProbe - Explicit feature interactions\n",
    "10. HierarchicalProbe - Multi-scale hierarchical processing (fine \u2192 mid \u2192 semantic \u2192 global)\n",
    "\n",
    "**Setup:** Run on Google Colab with GPU (Runtime > Change runtime type > T4 GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUJWqAT_Mi0d",
    "outputId": "0d1f4c8d-930e-4dbd-8c02-37ab24e0011a"
   },
   "outputs": [],
   "source": [
    "%cd /content #unicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-Fgvs1jMrAN"
   },
   "outputs": [],
   "source": [
    "!rm -rf /content/deep-learning\n",
    "!rm -rf deep-learning\n",
    "!rm -rf deep-learning* #unicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZ0hcxl9Mejb",
    "outputId": "e80d12c5-80b3-45bb-911e-395a2b019b71"
   },
   "outputs": [],
   "source": [
    "# Install dependencies (Colab)\n",
    "!pip install -q transformers accelerate bitsandbytes datasets tqdm matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DnSMMJx5Mejc",
    "outputId": "6bb2eb5b-54cd-4b0f-f78e-38452944bf44"
   },
   "outputs": [],
   "source": [
    "# Clone repo and setup path\n",
    "!git clone -b maureen --single-branch https://github.com/joshcliu/deep-learning.git #unicorn\n",
    "%cd deep-learning\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRdooVdlMejc",
    "outputId": "59dcd270-6bb4-4243-ae09-3d9eef71175f"
   },
   "outputs": [],
   "source": [
    "# Patch for bfloat16 compatibility (8-bit quantized models)\n",
    "import numpy as np\n",
    "import torch\n",
    "from src.models import extractor as extractor_module\n",
    "\n",
    "_original_extract_batch = extractor_module.HiddenStateExtractor._extract_batch\n",
    "\n",
    "def _patched_extract_batch(self, texts, layers, max_length, token_position):\n",
    "    \"\"\"Patched to preserve original behavior while safely handling bfloat16.\"\"\"\n",
    "\n",
    "    # 1. Tokenization (unchanged)\n",
    "    encodings = self.tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    encodings = {k: v.to(self.device) for k, v in encodings.items()}\n",
    "\n",
    "    # 2. Model forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = self.model(\n",
    "            **encodings,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "    hidden_states = outputs.hidden_states\n",
    "    batch_hiddens = []\n",
    "\n",
    "    # 3. Iterate entire batch for each requested layer\n",
    "    for layer_idx in layers:\n",
    "\n",
    "        # IMPORTANT: your model uses layer_idx + 1\n",
    "        layer_hiddens = hidden_states[layer_idx + 1]  # (batch, seq_len, hidden)\n",
    "\n",
    "        # === TOKEN SELECTION (MUST FOLLOW ORIGINAL LOGIC) ===\n",
    "        if token_position == \"last\":\n",
    "            attention_mask = encodings[\"attention_mask\"]\n",
    "            seq_lengths = attention_mask.sum(dim=1) - 1\n",
    "            token_hiddens = layer_hiddens[\n",
    "                torch.arange(layer_hiddens.size(0), device=self.device),\n",
    "                seq_lengths\n",
    "            ]\n",
    "\n",
    "        elif token_position == \"cls\":\n",
    "            token_hiddens = layer_hiddens[:, 0, :]\n",
    "\n",
    "        elif token_position == \"mean\":\n",
    "            attention_mask = encodings[\"attention_mask\"].unsqueeze(-1)\n",
    "            masked_hiddens = layer_hiddens * attention_mask\n",
    "            token_hiddens = masked_hiddens.sum(dim=1) / attention_mask.sum(dim=1)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown token_position: {token_position}\")\n",
    "\n",
    "        # === BF16 / INT8 SAFE CONVERSION ===\n",
    "        token_hiddens = token_hiddens.detach().cpu().to(torch.float32).numpy()\n",
    "\n",
    "        batch_hiddens.append(token_hiddens)\n",
    "\n",
    "    # 4. Stack layers: (batch, num_layers, hidden_dim)\n",
    "    return np.stack(batch_hiddens, axis=1)\n",
    "\n",
    "\n",
    "# Apply patch\n",
    "extractor_module.HiddenStateExtractor._extract_batch = _patched_extract_batch\n",
    "print(\"Patched HiddenStateExtractor for bfloat16 & 8bit compatibility.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7IE2efVMejo"
   },
   "source": [
    "## 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467,
     "referenced_widgets": [
      "aea5ddf66e944171b8e9f181d10b998c",
      "e353507eb2c64dc49eea984770c82556",
      "96da418f804443e8ad60360a01d1cf5a",
      "b181bb1b1f0d4263b4de717075495050",
      "1a8d38475b6e4dd9b0b0c39ce5e28fe9",
      "995fbdef2022441889fb3ed4b14830ce",
      "3ecd57af337e419abff8fe020756bd8e",
      "17c442745ed54e8280908cdb868e7a7d",
      "87a493fdebec499badc1159abfd9290b",
      "71d5105254b84707a35c1ef82fe0339d",
      "e269dd8ca365472f9c7cf928b226619c",
      "65c5a36b84f048b7a16d970e08265ada",
      "1cf50cb7c4124a7ab1036093eaa8d913",
      "73419c4e80bc4a9887cadb6b40c2d453",
      "cd59f22d0b9d493792b25903e3555f64",
      "f4cc1e82d5894b0299bbb6a6092eeddb",
      "0d54dbd0ea914a749c7e74881e8ebb7b",
      "06f3bfd33e044c76a27d9105acc4ab08",
      "31461abf39e945ee88aef027edb98946",
      "9ea74e6a0e90477ab0e9e72ae081192c",
      "bdf837f226484d7dbe8785c0d2343b90",
      "77829eb3daba44368aa527a274d55a9a",
      "ba0131c50334497f804cc4a3b02e9164",
      "437703e34d9f41d48a7b3a8723c81773",
      "7e618d9b163c4e47a7948011fb33f5e5",
      "b117b0eb3d514101bacea955074167f1",
      "d62ae3f7912a4b6bb2350e378e309a2d",
      "85fd43c8580443798a1900bc6ec537f6",
      "c9b2668c717241d3b471c9262ac9c65c",
      "c95ecb6ec5154254a3a49ea73ff9821d",
      "010005e68627452289180599f051b81b",
      "5f49426c19014ec9808f35362fdf6dd4",
      "120c8ffbb2f64fcaa3d3c0f890036754",
      "aafcb07947ed413db08a3001ed4cb1d8",
      "1b7d10b2a3344653b825e62820181f48",
      "4faf4ad615c148cc8ee44f257c754216",
      "85bce8b7cba84fccb0e6cbdf6e0b5f2b",
      "c2830c30a4914c83ac06ed51f41275a4",
      "3132c1814d3745a68585ebb422597422",
      "1cf459d0ec594c80b6f7edf663529c6f",
      "5234adb42fc1484eb062e1467d0c9d17",
      "aab92f821ebd46f09e3fffbfe7740ea2",
      "21c80dc928bd4a778c8fec983e66c081",
      "612cc2595d8b4bd7921ba59cad08d828",
      "897affef908c495fac8c32b4307f5bdd",
      "44f6dc7274644eba978a7f36d83a033c",
      "6d197b0b6dee4ff790e0ac3e36b2ffdf",
      "d276061bfb2a4e83b7eba3755d331530",
      "a77d96cfed1a4504b070c1fe062db9de",
      "810a67d8bd6d487baeb60908a944272e",
      "e1c360859f4b4bc1b85c4ac3074cf6da",
      "6937500f75494e2dac6231d3262f751b",
      "e3bd3dc1bb5649c09853e1659f49f814",
      "194012630d3f4094ba1649b0af08b3a9",
      "f890e3192a854492ac60b4f544a04fd1",
      "2b35b62c0da942abb50b74e014fd0c50",
      "15d6048aade84221bb08d185c6aa70bc",
      "4142d27bc22c4c17b9afedc461245102",
      "b3a41cbb890d4c7098eea3c01697f38d",
      "6c7339a967ce48e7bdce65dde526fc52",
      "b2931545ab1d4817a042b34b949073b3",
      "b8d3ebe38ce24baa945efccd28b82ca5",
      "59ab2156f6434ecabfcdcf9e6a58d10a",
      "8d0b9cc7f8434ee28aa4e59f7028da23",
      "d5f97a4a04a54a80a5a05f7f1ee965e9",
      "75ea8884e84f466a9aba0104dd0bf422",
      "82b9be37b88948c79689063bc2d14a25",
      "ba47e84ce76e4afa88eacb9631bb1b4c",
      "b66ca077ea034cfc88352e560bdac690",
      "798ae2a4317c48518cd390ca12794d19",
      "af80143af7804cee89a91960b5a8ed49",
      "bfa2e586cab147f5ba6d1aaba2347533",
      "3667a4e5d252435a9b388541833bf2d0",
      "64deb357af4c494a894ecc5647a95dae",
      "70eb9f5c831041b4b2aa445d3a753ce7",
      "758edc109cec4b68b4529256b0cdcf81",
      "e57a02511c704d9f81ed0c3c9fe61b34",
      "4ddd34a850aa400fb294c9ae522444e4",
      "b279579f2f1c4aaa91707806a74a945d",
      "d59aae1819f94c69b2b2b3c8b4f9244a",
      "57052f53672944e09ae6aac68ffc0eed",
      "56252be55f3047bd8e873907ca81b79c",
      "d7f616132ac24ca6ba4d669136a8eb9a",
      "87e75a0d2b1c4f718d28983c3723e2b9",
      "9f7920553b3b495a9eaece2e46db8355",
      "ddf81f7e243d4b0096f5769053b2d146",
      "a4c4f7476a464a10a1aa1982c13b456a",
      "09ba9ea6ef2046399893b2cf0d4c17db",
      "f820a62743fc4d139872a7ee8dbb4976",
      "29854a0a8eb2437983d77211d608ad3b",
      "65d94fa40b624c1a9ed049ecd309a314",
      "e0e0337b561f4087805ea4cd1c2c2460",
      "9802793c4de043db94229be19aea0784",
      "49f759c874454e8ea3d01fb655557176",
      "0bedcf6c16af4cb1b24defd8d42878b7",
      "0bd7c5d71f7649419057962f0eea755f",
      "27d0d0d591574cf496a7449e0ed58ed1",
      "0332f75661674ecd888409c15d75dee6",
      "cbefde1429ee41979f84584021bd1ab2",
      "f120df4e0a2645d3bbdf9f3c0a109c2b",
      "f68a2112969a4d878c443af0ea76674d",
      "6c0e5964196c4b068726f0d38ff232a8",
      "7fb0a631d4344ddd8474574f5d59b111",
      "a8cecace355241b58d03eecade2b92b1",
      "f385943bd99e4e0d9ecc5d78265b248e",
      "c26a5ff13bf6471aa3e45d75c7ed12c1",
      "28583361b50d470f8d33dac9c62fb043",
      "460de84f425f48dbabf30960e4cb8e2e",
      "048dc4189ffe48dc8d407fc123e95b30",
      "e018c31dd4cf40c2a17e0f48391198ac",
      "f16e26b887d04064af2e41fb6331fa3f",
      "067d3f6595c643a0b391f37b227fa08d",
      "260001c2a9e0424aa8604720d6aac4d9",
      "e6dae3217d7847a8a1f2a40ed8a73b33",
      "906b26fef6ba4893b014c127e978d0e2",
      "d720a449d71f403493a81a08ec4bc136",
      "e6dc3e01e9d64659b695002fc0a9105b",
      "fc56d0045cb24c2ab7fffd5124e4bcbe",
      "7dfcbb7f4c7e42aa88e4f65a702f939f",
      "b8ccac645cad4be48bae974790d98a55",
      "0ae387b35bd14d1395e7050be2771cbd",
      "3f4734377d564f00bcbad2463135e2bc",
      "2073eb921dc24d0ab573ee12cd5ef013",
      "111a2769fd254677b7cb5a97e6dab5ab",
      "a60d3d362eb84d538ecb1201300f656d",
      "6d5a939161c443e8a0bc260b4972baa0",
      "f3c8ac1a2e7e4c459381f36735a3c7bc",
      "2dc7230cfc89487196e853fab7566b07",
      "da16e52dd8fb4af3857ea49f980b4c37",
      "88d9f9e3724b4970a27ff169cef72378",
      "6a1b41683bd64f7bb9cf22b60dc35823",
      "9bc05a7fd0dd4195a32116175c753eaa",
      "682715b348624a95a337dde05db4cac9",
      "2d8f47ec16f7460ba119bff91ac198e9",
      "b77bac29a54d4e00a17601de5c705412",
      "25a8ac1e01724d11a78e2ce79ee504a5",
      "1220702ffae444f9aad80139892d0a8d",
      "7f0e49b4a38b499f86e19e8dab565148",
      "17ff9414a4074b3384f16f84a96ba182",
      "31b682c69bf64d07983bbd23f3143b52",
      "797e187f29f341f8b49614b926fbb274",
      "ef3c89ca97784da2a469cfa02928afa6",
      "3a1fc8bb51b44c51a2a3fb7ef2b8e288"
     ]
    },
    "id": "EWQFjEXIMejq",
    "outputId": "282ab3f1-2d6d-435d-f1d0-6893851b374c"
   },
   "outputs": [],
   "source": [
    "from src.models import ModelLoader, HiddenStateExtractor\n",
    "\n",
    "# Load Mistral 7B (ungated, no approval needed)\n",
    "model_name = \"Qwen/Qwen2.5-7B\"\n",
    "loader = ModelLoader(model_name)\n",
    "model, tokenizer = loader.load(quantization=\"8bit\", device_map=\"auto\")\n",
    "\n",
    "print(f\"Loaded {model_name}\")\n",
    "print(f\"Layers: {loader.config.num_layers}, Hidden dim: {loader.config.hidden_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75tXQUPOMejs"
   },
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "66154bc343fe4af7be6e82b4f8a92cbe",
      "ffd8bf1ded65449dbe7433809783495a",
      "aa67a25edc154457ab25cba6dce725eb",
      "e0f9c3fb29264b7c9854049e360925bd",
      "e43c301870c447c4b1ee7ed523711459",
      "e2fdeefe411d4a77b2e5c1d51c16bcaf",
      "c8482504528a49089f6936aef36ef736",
      "30e47e7fa9954bc3a7156ee2231ffb37",
      "a0be8cb13be84fc6b82d32deafa62484",
      "fca42bcefc1c44179681b3446e33379a",
      "c317b8ac8a3a4508aca6afdf0787eb00",
      "61e3e6fce2a045c0b24bbc7ed7c699d2",
      "739587132fce471f87044ddbeedd6076",
      "0e3b14e5f29947308f67424bf7124213",
      "a39ba56c886d46b0af9556f50d565388",
      "7838608ed40143e5acaefeb4860ab4e0",
      "6f6397f2f20d4081b44a15bab330a868",
      "58cc40630d25484e8fd9934cb3c1735c",
      "c1d809cd5cac4234bfc4f6eb13ef32f5",
      "79316b5cc17d41889614c77a54702349",
      "7faf7eb268144b328ef418f7253a4da8",
      "5654d8e539034ad69f2df1e6e25a7202",
      "10086348156d492f93a05c549448ee32",
      "bb35a3a6419a45ffaa103db2a9dd455d",
      "5bd25c0749ea49f79becd839f8d2b7d1",
      "43194739e3704447ac429480f352df89",
      "ee5bc46b56b845e6ae1301a89724a1ea",
      "0696e907d25243168d838040a5656af3",
      "254c5e0503fd4ebda3b072d738d38f04",
      "ead562663c234402822aaefefce0bbeb",
      "9a45821296f4435da4bea83ed5f5da8f",
      "42806fce0916438d8762fc6de84a8b8f",
      "88f1d71456fd4613b62001ee34972cb2",
      "5b15caa633754320b6f08244d7549994",
      "6418ae82729a4209a4ed259fb3a9ad26",
      "ac000fd28dd547b585ba5d58e0a1ed87",
      "e8aebbf32b69407b853de5e7a4c86c26",
      "b1f1c8bf74d4494784e392fb51fa458c",
      "5c30afa3dbc4478184379db9b31fab41",
      "eb7e24c1a98b45c9a88d7b3821b54f24",
      "872cc3652e634b569d5e80a71428f3ac",
      "0d47b98e069d44d1bdb6390c9c86c40d",
      "b2883e3948324b29820bca1f2d2337cf",
      "fe0040f4798f4bccb073f280eecf459e",
      "fb88e0878f644c3a8f9635ef0aeb8a20",
      "9f52a6d0cea64873a05aba1de431888e",
      "51c084c84abe452b9d94ed568ed82f64",
      "f7958bce3e614fb2bca33646f0833008",
      "9391a1f4e20346cbaae81fb2d63eac49",
      "236a93f9d91a4660bb95f9fc776c4350",
      "ed04a07e20944a23b2e907f315d9b6bf",
      "688cee6c6a0940e98fa2b83e80bda566",
      "2669e73baf674dd99329210f85b397ef",
      "1bb14d8f587f4f71b04738eb9f954122",
      "5fb3bee77da747439935f834b7cd342b",
      "be414fc03a08437d817b04cf35f074b4",
      "80dc4d33e61e4747910651ff604c03d5",
      "158a45681f944be583d5295c440b151c",
      "8924ca34a9614460aace67789e5afb1a",
      "70a1dd802ace4612b833ff4f551362ad",
      "99bb3dbd00704e7dae5b299dfc69c715",
      "587ce5a1290a4a8dbd4ed1cec84e6e55",
      "5b4b2370afe64443aa23140c7c463789",
      "a5a6ccafccb14b4db7b900ea64f57c4d",
      "849319f7879f4d9da3cef416219d81d6",
      "9d64ede4e36c484bbc2df54bc0120406",
      "d95eab550f704c31bbebc6382ab6bb0f",
      "9a0143fc6ecb4162b9969e0408c5af20",
      "60201d9cdc3c4c0ca144de33bcbf17ab",
      "505ad44cbf7046babb1a1e2cefeb9cb6",
      "7f508c3ad69d4dd89ef72c556835be94",
      "51a4487c18504e58b48d1f5682ddb713",
      "c93c943ccff5454882a5c49777f7d506",
      "207912024f004f9ba68edb8f48a8e778",
      "237ba7588b384973b4fc11a3762f1b24",
      "243fc71455e243a2bdc9515c32c6a929",
      "b74b6f9fde904b74ab89cc99fe7154a7",
      "f4bf70cdf69c49e880839916b21f8088",
      "069e5ce1b08944b3bf1976ef8a947bad",
      "509d3c9e6c0f44bdb3bd3713af4ea504",
      "2893cec25eed425e93e02852d2ff4fc2",
      "f1d160ef496c4d8899897a6004672b97",
      "14bd1c6c3e864a479c0a825de9b05a97",
      "4b3919869d284417ac3587383dce2cc6",
      "63ba357de60c489791acb51ca8b07d61",
      "adb85f367ec842a0a83fabcb16da23c6",
      "7dcf80029c684dc7a7aead52e73dc5ec",
      "d4ee39d1a8ef42b1843270ba06fb1b56",
      "1d41fe5ced2e4f71b0eb37341679176a",
      "4e2cc24261ac4024a01d933cd0f95ce3",
      "e127343179734fa58e8cc118cf1ec8d4",
      "5674dfb1af2b42ae985ac13408f273a8",
      "236701f407904f9d9a300535d77af9d0",
      "1d9ca589e4b94c07af3240d23e9dac65",
      "dd581301067141b886184ab5be62c558",
      "0644a15c6e7e40d78abced388e9b9858",
      "5ec1b9fdb13543f7ac0e2800447c2370",
      "f741e4e97dd44ed29f4b86482d818b80",
      "9bf4689db99645398a65df079f228f19",
      "0f941d444e424d72b2ca10850fa03e8d",
      "02f665bf94964d228c26bf8cd6059318",
      "0ebea8d7299c4f61b39962e51bfe35c6",
      "dffed12e645a4be1aaa601106a944b1f",
      "5b792635ede643a8950550dcf835f33a",
      "64377c253dd04e9e8ac2280dfad38758",
      "82150f470e774512b75197d3d6e2282a",
      "08e2cf18d5194ea38031533a0f3fd6ed",
      "6096d636d4bb4349adeb3ec54c024069",
      "77527e281c3e401487cb03f895eeefd4",
      "d7a8365a1bbd4129a4701c1320419145",
      "536c149e08124f2eb10d4bf87ed0718d",
      "864258c25cd14a74878ea3acbf92bef3",
      "518847f473e24ef9bb26a1a42096ea06",
      "aeb04d8c42c04cc383edbbd7ba4826c1",
      "10f87c062e1441a5907d693bf7923099",
      "35122d9d94904c7abae9589ba6f03499",
      "e2f33cc9ccde4283ab4782bd5e72f554",
      "6467c62d4f814e5195cc825da880c905",
      "ad52878bf2044c45962c4055a0834109",
      "c64f2538b76f4952ad8cf75c18d7de49",
      "76878d8142c641a4bd6c4bded9d8fae3",
      "620be941ed5d41c1b9cc3982817c9944",
      "a435393f4b894853907d5cfee8f1dda6",
      "21ae7147fc0048f788a08b5b9f5542eb",
      "f79dcc158a4746e68dcac1d1c2e305a2",
      "ccf8342f1da9423ab31913da5f87adac",
      "1238f30ac6a241cfa67e7b49016dac95",
      "b37a55a4a85a4129b37e0d07a00e1fd3",
      "9510ef45481a4c89a170a61282839c5d",
      "2966ecaf8be24825b0219af0e3de51af",
      "a9d6f4be78e24f978823145205a57b15",
      "28a472435d304485825f8c9dc1f484e7",
      "f52b870322044e3f86020d8347fb2c73",
      "e3785c9e91784094bd7a0117e81b5495",
      "d0eb0db2f605495288c074f21540f6c4",
      "9b61c52f01b049699f0b95d48b0bb85b",
      "1eb4d8f86c3f4baa8fc70074b7df3bdd",
      "02bf59ef6a7f459ba623bf90e2b6c857",
      "3c93231a31684ba597c6facc5994b8b3",
      "bb68b7fdaf98457c99e424a6efc6e42b",
      "38db32f5188749a988f3cac384f76b02",
      "963631ac2e584a27aa75331c125854e3",
      "c856bc8cd30347f281abfdd9a1b0e782",
      "4de6861cddcd4b12a417843a5e80650d",
      "f74a573bab344de48c1784d643ce1b96",
      "4bf8841278464b36888ebe9d8e71bdfd",
      "3faad51c0ca84e6eb5f85e69767b80d2",
      "afd3397e1a2143deb6b9fd0e48296e56",
      "8bb16349dca248fd9594802100e75672",
      "287f3d5e23c8485aa3c0543f76b54091",
      "478b4079256246dfbc7371b9dcc3e1ad",
      "39aad6da34a341b8a81cf0252cd58a30",
      "c21ca60010984c2b9e347a9fe85ff8dd",
      "23be2da200584558bbf4e7e291951f3f",
      "6b7f6b1c7ef8407dbe3ae9d652c05eb0",
      "02e162daf7934e0f866d902fdef7e3db",
      "32a177e34a7d4709b712943f1ccec870",
      "87558543a8c946e28656d177eb4ffa74",
      "4648777fd48249e7a3182580be6e2cec",
      "1626a2dd40e542379995d6b748e261e8",
      "6d5dfc5889d94678bdfcb2f185c296cd",
      "3a9a2f23d7ca4a45b72166c60d96f3c2",
      "338219404a624551886d54d325e755e9",
      "54c3d7746c3d47c998e0965d17d12c0a",
      "5e76014de3c74a5399eef03606975398",
      "c2a02d9c4a35485a95eefd9bda26d15e",
      "1f9820c591604f4c87206a1037fb9fd2",
      "31778fdb486e44afac8cdb08a6fa2b3a",
      "3ff31bf8e2bb46f090d249bced38b19f",
      "29b3fe43e9d642d3b0ab38bc24de1e4c",
      "f94be814f42d45bd8cf8e280e9f77ab2",
      "553f270826474e088a49707aaeb2636e",
      "9cec2c5c5747462baba9ed3a2af7c7e7",
      "1421c247498f4de1a4aed73bfe81029c",
      "5cae17f7528a472d9c984d719b2d756b",
      "024dca6a57854be4a00dd48beddc6f2e",
      "a59c3c83e5a343659ad05492485d72a1",
      "9bef64f69f4e4e688d02986758a04e43",
      "b60628f1c5084c2389a19de7b9a76a27",
      "4c25d671c227405496633f8057079e06",
      "b49c880450564951aa95c0e02e70366a",
      "960707d652d347cdb4a894743693b693",
      "5a1cc0e1ef3349eabccc2f4073551597",
      "ac04bce3bfcc4199bcd835660c8d1e8b",
      "6ebdea5e337847d8a478cf8cf620cb91",
      "e55e18330b8d4f6c9de9c089a78fb545",
      "0266e005e3824426990455bb25efecc1",
      "035461b14c654039b8cf8ece0da2e5d4",
      "17ca7db3540b474a9985756f7f336d51",
      "ccab9ca75fa24b1eaeee5e1df893fdf5",
      "8337cafe652b4a51a641b22f755940d5",
      "6817d6675735447e962af46fbabbe59c",
      "3fea2c8a23124e7fa64bb3501a7097f9",
      "c3fff807d96b4d2185d9040fc2530fbc",
      "0f34ad43e52b449b9c52b43b3263c87c",
      "f74e2fff0fe641c0b7bc204c00108e42",
      "c5b16a591da84fe0a6be7743982511b9",
      "65884dae29b0486186aa7d9598a77279",
      "5fbb3b51f34d40df888cd98913ae2863",
      "fd5331f2f9144758bc90fd8715b065be",
      "80269668147e4e69a101a45197c85eb6",
      "a857e97b64e14b08b64c0a7fed7ee0bd",
      "d814820530874e6d82841919b9e695ca",
      "c8f66de684c1424b9e829d38d5e2f664",
      "ebc3ddd530674bc3b81c283d99b494bf",
      "b418d159523a4b14800793729053f7d0",
      "25a58b9502ea48a39c5707aa271ddf0d",
      "fb66ac091ec0455e8809e3c62e8c6e7e",
      "ba5796f1168f4adda36b59df2c8b7c51",
      "cc244b5155054c9f9f0ec08770189b8a",
      "d5341f0cb01e471494c67d374e5d32f7",
      "3653907d14064f58b5fda406e237e5aa",
      "4bd4c4e327b1455385d3452d53ba5ec3",
      "beb5ff5a0b2544b28ebbba96b2dbe1cc",
      "09fd7f08fa6f4b72965461f06ff6ffb1",
      "f3e7da7917de4fe3b16ac8bff9603092",
      "afabea9ce1ee4b82bb80cbe9553b75c2",
      "9f2b6234225143b18666515c40c1ac74",
      "e4bd7745705a4bca858a7b8e1f6c0ba0",
      "28c62ba0824048e48ad92d169065f084",
      "62d7f3a6612e40c49429e9bcb3ced62a",
      "5ee2cbed1e6d4895891199be00843a84",
      "266b0bd3d6174a8891156d0fcb607ae9",
      "cdabc9eda5c04d998027e86cf2c46d07",
      "0902a6b534a24ca091c8df58fd440783",
      "43d4d5024c994f4182f34b0f3589f869",
      "285e913c978f44859aab6ead76b40066",
      "5d89aa63b1bc480189383537298cb326",
      "0661804db31746ebb88f19c11350dc7c",
      "cf837e58703e43d592db3245a054e61d",
      "2dbe0b48d55c4e7797ed04767091b787",
      "b7147b5e9d59413c9682e3489159b7b1",
      "d953068d7505461c9e8bbff0796b9b34",
      "0970ac07068d4106b387bc67349e2390",
      "614c16d0056941b58292f0dfa7097a33",
      "43ec95ee7e514469a1228e514fb5b99c",
      "b9fb032a4ec0404596cc27229382d3c2",
      "fe82197cf31541899b5f1f2b95fae8cf",
      "75c9326e4c7d46bd8715c3eb80d018dc",
      "71a0fcc40b614700ae4fbe5ee9f0098d",
      "3e020a45cfc34cd2a19ba22d393ed72e",
      "561e1e58c0834a998852299f078db34e",
      "dc5b492680d74ba48d04ead992579061",
      "52fb83404d2b4441819c21d4ac05e00e",
      "db6eea5dabf74abba0036337ea07ca03",
      "1df7f5bd4e814ccebaf56b73fea06426",
      "78c89f368d9447d0850ad6d7ba8fb7b1",
      "ad34812c7b914070a919b6a31962b39b",
      "9bd261c875984df28b62d79554dca897",
      "02b2c8816362496498aa29605f99471f",
      "d5fedd3e540e4da2b972657d15b37f5e",
      "d4f77857ec314c2b8181ffbfc4cc4684",
      "ea31ce57029a49d7aeee21fcdb23ff02",
      "5adbf5774f074f54ab608755fd127410",
      "926054f6c8d149af8bc29843331511d7",
      "6a874a33f2e34fe980a849b27f381f24",
      "df92d63a4e094d989ae6a5ec658429f1",
      "89ce99b5824447beacf1ab107464acb3",
      "cfa4a5eb43174dbba01abf568705d06d",
      "2384bb0c8b8245c5abcdf48e869c9291",
      "5e7b34bc27534912b2159538737c6956",
      "408d6c11605f47008070cf030d3c4755",
      "f48649f775ed43df9b494775aae57b96",
      "2205ffe05e0247c593b9e37758f7a722",
      "813780af192f4853aa5108c9128b432b",
      "dbc069539ae04642b8a193de89bbb168",
      "6c70a60ef15c48418352e3901ec320ac",
      "a6c722ec12314b1fa0f1e1beeeb38bb4",
      "34577504693049a9851805aacdbd6e65",
      "5f4a2613f015471d9fb98e87bb127f2c",
      "2351c4e17cd84c8cadf06afbf5d09ebd",
      "15bf3429f2ae47269baca3ed8b25c153",
      "5af121ba88b24168870b218602682d61",
      "0fdd48c665dc4265a8da7f7325230bcd",
      "303ef80916cb4021905a1022c4a84e41",
      "21587b8462b04ddc99a3263b72ec9631",
      "c0742cd00a394c69b18bdd221a3a5817",
      "e641a79a8bb94ace84e0fcd316b5ebce",
      "7da47a4c8fa64976b7359d69dcd849fa",
      "a8e1b99a40f741d3bb0111ed945f3f95",
      "f4acbfcfb265482088bc618f0a4bf368",
      "eed32e1114f04baa9bdc1605a7ce95e9",
      "a303016c11c743d88bf80fe9f04d2cc1",
      "3365b04c67fc48ca9c9309ebf0071c4a",
      "11223753f5314dccbdb90159a28d5cbd",
      "e626c4b08dd14f589285ab84c9137c83",
      "ddaac4fac983466a8bf8fad4a7426dc9",
      "13af8e179c674a728bd8b930fa60a2e9",
      "18e922f0d08e405ca37f6ab77e5734b8",
      "13665f61e1284672b2f065c71ef4981c",
      "5dd0fde06e3547028af9cc9841116469",
      "7cdea9438b2a4b68918fb3d585cdec41",
      "662b5fdc95a14cd092371374eb7614da",
      "d8066253e0034c58930cd97ce0d7f28a",
      "fd0226269d26480bb38edd311508ff21",
      "ad99498d487b40578d28fffefdebe4b8",
      "3c9cc9f0c3c149e2bd1a0ae4ab32a5f4",
      "5c87606f079b411bb2c0f78618e40778",
      "d4a4b111ab0e4b86a5785d7be0ba45aa",
      "f1d1fdc291d648c9a1fbf80c151007fb",
      "d4550a83a6044f4781802c624280a6ca",
      "97ebb5acf59d4e398d87acfc6cdb9061",
      "05a900de6617467eb281f8f6dc73b5ed",
      "78931a119b8b49759b325bc0974a2064",
      "90cdb3ff19d24ff3a7288eb157f783bb",
      "7eae1c8711d2438e9f2b99afcf37a941",
      "b4285511e2604d66aff902ec8cbf31c8",
      "69c11e34fcd84eebb54be8fbcf101d5b",
      "60c22dfe28ce4126952a066d8a785ea4",
      "481b2c857cc84441b189fbe591078e79",
      "f3da2993f519478181fa0b5de30371d5",
      "440b08f3a4224765b9fc631685585c48",
      "ffdb0c7a3f8f4177b6aaa9bee95e7229",
      "3618c6c478db4d4ca006f74530a8be36",
      "ef2c076e905841729b831be7fcfaf449",
      "da0a8c2f10544452b829028d472c1084",
      "0186c1a6ae234462a6191c76827f727f",
      "56652005d7ec4171ba113feabd5823a9",
      "878a72b142524f54af678e9132e1fb8c",
      "325d8b36b1a149d39e8ed12a5d2b0ee6",
      "095135401b3a4e17af9bfc95dde04682",
      "9d8096d6dcc24452b0ae2277bc3c59d4",
      "941891b65dca42f3be227c8674b91f19",
      "7bd025a48c17420b829c6921d016c275",
      "a4dc901eaaad41adbfbeaabb0207f2b9",
      "e539a45b05c141fab490627dc371120a",
      "8a7966245890404abd4301d7a19e71a7",
      "9cc68fdfe4c14d0d9b70e0ae14b386e2",
      "a64aefe75677463c9356384dbfb7f829",
      "f41decbe9f2f47758581f36ba063ff05",
      "e79b3487e00b4f4eafdc2602628610e8",
      "c1e14a6c1bdf42d891e263a50ddd44bb",
      "2703833026c645d99ff56256ca5e8694",
      "52dd8dc9757441e39a01782ec7125a3e",
      "d72ee50b92f0497b90cbf7bab33c2034",
      "b77d083628564158b479467616e98ed4",
      "83659ad109b04635a0452667023d0017",
      "14193f3ae6fd43f0965b41e62e59398d",
      "ed615c0c8c394f8e90abe26197890f45",
      "d1fb7fb175da47f5a298da68d108ec59",
      "b8110f1ee9ce47f59815d1a352f3da60",
      "1cd9aee1ef024becae6e4fb574e4bed7",
      "72f6674b29d84052aeac6e53ef53e848",
      "5f93ba23abc442388ea838a5698e9b6d",
      "ae328d1205a04c7eb2dea2ba36552450",
      "49b4832d14af4393919b1d8f99652e66",
      "ce50c4f5186841f699fe5919b8c6fbe0",
      "f8176cc414d24fb79b689c6001dc2453",
      "9c9a7bd9bd2f4f92b363e59863119d4f",
      "08101a7215d842feb47548d92d6cb2e3",
      "9330d34a14284804a428db96c70a0fa8",
      "9f0a3a60abd846b597c7d4a3c13d432a",
      "2832b115918543e896c8ccaee61db3a9",
      "4a54fbcf7ec3478cb0b10e3a24cdde94",
      "e9784a880d034ba5afdd7f7f677f626d",
      "63b345dd79104666b129478c7a5572e1",
      "4af4079fdbe24add81700c9215cc75a0",
      "81699421e6874490a97682695a5f4ce3",
      "8898f165e7aa4dd0a3bdc0cf8b7f9f55",
      "c4e0b084382c4cb7857366a5e273925a",
      "b69a86fade2742f6b198b14b859f164e",
      "1427f99f06bb420895839562a2f46779",
      "5792e35429e848b9b695b65722c5ac53",
      "74b22ebf912346a1979f1d7cb5b6c98c",
      "8edde9b7f5424ce5ab3df052a99fd10e",
      "81b0f3042fff4b25bbe96a2cffa858db",
      "916559f6d368427ab0d474f833fafefb",
      "35c333293a5744fc8498d95929e85204",
      "4595a2812a8941a4b577353a39787684",
      "a844ec9438a8439bace1cd3b5a86d7ec",
      "92b1744565fb48238913c6e04b386f87",
      "dcde3fcf0caf4161b131ea1d3d0a8a61",
      "938a5b0254ab40568074518dbea837af",
      "ae7dfeba73ae49bd866e427303858b76",
      "bbae6c8a76154fbf9a0e469530f86e8d",
      "e54f7f7bf76d41f88ececf99af89d353",
      "a6c2a6e880244125b25faf6d470d8a54",
      "58187ab700ae452e86b2bb0d2a236a33",
      "9dea09b9d60c4fa9a9ec9ba499aa64c4",
      "46809b7078af485dad104891d1a3bd4f",
      "4ea6daa84cf94912afee85e79c418bd9",
      "638db70b1b5e42b9bf362d3cda8197e2",
      "09d7a388e5a04a008aa284299835e08b",
      "d01f318105834332aface579e1152d02",
      "edd1f838e1ee4bbbaa2e3cd3aee862aa",
      "ad98df1473c0450ea26f24dd9a224cd5",
      "f97b2929b57b47acb91b5badba18f880",
      "3686e245b8d449afb24e0e2bc9e2dc79",
      "95b6f09f029745baa17be9559b028fc2",
      "b7abb829643346feb1dda4deff3a7b7a",
      "d474b94ac3a84f4490df432915cf3bf3",
      "5ca3d63e227c48b39d48641eec5819d0",
      "131f72e0fedd4dd78144af0775f43fa5",
      "1206a289bbea4183b525cef6f4d662a4",
      "829e3f9e7ed34796b399cf055e582cd0",
      "3b7095f504b149f78ec035b5c0c12803",
      "e80cfa6081264f3e85e2753280fb3c1a",
      "bee0280582524c559c33a77c81a05312",
      "7e3aa5fa6c3942ac8625b3133972b962",
      "a2cec64b521c4c5ca1814aa97e0d97e2",
      "38603aa288184b1f8a46c57548114f4b",
      "95f6bfb49c4849da8bfb20685e84eb40",
      "e3e4396e49ea4c23a551969c5818ba67",
      "6533d3de1ae748699ac27d68ab780607",
      "d1798428b3414aecb7580e83c876cff3",
      "ac314751cfa645e4bcd703e3bcaf8487",
      "53605133e1e64054a7c25ef96609f656",
      "1e7906058dab44d8a4ea3fef2260a7c2",
      "677fa83218154a5e84a23ba61a3f9b22",
      "9f072029986f449093de3221cd3d4f95",
      "64b5fb2ae13140748f9384b5ac5854a7",
      "1140c17c30b54a109cba42baabd65b25",
      "47ab4467e78a469993316ffa7314498a",
      "851fbf7b49d14d49a76f74b2c50745db",
      "22bdc8eb9fb542bda3033378e9fba7ad",
      "296ae1d608fc4e84bcbe203085c68c86",
      "8e6805976d044af1b536467b9091ac01",
      "002ec06a60264fc6af3a36427952a24a",
      "9d021380f1f44a38b361578bb43033a0",
      "edce1295df6f465ab758eecf741b3e02",
      "f40aa1dc1c6a4f7489f3991620ddb900",
      "8acdc79c3fc34d7fa391040d0feb8e54",
      "3baf6d29864d40458c71d4b63c904170",
      "ae99a6fd211d47e7a4c9cee903867b33",
      "eae305db10c342f6a46b0ba0b90f312d",
      "6c5e4fb556b04698939d91959d37a442",
      "f2cffd3e43dd42b8946ee48a0a81f315",
      "5e21ede9128b490fbb6073c5a8c78615",
      "ab0256a9e182448f81d3bec06c69dff7",
      "9d0525f4da5d440cab7cd9dbefd03914",
      "33aea8e8399e4765b281906b21bae401",
      "ca061f0554be45109903253068dfe45a",
      "530de749ad554fa485aea1903e8d0daa",
      "eaf54c43b7084743905ac6e7ca9838cc",
      "65a1676aa09747489803f08d3d1ae355",
      "463e0fa8a22b4ee2ae6b1bcfdf177e6d",
      "d214d264df1e4e79aceda16420448f07",
      "8dafa4f868a74ae086f7626578b28a0d",
      "4c3ec1f371504be59d8b17d59f096d23",
      "8fded5a1d7a94f7699be9b39461c26e0",
      "0b3b42fb14fc496d97c3e7db2d4905a4",
      "99b1feafca2a4549b7ef02e6788c8d32",
      "54c143ad775549e4bbe14549c9388d45",
      "df8a05239254415f8b801a05bf81934b",
      "e252d3178b204678845fc4a31bcffe22",
      "f8ef67e53bba45418c9a340fab9b4c15",
      "6aee4003839e44bfa30f365dba8009cd",
      "f0e789ad4eba49598e4a371381fc501b",
      "07e08623482949a399b71b5830c872a3",
      "5f9dc33bc26e4451a488b8a5338176b3",
      "1e319d8e81ce4b53b434effd7d04fc7d",
      "47c80179f71a4b029552c78db9991ec2",
      "4bf42053d50640ddb04fb5c025f13b34",
      "ef375c5afd664e0eb9a00940e2c7686d",
      "3afb00bb618e437ca2f863b16d4df5d0",
      "7c96b7861e464b86b85bdd871c49c642",
      "c25e55b951634d8489900716f1ea9173",
      "181f56f428fe4a4f9c2e2b47fad4228b",
      "57e50c959b884771b1e92a6c25578bbd",
      "e136dd15cbd24fceaa768c4c2a3419d4",
      "f49cbe1f3b2647bf9cb9028a92b0078a",
      "a547cf8606b944cca3e5f139cfb5341c",
      "98f49ab4862f469c96c7938297e168bf",
      "0db6706cc0c940489a190a5a8deb4e2d",
      "9b3a162b7ab04bd4a8ae2981b26de8e1",
      "7149a8fb2bec4f59aa4f067f7abb09fe",
      "3eda4d63201946d3a48d6bc2c85068de",
      "7ef4354d3c3b46c3bd830db7005f573b",
      "2818f31983e245c68c6e8da31a19363b",
      "56ccda9f133a4428a8dd77249cbdbd38",
      "06721468d5054453842b9241af072f32",
      "295eff1120ea4b278b486082f92cdaef",
      "889877df0288478fbaaa504525eacd1d",
      "7dff67e4c7ae404bb01ca7a3bae2b9dd",
      "15e0c8e320ff403b88ec5dfdd1e33ab4",
      "6f36874b542342fe912eae3b15590630",
      "1445f468a9924d5fbcf7a1b320cf37c0",
      "09e2a961369846cc936b32954ec5a6e0",
      "4d5fb49cb2d74477ba5148fe156f5047",
      "c9f4bcef917d4d72b425a95019663b20",
      "04d2ec6084584f6bac542804af8941c8",
      "2257ee2f385542798fc50e092e8560e0",
      "259e5fd804944221a932c348371535b1",
      "72cf1ab564a44fd7bc4b909085176991",
      "23612496d2944cef86d7af7ece6a0cec",
      "f3937755cf66484191984437ba20f41d",
      "b3ef1e7af93b43cd9ce2a01bc38821b3",
      "8bb8c612268d4b1cbc6c37621dcdbe34",
      "daffbbf76bac4060a54cecda31598267",
      "3c706dd7cbfe412cb3c8309b8d8dead5",
      "259a26cd7f4e4294a10d3729d6fff11d",
      "5a8839ce5a68454985c077922ad95674",
      "6f8f7a5e4a9c4d2dae24a143c2653d6b",
      "3f6482675bbe4b1a9ae8a369e5495567",
      "ba28cb34446c43458d967ed0eb5e0f80",
      "38608b0745534b75b4578b86e43291ff",
      "8bc4c6c64d03419db8a56bf0449a5615",
      "50de82f350af468e8fb5579dbb78365f",
      "607a96b9652a44b1b636f6bd435d0bf7",
      "cfd4d03fe6ee4326ace675d9325c04e6",
      "e82e74bfa76844da9aeca572d3bc4ec1",
      "4e7bd28571a0415b8bc46c4d6ef954f6",
      "429240e65f3943a08849d7fa83913de7",
      "8392d88297fa42e2af605d4a5b6200ed",
      "82610dca193442d2910d5a0d0ed7e9d7",
      "9d698d0e06e54d09a84899c16f4ca281",
      "9101f38434ba4c66b4a442ed2b5ff165",
      "f1574e563c8547758ec667b0ce7e9a75",
      "3b4fddfe94c84a1996aa7b44b325ce8f",
      "354b2d20d767497c8e8987ef98527cd9",
      "fb2e459304f44aa48d6b264934d75729",
      "c5faac67bded4ef4900e2694df33caff",
      "4d9bb712fd134d929607168f68faf0d1",
      "d6ed2e611dc04b908c5694e59a959d65",
      "608c263bf9d4478f9cc3447db73d546a",
      "6272a613e9fb442dbd9f7b79edffe529",
      "fd75c5a6bbcc41849ab4f3e2239fcf0e",
      "b9c4495f3a0e48bdadb2e98a76ffb3d5",
      "770161693a064f6c8e76be8bb28ec5e7",
      "d02f4b8e131642d89836af8a15e15b90",
      "4fc7fcc5c83d465885bf297a9b68b4bb",
      "ebe425ad178d43c598162db2aaae7fd7",
      "6455e1f8084a4831a424b9ecba84b879",
      "a7e0550d93bd4ddeb4d67c2594863d23",
      "6e7c8b82289b44b6ac1ee7f260c8d95c",
      "6f9d1fea74dd4b9084148416112785b2",
      "73b051291fd045f4a435c111f1e0172d",
      "697101c8f5954f48b574a6a62377a93f",
      "615eccf5031f41a5b60805280fa0942e",
      "54fbbc0dba5b4b3fa1c24e1c7cb9c362",
      "79f71a14e762454a8165fc63cf363e8e",
      "362d3de0cbb14a78ac100e610f71e4d0",
      "378b65c6fe2e4477a62e8beb71b7da5f",
      "24fa213619a64801adc58836be9d5417",
      "cfc0357871fb4d91aad327ade8eaab9e",
      "561124fb0b934692b59667f1b28f32d6",
      "45998ba5685f43fd8e93cb883c326a55",
      "a81e03f9a73e42b4be2504fe9f2966cd",
      "9590296a33094eb2a7c27235b6253131",
      "98b933e86a8349f197e829410defa23f",
      "7a9d082028954033beba28a5808a9503",
      "37d0f424c58945e084a984f8eefbd0cc",
      "ed81ab4e04bf407d964baba6122feefa",
      "94fe81ca39f34b31be7ea076cc810f15",
      "b1e14d8e75964c9a99590098f337e098",
      "4cb4624f73b04567ba57fbd71c7ffb84",
      "51422912fec1434d9c83f30f75debb92",
      "52ef3d327ea64df1a0e5c6e0f1da1014",
      "57257e9c30e7445896a6f376776ad000",
      "7f41b8e6cb4f47b290b810de52839292",
      "69bca3bccb88402e9df11407c5acbcb1",
      "23d5625a1e6d4c20a903c0ba62d3d962",
      "e500864f4baf479b8479d96469fce70a",
      "fbb15e6cc9c24b4f930dd76df05a016c",
      "bc3363b8437f422cbc62af9282446aa5",
      "826e32375dd547fcaad53035b34f91aa",
      "3d073b86d2c74dbf8a90f21a98aa1d48",
      "dcb6eb72a2274c999c9ca42d00872356",
      "f4a91f3fb9ea4af7801795be5aceafe3",
      "fb4182fc81f541d1b333a4f1b2d26774",
      "34cab32d9a5244bbbd84d3f9ec85cd3a",
      "8e52bb9b145246499e217ca1dff97d91",
      "9b3b59e2593648cfb37ba6f40f6f70b7",
      "e5daf631e2c04fe4bb6d04c6f68bc666",
      "cb462b05db5646209d6d68f58beb35e1",
      "8be94e024c5346f990704c3c59ee7fc3",
      "c27d0540c56e4efe9a53f9204b90b82d",
      "2986aed01f9841e2b81534f4dc73bbcd",
      "df7236e6669a4d0f96331f3d3b9412ef",
      "5e694dee80534d45bbdade3d65036da6",
      "b440c15a5dfd498789fedb830c1b261b",
      "c58cd6182efd441ea7b48af271637554",
      "80c2de941a964a12bf73a7c10b54c181",
      "dfc98a4e508c4f08b366c7e49404e99b",
      "e08e080a00d948c589cb1ca9d6dbf5e1",
      "f30efdefc3ea40439373d8158bf1e4e4",
      "29af4db371254924985846b60f2bb513",
      "34d7984a6eca437ab3c0a9587818a4b4",
      "9a31ae0ef6de483ab28b3a0759707889",
      "058215c914e042b5aeb1eb716b7e6e27",
      "2ea6f1ca66be487eb9a39a816fb49b35",
      "8fe47b5806f84811aebd265835bc8bb6",
      "332bf0b6bd1e46b0b893b56a156784f1",
      "63a6f7b69dab4b07aa95feb5b00d277d",
      "cb27aeef2f834ad9a8279408cbd9fb25",
      "ceb5de7d521946c0bf0bbdb647dcec33",
      "b91f74407edf49128e10ac3eb66273a7",
      "74a76e2c2609443da29d4f8c12fe6a58",
      "1a616d53dc9343fa8698461fc4b31685",
      "26597265964e48bcbb90fae4c4007764",
      "4a7b4bcc5fd6402092e91137001217d3",
      "875acf95a4134e81a884167c2c67b7f2",
      "f0956add488a4d07b4215cb4627676de",
      "9be9acb45e024dcca472419f273831e0",
      "1936fc0663d54e86b90f479ee6d5afe4",
      "ad6dd28ce91d4b0291a44f834ef4202c",
      "0274deace2954bf3875a997f66df5831",
      "7928e03165f94dd6b667b2a21ce080f2",
      "339e25c86914461b98dd331efbe2f9b1",
      "f469f22d84a64e63a6c2ba0595532694",
      "2031922889db4abcacdea5b0ead927da",
      "2d8dd2de12c64f218b2d314508cba035",
      "43a2646666594ec296c2e807701c4793",
      "f49902207e3f43c29c0360659943513c",
      "9a8c032765834ef0b0a0baed18d8fae5",
      "60f8be5b177f47e7913bebf92131ea88",
      "1609996ef6b842e781020d3bb7f88a35",
      "7bcdee5d320b487dafa26e40adb0ae27",
      "bd35a44e990244e8b2b7a3b2bb2bbd07",
      "e7a0d63cd5aa43698ccee83b15de4d86",
      "c8923f58c7944b5fb291ac82ac659dcf",
      "7f14c7d032864005a22955d23997d666",
      "3153a6a880a648079b5e379c59f8f2d3",
      "1e24a27490dd41a89d58b62530f96a02",
      "8aa1381fa4994544982aee3825c78b6a",
      "b3ea573d429f4a46a8a47282e8db8ec7",
      "4a6fd0ea1932477287e43724799f7314",
      "765febdbd0274666824d5553985cbe73",
      "352722b510d54a1f99b64f4d20d62ab9",
      "3efb3dad28ca4a25b20e4d608573867b",
      "3f63129ba12442f5bee782bdb96bf018",
      "e7a1df9840024806ab379f925ebefc47",
      "01fe055f3906482c95cce02ec8c3736e",
      "1d68372def6241bfa23d76c45e41bb65",
      "fe8294bc4c1c4c688fd9bfc20d48a864",
      "d0ab118211824a5d8b72abaa40356c60",
      "7b461622770e4a35be5b8a6c6736c7c6",
      "ee41054235f545109cd0f82c5bcbde7c",
      "29826749bd634ac8bb2539d002dff843",
      "c283d797da2d493ab253f4d8bbb41f73",
      "a881b133378d46e494c61f007afc0e2c",
      "0d1106bdffa4449285ad5c990cac95ea",
      "fd25b47eb5a94bde92fa4d66a7580a79",
      "183b47a05f5f4cb2b18cd495aa96b0db",
      "e579e30afce84350b7e0e31f3df4ed3d",
      "54adb7641d1f4c34917ec65e5731e1fc",
      "2e3f811db38c491d91043821417f70f6",
      "29e940158c79402199b4b86facb28cc7",
      "d563fd0400e04fa0b762ef142b580618",
      "3dc3a7374f754e209e4f10f3600b1585",
      "86972254669543059f00ba50f93b57b1",
      "fa9c7d8cc7204878a1fb72c5e5091ac4",
      "2936426c1bcb483e9b77d01b92e30322",
      "07cdeddec5854c01984a09a411b1d1f3",
      "d4b48ee4c80e45ff97806ef2f8b5021c",
      "e76c099fa20d42d0aa516c4eda14dee3",
      "526ae2a37f5044b2985cac9b8ec254ec",
      "b8ed6481713f4623840d21fbffc72611",
      "8c0640f6812a4e6387baf226b51a9a29",
      "b506ab07786c44ea9e17c94f54941297",
      "03df5c7e80694933b1915737341c2d6a",
      "e5ce54998cf44d8e8c04153ab4015396",
      "ecc8f417fbd749619505772d3359dba6",
      "a83c3c08b9a546ac8f452ce7f9003264",
      "5ae15df91e374855a2eca70e82e28ad8",
      "c10f92e581d64e618aba06119af38708",
      "94ed338357bf46fda635ba5a9dffc9b9",
      "53359925e96c44849444f094a57857f3",
      "82833e355c214f2289c32d4d68b72f9c",
      "09c470d174c04acd88272606ec85a6a3",
      "376067c672f34a4f8ec1ab01d1b3bf06",
      "cc47fc9973b64271a7655b78a1786c25",
      "29e13ce2e269429299eb81a12d283f33",
      "2f958d63c7d24fb384da59f1e4c3fd4d",
      "80cf4bf9e042475287a6329354d9ee40",
      "db65d22e44a546e6a27cc2f3f93d4b04",
      "57cb2387bd944de6a77d2275378e4202",
      "1db21215ce3340bea7914d5f191188a9",
      "4ea23d714e1b412b86b1b29aef8636b1",
      "3c0f994f48ff4a86ae1c96421d0ededd",
      "2bb1da9f5f9f4b3fa03b758bef2cbac5",
      "ac1859c39a10441a9c1aaa92138d9123",
      "4c5c542d2b03462a86b2f2cf2e8b08aa",
      "8fd0129f940d4178b0999a7a2864d8d8",
      "c781dd95c7e34baab8811c32601f4ba8",
      "44ca544c4d09424a9adf0d76f6f60b26",
      "8792d0673b5040c7a0e9840e9819c0aa",
      "63b21eac46a54bb98c94df5b5ab70b03",
      "51160565883a4bbdb41e78f3faff76f1",
      "8bedb481510042718fc4b83a8e6906a8",
      "717d79f6f18c434c86fb3a1d0a36314d",
      "76f526de27784918b0405944371dbe5f",
      "47f27489f4654f9d9bcdfb6b774bdc68",
      "fd0a37e84ef74cb5ae4a5db9cb263a32",
      "1f2959216ce54f2cb1836b6102c43fbf",
      "1ceef0d61ca543da9bec872b5c5ff35e",
      "6ab9933aa84d4dd993b873b52e515950",
      "4acb771c243d43f3baeff83f4621376c",
      "7d6caf41c8b842cc82504de49997dfce",
      "d8743eb4ba194ab1b147e38bba2ebb2e",
      "fb464d9cfa734391a06c0331ed1a0032",
      "8e7aaa5f49b243e498ca258092e0d261",
      "a2309206cd9a43c2a4bba9528a3a2b21",
      "3fc9a0fe4c954c25b511cc2606b246bb",
      "04a8ea0088ed42faac965f8485802eb5",
      "6b6afa0a57d241b1a5f5cef0ff00607f",
      "b8e8f41bcd7a4016a798d35298b6b02b",
      "bb9a8b2625ef4d7ab57b6f2aecd6ec4f",
      "523696234aec46a78cd4353e5ead3ebb",
      "80f474badb9048a7848fab6776c1ef09",
      "ca8a8b4bad754b9293d3069c70825588",
      "402c45df8b044760ae3dcfb99f34558d",
      "8cf7eab811f140ed9517e3420a34bce9",
      "a31f537bc57a49c6a0a6192ce2ceeedc",
      "7b4ad3298d874765b03d1cda3b4dff02",
      "490264d92e924736aa4a11a64c22b0da",
      "8789668206194fd3b72059bf717b3315",
      "b10322b9811f49db96f6d93c5de3d0a8",
      "7c8f57fdd59f4060bd9e29d2acf7ffae",
      "f9963b4569424068bfc44ed657dcb893",
      "38b2800e28a54da590a4157e2699e9ef",
      "1156f8f1e0ac4deda8f0c15aca187543",
      "efeb6a39104143fdbeedfed0742d11f8",
      "493d5c63fc074cd8968d551d80004626",
      "df926c240fd94af9815449d57610b8e8",
      "02fca3bb033e4e2888a2a3e8170286a0",
      "5e8c9341e3694779936705e630af7212",
      "9eda595ac7f0402c9299b0dd7ea2194e",
      "bbf96e1ba6304bd8b479aeb7e117015e",
      "9c9c1d41c622445bb96cb1743173fbc7",
      "c89b34d553614fbeb6d29191c190f6d2",
      "1d78a78e92dc4d49a8b35c4fbc8d5098",
      "1e18c92f98a7499baae7c03aaa477b4f",
      "5ad0d23372d44e5ab7c324917d261602",
      "f013b3989d6f43019ba30a7634df6514",
      "e3a2112d87614a0084b7fd2808b464bb",
      "9b968a3e22ce4abf9bb9cfdbff9b8022",
      "542351498fda41288f6c60d692b4de9a",
      "235a8daa18f449a48956734d0147e681",
      "0a261bad7820453fbb24ca5b9a424eb5",
      "10b398da79024b888f7df11dacdcfd16",
      "8d9eebaf2ed84cf6b395bb1376538068",
      "80831903afa64086ac760adc81401565",
      "60678eb6cf624d0bac691897009424a8",
      "7a9b1309b25b46379dc3e180662c9792",
      "999ec24f57934e0294b0f79248052e1f",
      "f8416914d0114750be4b545d5362f765",
      "b01c704595a445fb82329fdaa9775e75",
      "5f6dea0cdfdd454fa0d60fe769a101fc",
      "552b6c1252724411b9bc024e84016051",
      "a7a67d393c78402d941fca6dc3ba0705",
      "32cdec97906d4171bcd825e7537508ba",
      "90bd5195befd49e3b55f174edb81b9a7",
      "38047197956b4633a038cad30f72c9a8",
      "49420fca5b314721add3cf1a76e41919",
      "92a8f4c8ff72428eaf9b8b36076050b9",
      "50c20782c42c48cea0630b3b40668040",
      "cbb90ff3071c4dfeb46b1e41084988a8",
      "a0a4c62f16bb43eaac3068265166b2ae",
      "464cd94a88984e09ac168849d9502c74",
      "c8e6ba6537b4459195fbea8c2f4491a8",
      "b2366d6bbc60441d9c44cc95feda3539",
      "551d2558a2394115ba7ffbb7e663b327",
      "b5a1c8a0c5a24816bb94ff63660198c4",
      "54a362abc18b41b3bcde4a340bcd2628",
      "849946f71f064ceeb99c36f6314d548c",
      "0a6d682d4cae464da759e7a9ee0fb940",
      "ff1282477db9455da456ea105df172b9",
      "3be146192571436da2a315c5f409ea31",
      "42879c7d33204545a568a5c02a7eb162",
      "c5722eb59f32438ea35d9f08c1f4e5f5",
      "27d1789fe6654392bf212ca862e5b2e4",
      "afff078ff86e4d32a6d07c98f427cf2b",
      "f1ff3f0c019f4012bb8f07ad047a984a",
      "f09e6ee403914d3ab94438c953f2f3e9",
      "e3caef9fb83e42c0860a8036e4269e7d",
      "8faf9cd2156d4712bb5352675d16b3b5",
      "7c4b96b6e9b24e54ba5f406e5bcef1d6",
      "f424b374180e452ea66d1d13af715cd0",
      "70ca876c7b4e494c917cb1af61b49e89",
      "9ea3535e141f43549fddf7f59eafc9f5",
      "ba0a2999492f4ad98a445a00fb46e4b4",
      "4ef7a4a428a7416ca34e6c5e0e6069a8",
      "c1b215593d2848cfaea92d0e1aa8fcd5",
      "03366b9f2e74489f86c2ce9ee2aeed47",
      "d42decb817f8438b9523ac22ea5ad0ac",
      "9ac0656b45474501b01c91109f988416",
      "acf18c7e40f944c29717c4c91a4fee36",
      "3a2343edb9734b1c87937bfbfff4dc68",
      "49b6d713b3e047f2ac44621119ad4eea",
      "de9566f05337450e8349674bc5140669",
      "9c8334e2b7094875a2143f1b5e99e54e",
      "a1557bf81f4747da94e734fbc7e50c17",
      "d317768cb7094c7aabba53e51990e080",
      "b67f2e63697a4af7887cd1d193ef64e6",
      "d67e0198e98b493a9b0fda5d653fb594",
      "573a83acb1bb4cc78f0ef112ac6f0ddf",
      "1f03e4439bf548a3841a7e7d9e4bf817",
      "bbdae939d9214b38a997b0f75c54b748",
      "550e7245206c41d2bcf476dfc781f52f",
      "8d9606b41076430884ce4f9d183b81d9",
      "db3ee908032b44c692d0e7e5ac84c186",
      "04edf9594cc24987b6c2a6d3e79230d0",
      "0321e95ad31b4bf49ea7644e9b05d140",
      "bea636f2c6474bee8e7ffc845c4ce663",
      "22485efb4fe94789b046c054fcb34da5",
      "639cdc1987ee48368a22c6d479e760a8",
      "e6818eba5ab04722ad321c31b917b55f",
      "05229b8e9eb540c7aa2efb7d87aa64b1",
      "bed6c93244df4cc6a55b0e0e38b04417",
      "a4ea32c970a84ac58e7784cb00e38ef9",
      "77141844fc11499abccd147cafe8e2f9",
      "0260e44fef51440680446041f73506af",
      "a9c5daa1cd9e459db75c0d49f3c06753",
      "86463054000f4ff2916331201181da55",
      "cc102c12d2f64e0c9a141c2be1b73fc1",
      "2cfd8b1299d34415bc80a6f8909a16c5",
      "a863d00c698d461ab3c01b5a15a7147d",
      "dabcc3cdd03d48b2aed9964d160e48a0",
      "972fb9c1df7e4b1e9a61a45048612723",
      "670b23ae39c148cf88ad5322e5617183",
      "7b3735bfd7314641b542e5515e0dcb7f",
      "8791abab501248d2b30e2899371354af",
      "7933c20b1bef4f61827aa826bf233d4b",
      "73789699494a4a0d82b96a891497af8b",
      "09388de803534b78ba1a887d116f33b1",
      "8687e41b3f7f41a29b1f30b37a3ddcd4",
      "d49b9747655e4662b1cb6ca58e276314",
      "015d41e659154acd965e0c09f63be232",
      "c488106e38eb4c1eafa45e18884eae13",
      "00c30d2e47274daaa7dc445fa31ba4a5",
      "aa75612c619942da83b57a67ef173fd3",
      "82703a9f06dd4b349a786449bd206b6e",
      "a3d47c80813441448d15b9c07d8a63e5",
      "5793fbf5fefd41228bf1aaebe620db71",
      "d3de4c82ac40417b8209ef4f40c9f50c",
      "529cdb1df6b846b2bb5de6dc185b97ed",
      "57240e9b297248d9a33b0c98ccb49b98",
      "e4031ef370244bebbb60e6e8e159f188",
      "d88e86bdb6fa419ab5703204f9d82aa3",
      "c942c179d21948b880397555347abe4c",
      "41165cae72854ee5a096612c869b44d0",
      "bce6a606fea04079b84808dfc9d5b7dd",
      "b2dc14eca8d2430499e30beef52b3a2f",
      "38b5b115a06b4a6c8df9e4ce63f2cc56",
      "cc3f651d7d3c451b8e80176804f389d4",
      "2a920935f7e0421bace582c0fea2e8bf",
      "16d5c4f6e89c4fc39c7f24a05f5a410e",
      "3b4189cba86940dab5121cff4c48ed43",
      "b1e8fabfe5254f389862d2f5c0551c72",
      "e94f7b0cf72142c1b438362cc7713ec3",
      "58139498da3b4df2b427a695962108a9",
      "470cef01ef8a47fea336962c783ef1a9",
      "e3b42ffa53484b61af9a16ccfc73d6e6",
      "6ff3e019aef94683b8ab54bd562c35f9",
      "5ef06c4e2a584c31ad2b393d7f0c77e3",
      "4889423996d14c60aec3d961fa888667",
      "e4aa70a940fa487e9f55683db230a9d0",
      "cf66d39a908a4d8da56f1eb2d3e0b9f4",
      "1f3445c4874845cab5ac0e6e33f6f093",
      "e520883fd90744f49a6fe6b4521be951",
      "f3a284bc2fea4658b4b982cf3ddb3a99",
      "391e6d8c4b8f43cb9216cf46964dab6d",
      "38adba9d53404341a883b1997a97f03f",
      "6404a4dc931d48d3a0056da56b811ab9",
      "812bc6fbb6e5473990e876d209b91e9d",
      "ed98ea7cb1f14621929de1a212bc408d",
      "7df8ddfb019f45ff86e2022b4bb79283",
      "6746566a4eed48258ecd5113125f8ff8",
      "de618a3c6b8a485b98f6378f4ff086f7",
      "189af7678b284d5fa7762fecf2647d2f",
      "a46ff5671c4543a997318bc970399ac4",
      "d910920d66de4ae18e1bc65bd34f7a9d",
      "84cae6b9e4ec4e6f89ef0fe61821e36a",
      "05c956c634b4448d893087fedaff3182",
      "8766fe59c308403e887d52e4711e2ca6",
      "715f50943a524a6ea0d8b8b40496efb0",
      "a65d6776b74f4e4ab555ef513676e07d",
      "c30c086ad511406e81192bbd1ae2bc19",
      "18e957067d0a4699a7885ddfb2d27387",
      "27850e1bc9fe41268522056190a2a398",
      "fce3376cf0654155b0203a80317e068d",
      "33465f3069f949cf84ba8cc3ec8ea918",
      "d6fee57b751d49d4a6f3dddd0b586cee",
      "1be5cf48ca874b06ac635d75ebee78fc",
      "d993fee90e77404b8170401809223017",
      "f2af58113a8c444f9489673ee0d0c315",
      "8c614cac6835470287109a49fd487437",
      "d44c9ea723c443d5938ba641964c1880",
      "68c8499a0e66443abef699bfdef64e3d",
      "25e9f194e1414c2ab6e026bcf0b1b2b1",
      "bb817adf92e446938c8897f14db4f1df",
      "c056835e32d148e787493975f63c4a87",
      "863b7644641349d5a230e676fb2c3dda",
      "149b6a6e32e44593b51109343cb64951",
      "957965a3c8384ecabf5b400fbed547e1",
      "6bf4300639a140959643a8e1ba07f0d6",
      "c982a94518144219b4f17244c2cf2d08",
      "44102987d8a94c7d979ebdc3d80c637e",
      "524e245529664d6388f14763bebdcd0d",
      "34b4dfcd479b49f880105f5c0f9688a4",
      "e20684f6be4248e4b13f825d313aa4db",
      "a40354953f574585a3afd481b4185a13",
      "5d462248051347c0bd8b7537d8fb6830",
      "f0e6754735b6415685c729235cca756b",
      "1394fa80f0ee4fa4b2b150e9d2b67b88",
      "ab140bfdbd294de1a41975e476149032",
      "e3054d77fc3142e38d0077e9737a6e8b",
      "ec1f830f943d4e32a38703b9e50e945b",
      "38220d1c623f42d1967d42a78484e2b1",
      "aeb25546b0c041f9a077ebfd5e51609d",
      "7597eb2288604d1abcc5378fc1080a06",
      "930480edc4f549b2b15d6c7dbb742e69",
      "ce6d97c71ca84a25b4ff4cd7f34526fe",
      "f12e35d2308749acb1d09f9dfb251742",
      "cf8494fa534c40bba85d577ae912a3c1",
      "d9bed94a01f54bf3a191ff81a9d75767",
      "f5dad0b055fb441aaccbaedd8bc62a4f",
      "d0de8d1322614471a0db5c770ba95af2",
      "07a214e0ffcf4a8685943b5f237d35b6",
      "0e445623a147473587b99d007daba854",
      "41e8d92eb4d249a6835179adf6ec9c56",
      "06320f1ccb3448d6bef4acc3c7e7a499",
      "eab7bccf85254783b2b2a137452418de",
      "c77f19e828f0402689b4ec7c4d251d67",
      "1da3e92e8c764af6bc4456d5f9f6fe8b",
      "b8333a2431974f6f8ff30c3f8c6a3ef6",
      "eb7775da8ec0409880a380b9cfc9aca1",
      "a1371554981f4b0583d2654f8bb8274b",
      "e7dbd5ade52048d2b17693dc9e14b176",
      "48d819d4956c450d819517a39d01f9b8",
      "e8fe92a68c5b4fdeb9f2a1a7bacd52ba",
      "3c21905accb14a809ff73a4753c4349d",
      "1e75dfa8ce4d4976943fee59351ff922",
      "c2a8e2b78a0146f0a60a02a71417e521",
      "5bfdf462d31649ba8a25f26d9411c448",
      "b90e9fa37e1244bba75dc0d07a739f55",
      "7349727b9fb3415fb2be7973a48c13ad",
      "0702c2f8ff7a4b9f8ad4aba29e8da4f0",
      "a6e2b56bde9246d4b9a9d45809081434",
      "9e1122e29e7b449799d6b1497b3bf73b",
      "4c56559faded468badce506b8e5147c3",
      "e3667291e746495dabfa29ecc2b26ba4",
      "627df585099a41cf955ad9dac96c2da3",
      "c545d470513445699ca025f99dbb8879",
      "afa139e5dd644aff838e5731ecba814b",
      "73dd790298dd458e89f6e0f49eeb5804",
      "3703ba08fd30421e832105e8e0682498",
      "f3046bb8f6304c5e947b0319f27ffe02",
      "96ecd5bb730649ec99abeb2ca8697353",
      "fe870f301abe4585bf421e9ce12ec209",
      "62d5b8139bb04447af3e2b8d5e4832df",
      "ffaf72b22cd04fa19d776920308fbce0",
      "dde79cd5cbb744c3b9466be621baa846",
      "9835939d68a345d8ba66c573d3b76c07",
      "5a848130dea045378c91fa0f19d831d3",
      "4619d2a2714b47e69c5137af3168de9c",
      "11a31c166ddd49c3873383d5ac1b2e85",
      "11b5b080d2aa4371819fcee162617a01",
      "880bd9d166d748d390a468dac5a93355",
      "fa4f4cdb86b6447cb012cc05177d6d42",
      "6cb3205b201642709d568bc51df1ff2e",
      "f47e4ea8adc9431296c502edb3a63cb8",
      "094c2e9fbc6b425b9e07545206feb8ff",
      "6883a98eea8e4a66af1b7e4c356c9e6b",
      "05a82985e3a1482abf4c1c5b8f06d383",
      "01d3d881315e4550ab50163be31c29c0",
      "d4cffb24b4a74e8d8c633dc8da9856a2",
      "406a2da4ea8b43d593abe3fd05a3e01e",
      "a10a1f3680a9479cb23a07b0b6304db8",
      "dc59137e96954cbab01c29626335bf7e",
      "b59a0514174a49f3b301df8d06e9f0d8",
      "2c2266ca6bda4b0d9a3b53a563fc4309",
      "1c1a2daffd7947a9a558863e169a7009",
      "b899965a1fe94a0c824f51dc403e6c6f",
      "a67cb4b8e7aa487faed3d7ba6fc6b027",
      "3d8c1573f6d54fe1b351d7715f932f3b",
      "bac9140790fc4b159a27aa0792a3fc41",
      "f2e5cdcf16c34fe48070612af04737ac",
      "65e0bcf59694417a9f9ec765c52baad6",
      "ad87965adbb34b949f2b172ea1d7e563",
      "fc970b23d31b4d069be391f7f337cf4e",
      "fd9a57ebe5f4447db7bca336a98b6206",
      "39e079a5ec92411aa0702b4a67795491",
      "64dd9822d85d4c50a9575a9edd28d1ba",
      "b6b9818462864633ae76b8f27b8991f6",
      "a0d2f412442543e59c4c75661e806c5b",
      "4e0d8b04971748b5a1f983c1e692e333",
      "3c7ca00117ac4a92a47d771b62305fdf",
      "e30cd91edc5b4a859527b67bb2b96232",
      "92a0e7e8cf4446dba0e8a3cdb5537604",
      "4a8827507c424c1e80182591ca20f43a",
      "a75c775432ee44adbade5b6ceff834d2",
      "687ea855e8024a3b932e26c0d992e90e",
      "1112aae5072e45f19ce27b3a379a578d",
      "0705eda6424d4291b2f789d8d84e1e60",
      "39b01a5f0ad746babc11509feb4c7faa",
      "238cd85a4ba244b98c831388a2e98471",
      "01e04a8ab038463c9a6825cdf954bea6",
      "8a2af88c686a44b5a1afe01e87a9a7b3",
      "71b086e93f514a1dba684921388d2008",
      "981b94961ed642e3a7b1222b86365a98",
      "4e1e1e2a0f24423f9f68e4d9fd9e5e0c",
      "a60d84b8f51145ff8ba59e0784789f0f",
      "a80435d0662a4d36b3bdc3879e71265e",
      "b942884eb69d4f83b6688ff845b97b90",
      "a7b25b3815e948a0ab40f8e52e981316",
      "1f4a1b2a68fd4f70811e56bf7a815a89",
      "99cb7ad2c3144e7594df51eeb09be5aa",
      "ca3adf3ae4ca4481a4349b437a90de6d",
      "e7ec5bcbf80c467582d7cc4f503e62f2",
      "7251d3839b8d475689d9d5089e4be718",
      "4080c8da1f3b444d92d77494842a828a",
      "d42638160dae462bb0b3789883301e3c",
      "77c8e567112544ba90e2ad87375a2bfc",
      "d4e2a2a4a5e34693bb377e335968e1ed",
      "a367d69392724a4997b7ac8dfc05eed1",
      "e3139b34dcac4d5da4b3a656c515e31f",
      "646b2d8a06d6453eb5fbb3e6d6651d60",
      "a421bf0722344153b02f7a870aaa3d9f",
      "81e7738253124fea8001cffe3fe9f39f",
      "a5363c2359c94df59c1b8540035a852e",
      "047cfbaf5d70441eb6d40c095f461571",
      "753e0cb711bb40c6b7c06611ee1edbc6",
      "706c20b96f0542c2a200d8b15c6e0a48",
      "fdb6362ab741468ebd89777275d96248",
      "4198d3ce4700419da49da325e1bc8c8f",
      "bcba87f10f8a41409a706973a0f43a9e",
      "fc76d46b58dc4aa39e16c7691247179b",
      "3f6b9fb98d484764845503ddee257c2e",
      "2466836fc5e940b79d21b94445fd89a8",
      "8c9cf846d84949cb8219a288a9245307",
      "e7bdc0896fae4f29b3c59aae34671c21",
      "d55a88aae1704853a4e85f1069008153",
      "57d54cb1bb624843b2ece265108e6de7",
      "661b6fd351cc41eb9d588ca6ddd4f198",
      "27cb14e4ad8b4ba3a1638eb3c033b455",
      "b5b6ccc68fbe416a9e451db98d1f5645",
      "ddccdaecaf304c3f8e8fd3cfdfbe0622",
      "35d12b3872364b31aac9035ea4fa5869",
      "c3d8eac9c6504c2ea17d3a3e88d8bc92",
      "8aa1fd0660214b05aeaf263d761eb5a5",
      "097fd8a8383c4ec29d659a17d472135e",
      "7afc96d9ea86458e91052c239841049d",
      "e5c3efbca2414a9088b1eac6e1c99c7d",
      "c3e53e495000454797dc59f273ce96d3",
      "588879bcc0f8495da81c5128fcd27ae5",
      "4e917807769c4f3abff60fb412cccdd7",
      "19e19e727821443cb392c2e4c015ee7c",
      "081db1e1831d419895f7fa8c2c7a19f6",
      "f492cef4e7054035a9603c8ffa3d7ae0",
      "f2dd67436da84970a74fbb835569aefd",
      "7c2923cd93dc479eb565606183bea37d",
      "58de57bbf8a244bab5ce12ac6b6f0554",
      "b42e9c4bdc1c4fc3a47c0fc4099afd52",
      "a39c2b3622fb473fb5b4d65730123bfb",
      "107ac78dbdc748d6a75110570cd8dee1",
      "47436e0b97bd4d3d9c48ecf254df8fb6",
      "564c78116e4b4bbb88f683f9ebc24e74",
      "7006526bc4c84d9fb3db84b7e82d00a0",
      "a4b008f25cbd445482609f3a7ec4f1cf",
      "c2008a9ad71f4fd386dd130d78ba8cf4",
      "cce642bee264475b97b16457e5d5604b",
      "5a49176ca3db401e94e81d6988961b45",
      "878df6f9030542acb6cb23d26eba4c82",
      "0a7a3050289944eb89e388908493cb8f",
      "66b64802bd4c466da8a414e4e320a0f6",
      "4351328c1f0b4e8180d95dd0648a331b",
      "c6c0a6de2fca4dec8b5446f08f729c84",
      "f1a90bdc7c644d7b984bff95ce39e036",
      "edbcb1a7d801492085dc4e2f802e8600",
      "bd707dc26346405a8f668ed2132140fd",
      "1b974430b3ed4933bddd1d2a847e7983",
      "6cc5d9dcba2e4a04adc862c5d3c79a95",
      "bacc89b89c00477ab6ceeab503334bc6",
      "5925ed1a81794510a705c038dd292009",
      "cb4d1ed8bdfd492b95a00fc09eddc00e",
      "168386d266124f0dae88cce2f6aff33f",
      "912d5211d4ab4dec914287fdf93687ae",
      "92ab5eb687dd4823b390ebf349e1d5df",
      "ab47ede749c34acdae0506a29065cf6a",
      "87d7a5ebb7fa405283e4867c83636670",
      "4cc4da7aa33c4867be5f2e00c2cd9e1d",
      "3d8a98c716734971bb2345fe576c5bb4",
      "e28728b7bf184955b9993a2c920b0a7d",
      "c62ef2292e6f4cde80e72fa5210db849",
      "830032191590440abd666c348f81169c",
      "b6c1bf4ecaae40639c56a1fe0e601546",
      "36819c6eb1e848ef89ad1bbf776e9b39",
      "fd2450318f864a38ab4162e52ec2314a",
      "3a3fa91e8be244909ca8972c72832764",
      "35066854dd5e4d8bb41f72b823491719",
      "4f01aaa0c04849f58aa59417bcf73207",
      "02ae0ff6b1e64138aed3579fb2c13f3a",
      "e799b4bde6c24b799f558d526ba0a34e",
      "388f901a7220460abe0317f89a8eb58e",
      "303d2c7808824bbab4305f3a975081ca",
      "26417e15891c40f0b5f58e611bbac15f",
      "29a3b4cd0683424690f212192adaa5ba",
      "4c8a137f745645ba941e3d81e0f66fac",
      "805686f63099444ea8b77542149c49c7",
      "c5b31e238b144200956bb6a49ecc90b3",
      "4b05c9ba3ae6476582b217df606dd838",
      "3ed5523d64ee4ce5b556253b14de6a1e",
      "39feb4a0b6e24f96a94028b35d84f32c",
      "7a734589278d4050be57b6138bb8b376",
      "66b8a432646b4db0b43ef4e8b6abd16b",
      "d101adf928184d54b1672ebabb880964",
      "89860ab5865941129eb00defd3a3acdb",
      "6cb78f35ee2c49e68c83e1237f48dd85",
      "b2d5fffb66974fd0b455b567461f468a",
      "14a295326fbd419bad3e820d2e9eea31",
      "9e2a20c5e7b04be284e4ee2c5d4899f7",
      "69d7ea05f9c5438f88bebdda9e512b21",
      "386cd3a15e25434f93afb1a227e0f85f",
      "6c754ed60c3b45a49203d5cef3350735",
      "9b770632f1f24103bff0f256aa654759",
      "3944b44ed11841208432b9d344298fc2",
      "f9519e59d41d487089c110bf0602b516",
      "02838a3ed27a4aa2a85ab21acb803afb",
      "684ca6b3f5a949abb3d6f7583e2b0fad",
      "4ec7f55ae546442eaef872eff7cb6bb1",
      "5e2f008d5d4e4464a93cf764ef853fbf",
      "22d78cd940714f1484fab8f00354c170",
      "f3fb1fd3ca3a4a74ac0f1a411e534d5d",
      "14f38e4d1dfb4a9dbc6e6598a6ad8817",
      "a3f045f46c814a59ab40d90ff7227494",
      "f73508ddc3e64457807ab22964f60755",
      "a37ea2fe2d5e4d8287f697a06a923e85",
      "e76a19625cea4b94bf26ea3405c6ffee",
      "3a78e7fc716c4433bab29e115c58638e",
      "26cda2bfdb944b3596a3d378e735b06f",
      "ee252f618cd741fb9f809d7935b96fde",
      "2cdf2583e3ea4be3b4c906e742df6293",
      "4e116dec624145fba823f92876aef3e5",
      "a58fc437e25d40a784f56cf8a49578eb",
      "3d80f17b608e492289be2fb6fa48237b",
      "9893979d08f0425d950a3f7d6d78e3b3",
      "085fc694cd36430499c79723a4ed4ba2",
      "3c53842b88ca40978ffe41fe74704887",
      "78dc5a8383194cd4a8c94618d36bca10",
      "d6844201a64845a08cfc1056480826e8",
      "b566001aabe44942901acadc25c65221",
      "fdfeaae1e38b42368d352450c39914c9",
      "f36c5818e6304fe1bd8f3117761fff2f",
      "11ed2ffe51de48c0ad35cad776932ff9",
      "d51138098ab746d1bd5e380b3c6f0a18",
      "74b521595d1448a9a018a9fb45e4c6e3",
      "1a9cc507b6f645b9a1c34dcf43d66a6f",
      "221ec9a2b0524a97881ecf9f6c46f34a",
      "df505a5bc3924f05a5333de87c913efa",
      "e5d92baa5c8f4d1eb6cbc8626be502a5",
      "3255a018a00c4c829db373fb7a8aa690",
      "b62afb69109f4e0080bb63169d0307c2",
      "7c1da75469ca4d228392423f1504a673",
      "f5f25341a9c143248bf1f2c3d3ec8a55",
      "674593ad4be14d10a2919ba694aa5c48",
      "02e0c43b44df40549e0f9be3fbec6245",
      "697b4c05c9ea423e8e470918f63d1026",
      "9562642f53a0414e8298615e5506dc47",
      "c9f6da455311448db83f9ee9873d85a7",
      "9d82e976abf946a882e805a435c7410d",
      "b9c3fd15d34f4c2fa51b5162d49a79e6",
      "24bcc0fc4cf14da7a119cfb12352a151",
      "bb7dc44907fe4c70874a8c5ee8608408",
      "6d47e3ef768140b7b659d85e98d8f039",
      "5892465320b545f3b6d1d1e761b0e44c",
      "aca191091a4745e1a8f179ada63bf53a",
      "57d6cf7856ee4e6585450811b6497d2a",
      "3b0eebb82a294bd89f41d44c940a1e46",
      "ada36b49f94e41e8864955be44411195",
      "58e44cc484b44782b4195beaf60716db",
      "43e3dafc13cd43cb87b6e0f87776dd62",
      "fad9b9c99d7343f798968f8d32e0e4a9",
      "ab93c1450c9a4171885e2e25d29e74c8",
      "1bed921bf9a94fa78e60807131db090a",
      "95ba623c811d42b6976ee95494b73841",
      "5de3ee8db67e45d899bb9c70688ba62f",
      "f591c9ca4643441ebebf79b8b9cf1391",
      "d6db01f1e1f94c85a8dc883a450290ce",
      "cd7d42022d2f49c59134d32f6972033a",
      "691bffce69524fe39699aee88909577c",
      "569c253db5aa43f29b148915901c82ac",
      "700850e109bb466b9724578fb339eaef",
      "69dc87b9b67442c08dc66711e4000925",
      "d6833c9e00a64309acd4479dfbd8123f",
      "24ebf6db9aa0468e809d267f07b1911c",
      "4aae74fb73614b39b1e3737cd0976952",
      "619f5f6f3e8e4b8d96ee5c1bc7a06856",
      "a1c5e29f4fbd49f8877fffe31da0cc2f",
      "d37f54d598ae4a9a83d5c5610447f234",
      "ffe2a64063654a7a96e54c14595a7295",
      "dbf9ef647c7a4a84b9f538c2b03bd977",
      "aad17c8abfb34dcebd335282d8314e8a",
      "e7ec4a689c8d479cb8ef677707686b4e",
      "b315d85a825b4a7b93921c942aa88e91",
      "45bd922e86d64414885ea8cd314e5154",
      "f0a98655cf304154a276df2a2976acb2",
      "7a1d114a80c64f33a15152381b18f1a4",
      "bbd96cc033d1454db0c8589615c06678",
      "13c7a95c41c94a9dad93606e5a7965b0",
      "8bb5ad9afe81428fb8e8232b6edd2ade",
      "b8a88258100443d7b3a219cee96963c0",
      "415abb57fe0347319a51dcb21d8c153f",
      "7f9c984b092b4ca2b7b990bcf0791252",
      "3d88a6e2781349fe86b41ee93d62ebf7",
      "65d3da57ad244a19bd2889b2539c47b7",
      "83fa293cd1a741afb82a5e0b1f82dff4",
      "edd0c457f0b64eb185460b79788127c8",
      "29acf93ebab741cbbc0107f679979775",
      "f918b065ae7d4e4c85b748896257daa5",
      "12c29a8fddd34d47ba11c57d84ad1be5",
      "8261f4283d834124a650c9d5ff1fae0d",
      "a59f9df86b58453fac398c6a015b0cd3",
      "f8239a2e130344c6bd68ef8373405218",
      "60a330d3d587442c8ba8e7391bc0f3f5",
      "3170d514831e45f8bbe0ad82b0ce9cc9",
      "e2fa3d59f4a94124b210d4f17da68992",
      "328a8bbb28d74a9ba84abebf2325ed27",
      "29a2a33505824531af7174362867fa66",
      "a61d389bdf374a639adb71bdb235a130",
      "0346240f260c40f3b88ca3f71764a11e",
      "c02ce282b2724d7dbf44f13195e7953e",
      "5dedd51f561c4005bbcb8fa078aa6da3",
      "9bc1e39cf2e143789bd2fcd39d36639c",
      "1cd8646394584fb987172c397ce1fe4d",
      "e63ee7ebf24a4fbe931ac53b63e0d23a",
      "2cd344e6c2254181b0c93204a491f1b2",
      "40d9f42df3564363998915c55513fd70",
      "a2daf705e7fa4bae9aad29ea6b4703f8",
      "40407a087e514c54b6c2c3c2605cac31",
      "6b82d77c9e7d4661a890ff9f5efe52ca",
      "e3d51df7bec645408316de803217661b",
      "13f71bfbd53e4434984baf9bae27a5ff",
      "291993101cb249a8bfac931eb91ed0be",
      "d77fb1e0dd0c47df87f7c42db6b52296",
      "ea3fc668cc094f2c993dfefd736f671b",
      "e0c1ada1dc774ca8824fe75f3b8a79a5",
      "bc1f558165b54d2eae354154e3ece4c3",
      "746ee96563fc410a9fc7728501b35346",
      "47ae5b667c8a45508b2a27f64c2bcd70",
      "9ec5e22a907343a6989d31ea2383eec3",
      "ebe3be9061c74bf7b6270aaa69dd5dfe",
      "42af3e0035f54bbd818710d5af492fe9",
      "0e70dcf732e54e4fafa25bee4b0cc960",
      "8e5e2431275a40c0851973ffb124b98a",
      "2aad2d25f5514f7bb442768b7ed20d64",
      "8af4038a0b854f1fa7a590de32ffa463",
      "d0b6d257887c433ca9a1ac9d0791daf8",
      "dc9a18f62fcc4645b737b38b4ce218de",
      "1af4873878944ff98444c4123c64f988",
      "3277b03969004ffbad062c44d6f76c99",
      "04dbc46f51644572b626ded2bd83d393",
      "516a9aed02fb4134b0d628be183a8260",
      "2f97c4631fe148f99741c48da6e495d7",
      "9b12a2c321334dc4a1dc764e05112763",
      "a554f8d65e5d4133a424548476547556",
      "0b16c107d0d94ed3ad9a200e727a3360",
      "06653d37b90a4077b24155b68ec8186b",
      "5a04f438476d42df96bbe78bcaf48b6d",
      "93f84a2e84a3436990e27ed9bfe85fb6",
      "bc874e529ee4466cb79b4e49d565e6f4",
      "eb80911884ee4b4f9d8dd55c0da248fa",
      "0369e62b7fad481b8c7a8b87ae14b20d",
      "e693323850874ee39862651ffecdcbca",
      "3ff0309aa5a94507a19c45a683ccdc7d",
      "02e08c77923c4d94acf89fb46af39ce4",
      "0b2af852b5474469823115739d3d2b48",
      "170f2c379c304925983f377f4a633364",
      "0ecf6a8a693a4d1392eabafce46bb9f9",
      "dc3c30aee630495792631b7536dcd5f8",
      "fc6b399489604110acc0968c18581450",
      "b29d889ac52449f3b3c87b15cc4d4124",
      "2b426bb7ee184b7aa637489f221fd476",
      "08eb2c7b5ca04bfc8b9f7e32a356f270",
      "0228fb09a4d24a6a8399d1a99198499f",
      "5d147e8da06d4a0c9bfbe3200c84400f",
      "cd55ed31fb0947d084f09d7de35fcabd",
      "7304f63294314e7b88ea2bcbf769bcf7",
      "35db548532754a8290123e015d19932a",
      "8c30efad44a34c9c80a0ee7b7915e3a3",
      "cbaaeb2613af4b9aa81a370c044e3d26",
      "b485854a785149c8b29471f2af257d77",
      "d5c229c98b2d48079960f0b29e506348",
      "b69a79ad3b274a28aa24b009911eba43",
      "23e913d9015a4a649ab9b9288567b72b",
      "54fe4d891e6849b0a567a41b837e68ec",
      "6d7a5bd4ca2c432db244a425b6a2e2a2",
      "6229628b922f45c28ed47a89b14a4286",
      "6964c88bc4294722afb191dbf2a06533",
      "50e46c92e92c49f1b946263e9d953292",
      "8aff099fa3654d3e815dd3f5cd32ce70",
      "570e471a99554f3b89470a8d52b63316",
      "0acdd974f79143fcaa4d38583ddf2881",
      "f570481188f147fe95ed2153320a5b76",
      "ca227acd4d9b4608a405996f59907506",
      "263779624e444a4aa8ee3379afab7723",
      "66f04787dbe846f4a0182f103a5b0d2c",
      "830e81c9b2d74d3ea23bd04fdb37482d",
      "97d422c61c49402e95881190ddc07927",
      "edaecd9c80c241959ed6be28ae3976ef",
      "924d056d27394a41b410a8a848bb1153",
      "ae1e5c24d3514d28b15be2cc03c41be9",
      "aac2b67d363442dcbc7dd723f431d435",
      "c684b1b0cedf427daecca63ac44df213",
      "4daae3737fec48558ff49f1535a98495",
      "1d0cbdcf850842a0b10346ff570aa490",
      "b09308939f9f4dc98c1c3bf249181945",
      "ee4adda7366344b29c8c64c0d5043c34",
      "012ada3b242e49d0b4487b6a6f2cc72c",
      "bb8205e3e2474410ae8548d9e4429810",
      "c9a5a9b04bb6451b97160adc45e2d964",
      "611633d16a6c4b019191bd5d1ee73ce2",
      "b8940c6f6b3d4dbcb8d16634b5cf55a9",
      "7286e9e866fc4c93bc132473515c8813",
      "6d8c7afe7d444d48bbfabf1619f7d086",
      "348fca9f99354253b3728a5d8ee75cf5",
      "c2ea3f4c5a0a48099c2deaff74ad4f63",
      "b2004fb9e3524e739320ac63b42f549e",
      "f6830942fef640f6895215554015964b",
      "8b69e9ba488a46ea99400581e6808b80",
      "4ad9984b9d1b450aa7ae0f75f8dc6bd7",
      "f3ccfb39240e4718b4245d6ade6b9941",
      "2bb23474a95a485fb6f8323d281c3150",
      "42ca469b15244a869cee3ea7e0a3d091",
      "8017d9ffa8674cc0bb8550b2a6356a00",
      "c241a836882944a09f2cd53441d5139a",
      "1d41a4b717e34e959f939ea087a5cb03",
      "82b8e5a8e7514aee8c8a866781b3ab21",
      "fb7ba632df94442eb778222f2f7a73ad",
      "12feb93e1cbc4338ba60291b51bf5154",
      "b2e88d8e63e14458b0d9c591d005d139",
      "4b4f16c65df748aebcdf64dfe5c469e1",
      "39f8a4294af64e6d9892b85dc67e6def",
      "a13ef974f8644c17822a0d0d936ea34e",
      "6498cb618a1849f0803c5b23c1d14d09",
      "482448bb021842fdb7486a1f30be069d",
      "56731b2341bb4a39afbcadac69d70641",
      "0cf5816ed9424e8ea1a496424adc68eb",
      "d19b0f1c9d634fa1bee0049753ae5646",
      "28acc60f49b44e8ebba42d53c461e751",
      "84412c3efb8942998ed4b27672224980",
      "c88a3826733f4bcf96cab150748e9ed8",
      "f2985c58fee347c8a909dcf01cac86cc",
      "9c7dde5c46f44842967c0628b71a0a7c",
      "bba0df3d7d904d3b9447437e86bbe432",
      "6f36319514f64735af68ea357ad0083d",
      "ec9a28d4f4e24c46bc5254f89e87e318",
      "fb6ea994d9024f0c95015e471d7ba414",
      "2a9d9bf24ddc424fa2520c578c6c6bf3",
      "954e03ab94f649a8926ea859d13729bd",
      "8e17a448be0c46f88fc7aa2d9df53968",
      "bb3f6bf615924c6ca591669916a8b3d0",
      "dd80d57049ce42a4a35cc781cf78f67a",
      "52e38d86102546d6b8588c3439c07923",
      "6325074f4db946deb11c251b94ff23be",
      "1a7c05dadde94d4d8d419fbd8698003d",
      "e912b9a69fdb42b391ea8a4936bd9c27",
      "c06909f4a9574391b5d48bce4cf4217e",
      "73dfe06911624791941742f74130119b",
      "b15e59e2242d436e8112dc3926b8e73f",
      "76f4387a57e545b3a8f51312b4d17d93",
      "3f0d3761991541e1a948057bf9ef0d25",
      "eb1138fb62404d03afb48010af56c8e2",
      "da91fdc57f254c968ad24f79180959e9",
      "a72bccb9179646b5acab4be93e80e2b6",
      "4c7bfaa173b34fbaaa6d68746db0ac18",
      "aa2b896ea12e4cfa820dc4f0d397a8fb",
      "df9f64958bc14033bc5d4bd22d75d951",
      "3ad1b5d5ac1a423f9192c5871841dcf0",
      "30cd4af92a354dd78281156851fa1b14",
      "1088fba3b74344f4bb8c88868aa49012",
      "31fdbebc0e7c478eb66e69acb00692c7",
      "1350c09448f04db193b298d675207d1c",
      "067f0f652bd54029bfebafd0a4852e08",
      "917453b8f8e74bc98dbe90ab3945a819",
      "caf1ac018ad64bd6b233475eb2b60026",
      "649990e7d6944f68a64a59055a250de9",
      "de25ee7fa624426da08963711bde5fd7",
      "6699a053c05f4306b9abd7a9b53a4271",
      "0d92e3625224442d9e0479dc0cda490c",
      "08f17453e3824a4f9f7956a06d7af9b3",
      "243aeb22731d400093b17a1f1d6cae3a",
      "9917d66ca0cd413e939c00108743071f",
      "1346aeb62652471e9597f45f4afe3065",
      "ad852be09c084ba79a7ec32abb9d1b03",
      "3d5b3fd1b24d401e95910f224b014f59",
      "00701a1997624ccdbb6d4618a180ddf7",
      "6062d2bf141f43cfa1f944fb3aaa274a",
      "56c1ffeb4c38463c9dacbc521d5b058d",
      "b173c76a94f34d53832fcfcbfa386e68",
      "c80467a524d54a73968fdd2192320fb5",
      "6903ab86471546e5879f12996515084b",
      "e47ac8bfc2b24d9db7213878a2217156",
      "ef938d8ecb4d4157865ba6ade6d4adb5",
      "f86b3af211d145e59b4117c49cd6a3e4",
      "24cd3110d33344afa8f865abcb17ebef",
      "b9a13b40983543ea8c66ed748a6dad52",
      "c0b164e8208f484d9738bb2e003967f6",
      "450e8e4257af4750907726e9ce60dec7",
      "ffcc69d1d8014a8789e637ed82f03acd",
      "e00e7535d9274e8789022948f2f1893a",
      "aeae9a825bfa494f9e950c7adaff2889",
      "b7d84b41d26649d299d9acffa07cde62",
      "142d19a1acd34447a1f8b8e15b9dfff9",
      "e49da8ed220240bd8ccbb1ff4300ad4b",
      "54f004d40f064246b39d0ed79cefcfa1",
      "ad654ee75cb24e3097dd766eb9560607",
      "cc74944e7ed944fc8525f802efed9f66",
      "997026ab2d124033a773726e17945ff6",
      "bff065b1ed0e439882a944d496467e2f",
      "8af994c651a940e1b5e425c9daeb9383",
      "e35ded06b3a342018a881a511dea7fdd",
      "82f0d0a49f3d4982977c2b088e879810",
      "a76ea7ef933848c5b7ad18dd11453e5e",
      "07deec861e75488fadbf0fe1781b326f",
      "f46805fae46d40fc81dd55af3c9d7af1",
      "565c22c5d1b14a968ac068e9dba49e6f",
      "f305d98796ec4c97b829cb2569764256",
      "eec60f3247b140849aad979dc9e8fc94",
      "bd598280be814dc88144259399b74b65",
      "5d6d654452f34897b8118aeb8f81e0bc",
      "70fc4278d69446529346b0fe414c0b07",
      "a031728185364650b2862312da3f055c",
      "fb766a6c8f934e9ab49971e8fcbd17d2",
      "1206b900971e41e5a329fa169018b50c",
      "070c053d7e03407fa62c9ecdb9f2d40c",
      "9c3eca9a65d349aba7f650c612b4cd3c",
      "bd276b7ce6424351a334b031a6c9415c",
      "af069e71c7f64e5d9acb1c67fd45daf8",
      "18c4a49e1d0744d8b3295b5cc2c239c4",
      "bf6c7b79336047adb788ab0d0cab56c2",
      "dce7f7efc4a34d16890865602d69a26b",
      "3916b7ef89fc40318254b9fe57ba9351",
      "899b5088fa4647bbbd0805fa7b7b08d8",
      "3efc8b16be834dc2a1c7f9b5c11e79ee",
      "0f6441b56f464582b2c66fb047357a67",
      "1119c3608e29452fb511998c0ac9a427",
      "2a2b702e26de43cfb14b0433509f82dc",
      "7a4a07b3030a4c3e938ccbee3bf4a5cd",
      "842f4715be5a49a0b90111d88ff9b114",
      "a70a0fd5437d408c95dd10b784510d08",
      "97977cd583de4658b5b5367bf4d27f6d",
      "d04979276f354dd8a6cb547c2c802429",
      "b06e3ed7e524466695e8c845620c3992",
      "a43a6bd650aa4d77a58e548c356739c0",
      "92f537d9d5884357bfab74b46b7a7557",
      "f72c68da6e384a9583728c4547ddf112",
      "c9e0bebe492c4871ac9dd4975b349e8b",
      "aed6d6f6645a43049cfe1d0836d48d73",
      "9944572413be4b7da7260cf76f5f1aea",
      "fa57cad574e24090979cb0b95ff6fef5",
      "99e79aa112ed48dab57811ffb0ae7f9a",
      "dc35e88f038445dc92b84d37b317d43f",
      "1c2a7252fc184511b612367a8de8c02a",
      "7c234e5a53254042bc21fef93b91b67e",
      "63d15868f2874c12b8771ea9b935622c",
      "a3e33153316d46bd851576919ad4f26f",
      "aa4f30b9a18349248727a25fcfe006b7",
      "629d7660da54470f9f740b11742f1f8a",
      "76a9324a09df43698d4af76aae63020e",
      "e34cbb7120df4df4852d5352985d4a23",
      "2810daaa12ff4dceb28948f0eab7bc42",
      "f090b044727749719d11d69940d6f49b",
      "1440b57fc0d6408cb7c3c5221b093aed",
      "5dca0e5486554b278923ef77a6667627",
      "5e7eb60c8cec43afaef0479efe39d5ac",
      "a870bb3c903c44b8b1379057e1e090ee",
      "24a44d594025441e9e6d0b369aeade7c",
      "f68e596b45be44f9bd1ea2f8a8fc8837",
      "883e3dc2021f44258432b04346edc025",
      "aaa331f5db5e498eb484179d83f867e2",
      "c5603030dcab48a8be8dbe408506ac0a",
      "6c22d0d5ede74b6b861a8f8498fa3299",
      "b4a6efab7da9428faae785af453e1c36",
      "4e70b1efe52c481686d41c91a58b4b4b",
      "83f8a9b72a064d18b0bdb8a2364bc622",
      "92fbe774ebc34112b802bc7ef7c50c1b",
      "41353b5183df46a6ac9ea6036b8c91d8",
      "3c6744ea65f847fda24ce9281d05a386",
      "0f4bc52572204d9f85aa519529cb26dc",
      "66b398f1b34142d0b1f1ae5520ab246b",
      "2780f9310a9a45abad6cff5a3f45c550",
      "19c31350d3f943c2bcae2b8b578b76dc",
      "9a49ff5721f34be88116115c53883a60",
      "3636cf4493e44906a77c5733c9e21e44",
      "83ace03378a146778cecb9715b2ef1a3",
      "ca95c063827444e9b0e1cb16ab6f7f09",
      "3ab8a229413d4dbab4ddf0c5c191f930",
      "976316ab064a4888991fd5c3dd9781d4",
      "2fbfcc72a1de4cccbb9598ae6f349a5d",
      "be7c7e66aa494b3298b85999d11ccae7",
      "53a8d4bd7e6644c98be4eeac0214c2b5",
      "4681c0b32dcc448fbfb450d312147581",
      "ce7a1839b9854d4b991c115ae5eddf4e",
      "29101e2be12c4b3b8577b6e123b7cb82",
      "89726af8d74d471caab2263ddfd2736f",
      "d7e722fb535c441b86f62ffda0a70a0d",
      "ea6d0e7454c046579cba187b48566892",
      "90088ecfe4a64428bee4a71ab8254e54",
      "c9fd8293740540eb9acd17cc4a5d2f94",
      "d264ba6e1c0149deb354d63fb845686b",
      "14f0dbf3906f44d8b14b26bdb2337c57",
      "6d7c0636bd864ad09a8c88ccb66efbd1",
      "921fb5e6d8f34cfea0b52d07f846374c",
      "a7b54fbf4b024cf38059affd6db72d41",
      "47fbadd3dcd64f1a8009754c2191bb8d",
      "e989fce7c10445eabd906b093cf9b3e3",
      "9ec4c92e44fd4da9afc5c09d8d1eea0a",
      "a9bfed96e18f4bf79cf9e0712c73a202",
      "d5441aeb7fe84dd1b5d5d67e7ff62901",
      "93b4336f2626415589e1889a38507e14",
      "a95af532f89a4c7188cfb4d4ec14b83e",
      "ac62f93407c6463c83d2d0caa2027d3d",
      "99067493afef4b119c5c3d29b6b122c8",
      "9b5c3be159b748d6b1761d6e476201af",
      "3abde1cdd1144a458ddd08be79d9bffb",
      "9457bee7640944f58c5a318f622f1d81",
      "4f9743fa82a24a25b7b9d874b53411e1",
      "fb480a7f5fdb4dbb91a2fc72243240d6",
      "600bf09764fc44deb45712526d162e5c",
      "3a30749dd4384e4596ab147ab6448bb1",
      "1b00e5d451be4452be376169a7e08e56",
      "830cd82858924e4f80fdf9385c8838d2",
      "66c23ec2d2bc40419343e4c8fb7654a0",
      "0843d96e378f4323a11ed33d4f74004f",
      "0fcad141a95249249a0bde12e639820c",
      "d5b99aee0f334b81a576c55863e94883",
      "a8b2341587114d719654dde5d07adc4c",
      "1a2de60474824484a4aea47525fe36d5",
      "4af5b19f17b84549a3ea34b0fb9fbb39",
      "be522d3dfae1431ab3341db9b1cf6624",
      "eba04a0e5d334f9ba1384c5b4e0518c8",
      "7296255f62de4532b5f93999952e0d17",
      "d5a2facddefe4dd7b54834cb123ded4b",
      "a6b8a12f275d42ee9c050b4659c969fb",
      "9280cdec3fcf4eeeaaa31e3b77d27667",
      "c75025be96ff49b2ad4d8c31f7e7e9ed",
      "75018135fd164f18b1c2129e77669df0",
      "18669e1870264125b4e089951dfea2ce",
      "83651a03099e4a81855de7fcd6617220",
      "2decd7fbb9b349a190b4344e41989ffa",
      "37c594eb5dfa4cd8a119e54104c26506",
      "5adf2a79f84744eeb1271b3474bfe726",
      "7905e9d6043d4cafa83fc8c2a5bc63ea",
      "c49d5e9e2a8c47ffbf1622bf340e9ec3",
      "a715d478148643ea9a3ff3c34d7b24ab",
      "77d33ac00e554ce7b532616efdf85cc9",
      "fd7facfad0be46cf8dca85e0baf58d3e",
      "4fa09a4844294358918ac3419751c0a9",
      "24dd7d980b6f48ffa51ea927375e5099",
      "4896066c39a9457c967b337da33c75ad",
      "72d5f94c1a7b4fba80da2bfee1ca91ba",
      "6b36e84f48a14fdea950b0b99d25d7c5",
      "5d54eef63a014872a1a6ccf9a875b1ce",
      "96e1b4b3a86a4d85838ee0ff306f6e82",
      "dc2e5cc56ec640e089be9cca31e16683",
      "b8208af199d54ed68583984c715a41b2",
      "8beed7e3e5874ab4b8b350267b431db0",
      "8296887b5cbe423eb8ad7cc971c0df88",
      "a75b49c7989345999d3b55ff5aaa7d3e",
      "9a63180102264b83b98a6dab7390dc3d",
      "81d7521d1df6456faacee223e20bac57",
      "a3e603243abd40229f10196781cd56b9",
      "8372958ef1b441dda50b7380e659d0f7",
      "f3137f723a90452789d503571248ff9f",
      "b4f93d2964614d1e97afc4a2d18acc54",
      "0d6ebe11e28940bf85940b7432c8f784",
      "9a6b7606516e47b48993a9f25f8525c3",
      "80fe62c87b7840069d93cea7cb6f70e1",
      "97446a84bf8d4f31a603407a09142ab9",
      "3e4bfe2c5a7d4d1d875e9de747aca992",
      "c16b84d1d6054f23a7f6fdb50782e87e",
      "edea387479ed48e58b8d84b06a3d260c",
      "45d768efe12342f7a95ba9353ba60552",
      "ccceb1582b5247349b42e61f0b51bd40",
      "d9d6ba58bf20434eab6b579ab72838c6",
      "c4ba74176f1f45fb8029bc8b309fe903",
      "dcba5f3647da48f6a6d630da56842bf5",
      "45788ecffc3e47f38af6059a122c50d2",
      "e1cf42afd41544258e2b2da0461f8d1c",
      "737ccf54216b48cea4b343c436a06172",
      "a35f85e7d4e240ed87376b2069594f68",
      "bc56ad3b51ff42609ade9887726c8741",
      "6ab2fc9d687c4c2c8a5e540291d759af",
      "803c804dbe604e5ea7ce02b9b71d7a32",
      "d7802605141d47db8b61415ca8fb09e1",
      "2d2d29fce163433b8ede2a6e16289294",
      "a0f58322294e4547a59b549de63d7052",
      "ab7510b29a9d424fa5980bce68098a57",
      "50ed1281db764fd091172e50ed49b66a",
      "996f96d6414b4e2ba891340eb4d6bb84",
      "1c61dff72b1b49f9a81aace2bdc9674d",
      "c9994493796a408cb16aaf23d7809e95",
      "3210bbc3f59c43a8be9747ae8eda1f33",
      "c765f95165984740bdf0f12b5868adfb",
      "77d182e2691349d9b7743f32463dc2b4",
      "3a52b01d3aed4170a1f4657a4bb66852",
      "6749062ca50d4adf84b5cfa03c20fe58",
      "f19b1dc87f62405eb5514a7a610b4a14",
      "c7fcb647539f4ab5b733fee30d498ee3",
      "66e906e72bdd418a83a0ed2e4d06c00a",
      "4a6ab854795544a49a160a48503917e4",
      "3152017ee785495dacea99af0dcdfdf2",
      "042979e2ea154a8f9bd2b98178d95664",
      "d086ca6f325b4b56affb153f5bd84b17",
      "2cee5ca55fc745398203dd0f17986c11",
      "142d8cfd83b24e6e9cd404136218d359",
      "22a040eb6fe046fcb5727db19a0ed3ad",
      "60a99bc367fd48d2a8ba59fb8b2a59f1",
      "94ac350123ca4f8198a88e49a95343b2",
      "bb280d7e0dc94b169dbc430049add059",
      "9e23ffe4f5504bb7b4ccddb5535ab12d",
      "ac8ade9ef4e24adaa03345a0f6dd78ad",
      "a108b6011e6d497eb3dad3d019f154dd",
      "f1f437ee00cd46a58056811ba0c995c7",
      "042fac149f0b4cdba098b0ac3c873d47",
      "edee06cba00a4866a634f21486bf5442",
      "7c3ba18a76fb449ab3d484c323beb69e",
      "7fffa7653ab24ebfb07c97854af09a03",
      "cbaeef02b972463481d0a2c7e7ac8d2b",
      "d8795c69306c4439b67aa0adc894995e",
      "6a5893d9f732477fb3298e96f54cd1b3",
      "169961f7031e4ccfb57a1a7586d065a4",
      "df957a6829554c14a64c493eea569cae",
      "c7db488f79fb49078c8f2b4dbb379221",
      "c70c2bf573ca4e65bb088f40a48d5612",
      "e7f9070aba4d4ff3b4bfe6ac58c67a0d",
      "5648a545b6ce4d18a3dd8ed8f9aafaf3",
      "718a91c02cba4c51a9a9da8fc14a3e81",
      "6ba44a0ab2dd4fbc85849781c1dd0bda",
      "63745c3020b6485b83d483e8dc024dbe",
      "4280c8f543934ce5aa9ca9a25acc4181",
      "5745e439be584300b4170a255ea99722",
      "20368a696eea4683a9b8b31c0811d582",
      "4b4c1252244542bda9dbec26f985d444",
      "7ef20ebec33d4f23add7dd7729306330",
      "946f064f95f54063aa13ceb3ad28a788",
      "99b3d8f745e444d1808004e04a155265",
      "83d3e224edfb4fd6bcdfc7c5b75a9521",
      "fbb570dd903c44aaa7c1c0fcaa1e226d",
      "5fbf64560ae441199ffdf7c60e35b2d9",
      "d34022f74ca9437c8a1f9cb9436b6f29",
      "c81ac6e4f5214aef8ca75d82278dbd6c",
      "fbc4c225a63741528707f46b1f3f807f",
      "bc3fae82a0854afa8cf40437ff591824",
      "d55f89f393d044a4acc918b66c713552",
      "07af874ddc6747139df4cfb4453065a7",
      "0aaaa3449be64b509c57c6c5b4811e89",
      "ece02d2b87c24a60a3125f26fde55490",
      "78e58c9955364873ad9a27a40e7e1de7",
      "78d8beeb5efc46f2bf470fc8dedfd96c",
      "f38269a184db40819b12f32c13003642",
      "464bb11e3838499188719f92c04e2732",
      "9c9dc25253cc460abe6dfa2c2b316d64",
      "e919a6a7c11143b7a5e967343db5bc2f",
      "14c887e39f4a4bc0871134252d10d395",
      "d99ea4a52d8042f6b5c0b665fad05e0d",
      "ebcc6bab4e6342f997ff90af5ce672ec",
      "68d36db7ee1d41a6b531d3dd9c0c2282",
      "a57a5b2a8e6e4088ad652ad47282eda8",
      "84884cb51e124f39bea41c426e42df21",
      "b1cd36b8f3a64c50ac73242c71d322e5",
      "7efcc0eb2f5742948bd33a6b51751e46",
      "1631dd58e7b942b28fb84c7869f3fbdb",
      "44a4d295b80b4ea4995eb38c47f04b23",
      "fca5a54b572941c4b873ae0bbf2ae2a9",
      "4edf377afd934bd099c71f2ec22d0f09",
      "59f7a662c6214d89b9c922a6aa84d6f9",
      "fb1832e08e034c36b15ae67aa0012548",
      "824dd3d140b2418790302366f4259f6f",
      "b7ee27fb176f46549ca999ed4c3f0dd9",
      "83425a8e00fa450ab563cc42535ed160",
      "d28bed05b12b433dbc3b699fc2dfbfc1",
      "28f10c6a46ea4e7d87cfde02752af5f3",
      "357a8fc7609247baa1cc4893879123d0",
      "809f55f1b89744d59ea1b7da8e032993",
      "4752686a44f740b1a93d2799035486b5",
      "fcaa430536fe445ba89d9ffebe6bb263",
      "e1f1184bcf47441884cdad0fe05793b7",
      "f286c9764ea04ab0aabee8c5ce8bcd53",
      "781858ceccac4749b30eb0ccd9fc61ec",
      "caf90db5792e47218f16ac605cfe47f7",
      "0518d3e4839e4d9493dea610a41e52b1",
      "9bf076f1f7fc47db86f7ca1c2efd4452",
      "196e3fa0fc3f46b7930b1676098ccfca",
      "02cf0420d28e44a49136c635d8e509cc",
      "2a316bdec5d34901b5530b56964e5b2b",
      "179aa39a341e4cbc8c0080c106dca8da",
      "fe3f7e4aca9a40cbaae7ac962e71326e",
      "3ff476dcec5a44d6a05d2627056b6af4",
      "0efe8e1ab5e141a4ae4fcfb405f89970",
      "66613e97dd774ecabe10b0c8073f46b3",
      "22f0c62084034a54878ffe7433d21de8",
      "87e72741b6b740ffba1c88b8040d4dca",
      "f18ccca0e98d42aa8ea4d5c8882df078",
      "6fdb3a84033c489ab545ed3565c71a4d",
      "28c31ac821bc4f8db67790ae24b50755",
      "391bd0d227a745028b18e78817157daa",
      "a07b157fd2e14d5aad28b6fa60914f7f",
      "a12410f58577410e9e0aa9c3854bea8b",
      "ae3fb674e8df4138bb4c52027edcbbf9",
      "136a99472eb34d5b8b32af3b09a82783",
      "a0dccda15f534e9caafb849d75c1b9aa",
      "a2e9109ef6014b6087546c882a2a405f",
      "74e2ab8378c74797bdffce45e23344f9",
      "b6052ba1b9484885a47c00fb888c36d1",
      "dce484535fef432cb3daefc0b448bb4f",
      "1d35a03b7d5e4c0781cfafcaa9bc45f8",
      "89a4ca38c44c4fe29531d23c7c9c63ef",
      "7d4ec4b7f98a4f5f8a6ade3285f65d16",
      "dcf4e74ee12143a989c06bd38b2e6d90",
      "47aa2698635f43acad6f24b0b8967bdd",
      "9931e8f0aa8740bcb45006108113f46e",
      "bf6cab5e6da44016beaf2460ce3e3f27",
      "2781506d8dd844299eca3f8785e2f969",
      "52581ef55baa4d6a968e484ab4d835b1",
      "fbbd0e8e1621460d86587aef6b37f47f",
      "8c1bac7af1e345c78ee820ec87e41ed0",
      "456ae51bddcb4273a4d8f4e167b1e3e6",
      "6ebbc288431d4d21889205d4446891e1",
      "8b86aaa217bf4a74805a7eff68767241",
      "600a89b814434fb99f1dd6a718c82937",
      "2ee6a05c383e40d38fa204d4e68f7a79",
      "5111815ac0fd4a16937cc1fbbda97e99",
      "02deead6986749769bf626ef01666eb3",
      "87cf713f464a418ab3c70bfc173d24a5",
      "4396b03ce92a4dbe876be471244a3b86",
      "5d15c8634272433f839f747ae59217de",
      "66336ab3970b468894afbc3f6fd61507",
      "c691d57a535c423db109bb18a6d88bfa",
      "41720fe3882c499180f9afd4341f6985",
      "74d249fa27fb4bb7bc11fcfb2607b738",
      "32b75225a77e4c74b6dbc737074e1d86",
      "ff7a6e5e92f1418988ee7c2e4f40a490",
      "e41c940f8663422ba02ea0cb4813bfe5",
      "b0d4dcaf3f584b1697e0a8e781e4bfc8",
      "2b85cf53763d42d393c54993b6929b96",
      "c65c2e9929314aa6b019a23fddc6e10b",
      "b3ccb7977b48400ebf29198be8b88d6e",
      "d4935a62032948e4b408c7c532750bc9",
      "fd6c98e5b84843a8a56dbe297f22fb2b",
      "670f2ef141e04714bc1035f25bc5f40d",
      "969e48e7cb404e48b6c0fc356258f8f1",
      "9008702a29c34ef3a44c28def96de275",
      "914ac6d846134bbd87b583bbf4855373",
      "e0bf60e0b3514ab4a5a0b58cea5f22b5",
      "1a74022c36b544fc88e4d65c5978e73d",
      "83c0827082c84036b0cf85489d3f4251",
      "02f60aab0e3f451294d863b88b33c9bc",
      "1a97478bb51346c9b3dca97294a213a7",
      "fe1941246e254961b79bbb4925d2f977",
      "a2e25d3993fe4a31b0f0301a7d90d959",
      "635f0e5353144a9a8b92aa39c1f5a80e",
      "4a3e673bf65b40179e5fa6010fabbb47",
      "594cea2d1a764070a6bb1b44ac87c5bf",
      "a2f4738c5b0f4ad888827d08af924256",
      "ddb69f5dd77747568ecb22c126cf6426",
      "e9c16d1c2bdf4557982b2be5d62c8e94",
      "ec4c2ab698b649d999943531ac83779a",
      "708ff7b4bf264e16b3d26eb041506542",
      "369672170be14e4b8a90b7ca5c45ca1b",
      "78c3ec24787a4de1be166b73ab597d03",
      "2c7fddf0414740c29b00e016cb1aa1a9",
      "d09f166332ae4aa59482c8c2031a1f8a",
      "3b55f14e6f8c40abbfde8c9a230c2a23",
      "22c1a0efaa7d4a06bff53eed180528a0",
      "f77c8f5818ab45f4aa3bde5edba34cca",
      "a048f6db1906423ab6c298dcde1e16f0",
      "1ea5c7b2aa3c4c10ae66e9ee282060c6",
      "2749cde71778455bb88517675c169f7f",
      "34433764b43946acb2394d67c49dce2f",
      "d912a445457b49abaf9142710be77640",
      "a000d57c165a405094d2ffc90fc10dbd",
      "b873660b67a844d98093da8c107e8669",
      "362864d68c1f4b31bacc64eb37650c1a",
      "e985725eca074764a3225a9d1a52cfbf",
      "ba7ae1597a7843068839a9a49957aac7",
      "980b5812d7274c56a0df901bd4a433b0",
      "26840392f840426bbd82cebef6b1d659",
      "5dea393e472943ad83e6ba709203e0c8",
      "1d6e675fcbd446cc9a7578e964178186",
      "ff10c31f6a9e48c2bb30579308eaf06e",
      "2a1f85fc22d34531896864e073d45382",
      "9c0dd5ea36374922a0bef28ab984eb76",
      "1de77c4bb4c540e39f8561fcdc3a4c09",
      "1682a55d2f8845e7a3434ca50678e8d2",
      "90b30d4cc5fd4db6ae4114ef83660b7e",
      "76da03ebccf54be2ae2d6ca07eea61dc",
      "e218f70517b74d59a88953d440422792",
      "6232c00ea6c54558bf1ad3f3da4a0688",
      "1b24f7f3253d4ca38bca3080d53aaaea",
      "d1afbc898d5c4afe8fd307b2d394e340",
      "e6ad9a8acb424f698a3a424e30ed65c2",
      "e51f748fee924bbc9429ff48cee2f648",
      "1c795d810fb84cdebb793670aa135c6d",
      "784cb85b194c48bc8497486c72426acd",
      "31625fe3be954cbeb6964df668bc0c8c",
      "021cf8450e2d4fd5a1d2764f3cbc7ed3",
      "2b2e0335ed3145268204ce43b7e57ee8",
      "e2a744a0af934a4b9fb5e7639cc46aae",
      "3864568c290646ffa52f128e8a0299e5",
      "4c0a9b1f3dfe47c98e0f62583f5337be",
      "6fc55e490604447aba0f54a2305b2474",
      "ba1850f7836243a5a7c1447324767da3",
      "12a536e6bb704b9d937ac339bfc13895",
      "b2fca51ade114a259079d4c7aea8c6be",
      "bb6cdf3a14ff414e81587e36e527ef24",
      "c23cd94d09244d60a28b677a9c609211",
      "2bca3126ffea44099752a98c2b09414c",
      "512a1b48e53c4fbca66aa1777a47c038",
      "121317963a5b4d8784b20300b434e923",
      "f4b1dfc8c1f846eab8ad58fe642aa4b8",
      "b942edbf437a423193d61ed78df0005d",
      "0b1b34fbf0c24189b9777208e1da39c2",
      "2febed7496cc4b60a46fdbd4216d5bdf",
      "86d848ff7092442ea628300a7a878436",
      "e8c72f7fa96e446382381ec5cd6946ad",
      "3e6b5e39810c4b8d8d1a92ee0752b424",
      "9e8f2e5cc2274f0e8afaa4f7849baa8f",
      "9e89b145e7fa4140a202adc3cf0822df",
      "f85fa8cee66e4e76810974cb066f4471",
      "5a9ef87c3f78480786f048d2ad25dc45",
      "a17e3d27a2cc4e139d7b4e18ef95de24",
      "e431f2601c5041568710f7772f004849",
      "0fd1d945d6284d84a8e22ac7691a9f02",
      "c9b7100bc6e142938bfb7d42def78022",
      "16eea8b8de8e4b7fb2756b170a422c8b",
      "283efc6738bf4c0faf498bb03ea54649",
      "44db429110d04286b71136db27117ada",
      "3c69999d87954f2880a588d3e914b067",
      "7357b2624876483fbd04bc67027fe19c",
      "d8accf36874d4420a1c7c4f64c781f58",
      "483f4efeb634481e9f55de6b9d6d3777",
      "0819de090d84445fb1041e2fe9a5d21d",
      "f089a978ffad4380a7176902a52a8877",
      "942d6be1ae2747e38ac1a2f1095d2321",
      "c6aaa8edf51f4e6aa8e0937cc3ff4ebb",
      "449c54f4ff7a4309914d4105849899fc",
      "ea4c0ff6d9d44e308c96163d038fc3e8",
      "9efbf1ee1ad1443198539ab6686333a6",
      "90ccc9c9ba9a456a9fc9c01f9361e4c4",
      "a9b48d46464746459fec1cd5e8b2a5e9",
      "02c59fc966374854a755610ac6e5d68c",
      "220c9c637a48462187487bbc0feb550a",
      "9e62111a4d4a4c92b9c48dfa0d703623",
      "0af99f9f4dd446a4b849d84b5fc64e30",
      "9eceb8941d6f4f738dabe7eb4b573583",
      "b60e349606dd413ca3f3e66add24c8a2",
      "451d31284a304dcc86f9c53324d65df7",
      "bb94ee1aee69426ebb79202324994f1a",
      "94214d1e7f294f9e95e8cabc4aecd1ec",
      "9e8e680edd2f4cb588e4f18ba201fb01",
      "584f1661a2c7490c97be24eb7a01b682",
      "a7d238b6c42a4a60867c4fe83873a8bd",
      "a503caf3da3d4ddc9185bc13f4c619ae",
      "eded97cab22a4032ad23e1b52992c81f",
      "4833e37ffd5a4f6ab3518d312592b100",
      "99cc2750a2d24c3f8e08b51a1e9aa8a6",
      "f907b705366c47b2acb16c4321961359",
      "73dab0279c5d47fd934b9592aa3ab8a4",
      "19872bf5d23849299bba30222a09051d",
      "00139b8cf2d04d02b6761fd65ab23f7b",
      "0b472f99fa6643778cd54065fd09d0a8",
      "7917cc9e4d974bdca5510134e37de5ef",
      "cb7599c04c7d4decbc72106304e0d8e8",
      "f33e465caa9245e095c26e1c54b4b524",
      "98530003b7e640d182bcd52dc405287f",
      "1dbd6e7cb2ac478b96eb899c7b1ffddf",
      "ed973cfe86494f1780facf20f7e701ce",
      "4da866e9ca8b4fc5855a4667cc7abcb6",
      "1b9c43dd43f946f191d84d7b3b53c9b2",
      "5ad8167528aa488da0509116309d317f",
      "30570e0f8f73467aa4a74cf4debd2af7",
      "ba1d2f3763f441f782f2f32bd7017195",
      "7d4bb04d08404e33bdc83873f17d918a",
      "860f15d31163480cb5289cf4d4d5bc04",
      "edf284d1d88c4f789e69965ef8f4c36c",
      "89dbe065a44f41298b73b9dfc3eab16a",
      "de23a0edccb14d30a4fd4cf311672670",
      "ceb2fc172b7d41819f4906bda3f3cffb",
      "29ad9097f83947879a4e447e5ecc4005",
      "c99d0845da8642e1b099cda9504f3320",
      "b85b3071446049b09fde48ab88d0e52c",
      "17408c8d8579444799e055d859aad46a",
      "80af9fe2b162436a8ae0f0b75e6fad00",
      "1c6da66e6dc342d08aeb6da061379461",
      "56e1c983748649fe9fb4c7c523a250c1",
      "42bd6b65cd84430b93aae268896fb671",
      "66f94190bf8544fdaf72d137da64b93a",
      "4a4de083b1b1491493d60498d65da61a",
      "0cd2fb440a9241de98099d2d312be3cf",
      "c1542e4a316b4211a48c3209565fc054",
      "f1bd2124e37346549a94f7d25a52a766",
      "005dccdcef0040cc890ad35d564aa0a3",
      "92eda2ba8d18480088803b679993e52c",
      "f443a6d750804c4180ae021f992e8934",
      "00622cfd9d9b4d918a69b7087682ed8b",
      "6469629655d4429ab80d6c5d3f81919a",
      "b23eb36b413b4cf9839211963c4b49f7",
      "9f3e2f4fe997415dab024c55ddda3c4d",
      "c420e6069a5345a49b451903ab118369",
      "8ea34966643a49cd86fa7bd84e61af4a",
      "713b98b3fe024964978e61b6fffc7bfb",
      "520a06e73cda44c98703f22dda8cccb2",
      "9af3a515024349e18e45a1ca7bdd477c",
      "89a833f965aa4de6a0daee33fe47428d",
      "190122fc847a4a21b7443edc64b802be",
      "979500cb77bc4cf5ab92e16a3460e2b7",
      "901c6082115545a0971443ee87982772",
      "13a0c2f6d22e427daf8a0829505d7e92",
      "0d5fb674b7b8443a877598a4eef29586",
      "4861c3e00f204437b021a74c17b82bd2",
      "fade54fbd424443a980e12d510da8848",
      "e591d06227b84fb49e06eba22984589a",
      "d8bf768fb11c4a2abc618e5c17e7abb5",
      "7f8545a554dc424d9af7f3a9abe603ae",
      "ee463f3b73774466abece8422d38e7be",
      "49008d48fc96482ea03d204bdffb6eb8",
      "b760cd016067438a9b4ceb74c18a86cc",
      "33d0f5acc91f470baa3e5f281449694d",
      "f5adc00cf7f248e6ae816e181b650242",
      "81cf5dc6ad39455aa5edcf6a86927923",
      "54e17e0b222c4624b42044fc3ca964a0",
      "4678d8f22bfe4df8a4a516c8d176c52a",
      "b43d424c71ef4c29b90c8971b86356ac",
      "a407951e98ec48728b8c812b9444669c",
      "d2a0187f9e9e45e9a88e00fc596d01ca",
      "8e93a8c3c98145e59aa52751b1aa997a",
      "d71268c481b64dc2a887e2fa7cecef04",
      "189b59ab96cb4fbbbb23ba82a44530f2",
      "db66583d03b6473eaae56d45fef39355",
      "a05a77ea9c8c499a9a6ba543b13ddf52",
      "1baf260b8a2047c48eb44fb53de9c066",
      "ab7d58899828400982265bb4d6881339",
      "999d401b44964105829aecdbe19ccd97",
      "8a46bf39fa4c44da91e0acf6fb83b5b8",
      "40d6b526d148466e83310569c74fa0b7",
      "933f163fbf5c4309b077dea34c306f6f",
      "e020dc1f11dc4f02b67424eeb7eadbe2",
      "51cbae11a35a4bca925f65c792c83805",
      "54fc4feb4c914caf8097f42faf10a85d",
      "a304a1cd5a6c49a7a289bec33103f243",
      "7a985036565c4dc3847177e153b1f3c1",
      "2cef9fa949dc45a5abd7aa95cfd26e6d",
      "0f12f0ed107449ebb9d85aa126afce60",
      "22c117ef2c1b4395b6616ca72b05c553",
      "58012af9dd9542ec8ac731941111b5bc",
      "175da796f89946ebb688fc4fd29a3422",
      "5ccd8c1123e349ddb9f1dc876e3fb00b",
      "d808930bb2bb4a29bdc7cac8006a1049",
      "8cc9d017fab3455ab30984536c1f4f6c",
      "fc5e58cab274470994e90c8eeade9957",
      "448c713e244e4b558f82a6fd9f820da0",
      "4fb6e7ab6a094123a3db43f6a14fe663",
      "36e6e36a241e41a2b4f1b19da30b2095",
      "7e58293f07014fd08b81b04cd4594885",
      "c62fb6048df64a4484ea1e05a8a0bd55",
      "45b5e3cb4c0e42a4889316f5ca58475d",
      "28e644cb5fc1469987503610f1f1ce34",
      "04a22c9adb584cee89522785dd3326de",
      "9342c8f0bbd145df99c3e4c31052b37e",
      "3b4170c789b14d128692ea9b610c7eeb",
      "49ed1d64a72141cdbf159a17035d8e29",
      "1f5901de12234870971081c57f601c7a",
      "745fee83dad44cc4adf57ebe9607a35d",
      "10c7b8e303de4c59b6886e270e8c8d2a",
      "b55df068cef14e73a80f4ed1d7b8aa9a",
      "c0be5be2d063433cbc6c2cc4be2c4e31",
      "e6451d79d27a4031be8b18ae25014cc3",
      "c05bdb1202344b2e904ed55514cae695",
      "a0adff3a56764355a2256f01f4ee3045",
      "aa42b205feb34ebe9a3b11739a6a9f1d",
      "17752dbe28594e80aca89a8c31a819e4",
      "9dfa4e7697134cdfb976a62106040e71",
      "17ce84959950479989aed7f9895243d5",
      "b295bece5faa4f5abc334bbffc375615",
      "6b2f22d7be10422ab395cef00c6ea12a",
      "2a6661578b0f4dc3bef8a19634a3f19a",
      "11ebd5365c374c4c831c51c6b7bd7fd5",
      "f47febfd1a4d44b49d7cf50ba3514f50",
      "c68695e280984317a18a741fd7d620cf",
      "de2ed8ab604245dda44f0b07e4e53e2e",
      "52181c632a7241708ce4c4588441aec8",
      "657a9a2bad0c4561a59ed7167d44a44e",
      "65670fb336df4087ba0d541be426859d",
      "c2232a83a916489688cbe91c3eadd8e1",
      "b42ab1b1412e43c4b6de28d9c79e5ce1",
      "beefdf735bc04929b2bc23b04d7077e4",
      "75c953f15e7942e39ad2f1b917e70298",
      "df187e4b1b4548f5b555cff9e7a8366e",
      "868b4460d8154e1da19b575b275fa0a1",
      "fa734e586adf4087ac1dd67fef3a9c4c",
      "572d93dde47240d0abdf4383fb9046e9",
      "64f959072c994ea4a6acb80149f2713b",
      "b9741954e6894769beb193664c8136b8",
      "fac9404b212d497cb3e600457c1a6232",
      "1bc3789f44254444a7a89b6a20b63129",
      "7bad372ebb98410cab311ce1c3305129",
      "fa166eb9c71c414aa9eb9b5027c27147",
      "84c03199c7274b9d860aec95dbf68b44",
      "ecf64b8760b3435194ca98f94b917c68",
      "801656da4f9e46daa4c361c89dc4c478",
      "a21a0ab27be741a5a64ba903ad50269f",
      "8b7fe23bb9a643e485efdec2dbc36525",
      "abc2047660e744249bb1f544c2cecce3",
      "55f6b2e190bf41bbae0c8ba5ff5ba94f",
      "93274435a7d24196824e4f8fca56886e",
      "85713766c5b44072aa2e3661fe1aa8ea",
      "0a4f03b335464623958dec24832959c2",
      "17c01e79e49f4bab88eaeeb65257a8ef",
      "483a55fead7843768468040c7385a407",
      "c1c72d2b39a243718897e0531948945e",
      "9aeb23a6446f4aebb907d303c9bb1655",
      "793f8617bc35457c9e23d693ee5cc966",
      "3640734ee1b7418faa485eb4f55c40b5",
      "f59e334b35dd4362ac2b2ea2a9fd6d7e",
      "74214969ebf345ca85fcc160f96af47d",
      "cc75ed8e8e4b4097b441736fd85c940c",
      "573e4f1d12564dd288ff5bdccb4055f5",
      "78836df97bc0442f88c79d9648886d9c",
      "c9519d2e6d3e40968333def7bb45b1a1",
      "7110baf15a314e1bbd0f32d46d46dde0",
      "127f53e1b9e2432bbf11d05c3eb3f23a",
      "92e7d54b4c544670b741b0eaae427364",
      "248de450bdca43c096d7d490eb419618",
      "9db52cab06a245c89b5e6c0906e1fb49",
      "fb0e4c06bf6d44beb5c017b80f2e8135",
      "ef15d428b83544e4ad92fc5170d5870c",
      "c05357c33f6e4c8491673968335e7242",
      "07317ef8e9ea4abca91f528138883091",
      "500b54f076a54c3c9ba5eb4de9dd187a",
      "0ca56545728441759ba0d799a12da73f",
      "c9ed01b3a68543dd8887048b5cfb822a",
      "05b19bf6271d4f898976042e49ce66d5",
      "0489f9eb82634165ab0cc23c2dff14f6",
      "f1a3896c0bd24be9ac641a80461cbfc7",
      "1d4beade100448f4b1056860a2dee834",
      "0fcd2d7e43764570ad118f2cc870d66a",
      "7d93f6a9b7624cb8b023c7cf676efdf7",
      "a9e940f8c7354593a49268523703eff3",
      "e37643d8b1e34a0894db1b0d0ded89a7",
      "ae2022237b2f4e2fa790f7d96a8ca698",
      "63af6f6a54ed4c429de114e64e29a560",
      "3cc55157f9144201b6a8b2cabc34bb94",
      "4616d6f573df42c1a450601ca054c1fd",
      "9a822a84ddf647c983ae630936974072",
      "b8123f8eb9e3470ab0d08b8cef3b2d67",
      "ec54aa0d886142939b1f6beb175888c8",
      "98103ea609014f8a887cd14a4a779a9a",
      "76b642eaa2834f9493e9a66424030d01",
      "e0f44cb450a24bca88b78d6706f4cf67",
      "bd385c0d0ba547aba5e58a12ee193eba",
      "470f3811d38849f3a8064857f0c1765b",
      "45523eb81ef345329a326fb275d3b08f",
      "83929015b436478fb2704bdc387efa35",
      "d4f7e7a17a204c238367168a36a5b8a6",
      "04220143962745eca557bd8f12f7058d",
      "4f052f4b17fc44d1a9195522a2d9392e",
      "e6375eb5ede9475189ee3f825897410f",
      "7550d687262647c0be5c6604c78fa30d",
      "87acbe99bda04109a9feddcce61dd94a",
      "153171fabb2a494881825091671336f4",
      "085aa9518a3849be8dd5a071bda05c91",
      "b152a7ccd6294f03851a865171a299e5",
      "04fe6831feac40908b544845ad1c3fd3",
      "8a3fc24cd8ab49e9a11c05999e47e572",
      "2244b4aaf60546bfa8cea015330c7a51",
      "6a13572342d64bf4b27ed1ef681e9b70",
      "b6561b4a208c4502933a901722c081e6",
      "bfcee07e95284fd680a9747a09f53d8d",
      "0e6661eaef6a458790567026ceb949f5",
      "6e8ed5c3f6634a8fa4cdd48c49bbcdbc",
      "0d8e93412ab0424ca15c86d0b9df794b",
      "02566e98fd1d4dc9b5e33d0de3caf5cb",
      "764b21392a4e439c8d1cff569f8b2749",
      "97b6d9285ff04922804b232e9c9a983b",
      "b4c501e7084348218ec4e666b91da398",
      "18dd01c3cc6f49c59cac1d38cba57fef",
      "28533bdbc7074a6fa54091e02646e170",
      "c4637ce2a69e4f09a996947e52223ace",
      "3ff8d173bcaf4432875c1b13f437610d",
      "e276b67a7d434e0f917276b09676d8a8",
      "f3581e64c0e740ddb63c44fd415e9ab3",
      "4693e5b347f240ab82a74347d0ba4bde",
      "4e3c721f68444e7ea4f9c76b1e4fba4a",
      "d3abc646b6024bf581ec2f7dd267332b",
      "52f5c4b875044977bee3f63001f66dcb",
      "9f20fff774b848218608aade2ae848d1",
      "11189cac139d48ceb2dde41500ed55cc",
      "f25bf3694bc14764a992916505f99fa3",
      "42a5ae1ba73b4d8c92652aab0e1380a2",
      "675dc214a561431090672ed76bc1ecff",
      "aca8ec4e2bda4a488e13331e97c328b4",
      "365d81bb89e34de3a07a346de96f1697",
      "e5668c5a5bd14686b08a91268e9f9a44",
      "4410259ae5b1444cafe80e538bc395c8",
      "0b412711525f4e2aa3fe88a3e4e33433",
      "d33a468469ee4ec4a91ac578fe097916",
      "73cc232a07124ef58cd8fa50d4256649",
      "02e4e56d9a904b8297b20a74113a8f8a",
      "324687b4cd1546da9d30740981d2e0b4",
      "c542a7c84e714904a350714b548f2928",
      "4764e8cd7ef04ae48bcc501c97ba50f2",
      "257fd442350b41959c6fbfc30bc4d30f",
      "77b55e3b7eb3485a83cac544e8d9668d",
      "4e4b7c12c54541ada007f0ce4cdcf643",
      "36e26b3df9714d07a76457c1befa981a",
      "bd141b9ee1df43c1868a5bea88f6325c",
      "e2b7af44fec543d8975ad096619f4eea",
      "4937a6b06abb427aa06ca555e5cc894b",
      "a7637ac0cec540b28b88955f4d0b0d86",
      "1f540e1dd07040c1b864b62a581c147b",
      "111c51d4d9b0487db07c3aab433caaf8",
      "e3c97771cef6456c8cb280bb867171ed",
      "cc41a8a17ca542d2b8ebd8cb4f96f1bb",
      "1ca9c07be10b45fb88c734a4a791a4eb",
      "45cc13e695a84f63ba8118b318d244e4",
      "cfd78578509d431aa88805d6a248722e",
      "8db41110ff1540bc80af5f9039c14db4",
      "c8014ad5c3f3470a9f73a77f60ba7bf9",
      "972a27d5b5ac41239aebe7ee11722063",
      "1130c352a2764e4391c6a2f55b5c5ab3",
      "16552f703a6c4b43b9d4e6e717aa54c9",
      "2e05ae9c7ac64b0a9273de49deabe0af",
      "ce8e1f84d21340fdab5ac6eea248cb04",
      "6614b727f1884f28854d501a365495b9",
      "69d4ad853535425a94e6e809975cf8da",
      "3795278828324a8e99565cad69764e55",
      "383c3d6e250647e689bf69c70b332e07",
      "a937a70c6f394d7aa15482a693932f42",
      "fd4ee82bdc6d4a1e9418720637a87247",
      "5fc64bba87d7434c8a108564d04006ed",
      "8f955256bdb64ad8b7ba0e71d5fc7eba",
      "651093631a964ccf8c3073c8ea2a0816",
      "4e2cccbc3fb8420c972c074ac46b30c7",
      "019b5d1a2c3a4b09ab0fc074238de4dc",
      "2381c83c1fa744a5b619734d4a0716ae",
      "7f0c8728791d444393ce13ec6bae936e",
      "48fd9edde1f64ae8b7196d7522caa685",
      "a1d1a707fc25409197860d2f439412f2",
      "e4e6ccee99fd4f8bb74898a214be20f3",
      "5cd2cafe8958427293083678f64fe4a0",
      "77e3e6c0572f44e697945f76be0fb9dc",
      "4c68758badbe4974b4dc2cf64bf51e9c",
      "e958fdfeaf27429aabdeb31e9ab18f47",
      "82de81047081491285b7a9a4c85d5303",
      "8d306daeb3fe4cc78e089b249f206e0e",
      "75d553411e8448e08d4ff79a15ec2e11",
      "8901d19e10e243d2be807e753339c907",
      "80da7f38b3844c3f874b544ecb8a060e",
      "a1e7dba70b4c4ff596c79dc76666e372",
      "c9145678fdb74ce38328857c5eb6ded2",
      "cb26216c55c24e7f80b7b5df7f39d0e1",
      "318093f026344d9d80aff9ae26c2af41",
      "21e2b77b349e4ca5ac398e804b3995a3",
      "7044ced5c89e466bb088f601daeea7c7",
      "d860db0e2b204672a6f222847ba91f4f",
      "f371a73cbcb34865b934d7a0d8402b3a",
      "7a3c9c32725e4747a0cc1b90fbae43a4",
      "c9858bcdf69b4bc39bfd48e6d7fefdda",
      "a9431e3589784439b2547ffac31568a1",
      "336bc16a3284451badd802a6ee9a6e1e",
      "d5de1017df904fcb8afd3d1277b56caa",
      "f038e923db8042ec94ca623e132b2be1",
      "569cc5084a8847d79c878fac6b22694e",
      "50ba9f93a07e41dbbc4567b7e4135c68",
      "8b0b3e963cf648e1817766e29d2052c3",
      "b15e747e68894d7ba7797a6c7c18c0c1",
      "fc83dd84c2a542069386035eac2e660f",
      "45d93bca1bc8463580c4d5a7eeafae01",
      "26fb6c35a8ea47a58fd469d0fbd86308",
      "39f1c3cbdc7c4adf86e10a9d146ff776",
      "6fc3c9adb91841c785c23984121bb703",
      "ef79062bcb4c404abb9318bcb959d6c5",
      "f18baf6344b444ae9c1a1bedd626cae9",
      "900638c0502c4ac0b07ba950915a82ac",
      "2db7eb099eed4e2fa43ca957f3f50f2b",
      "2d3f997fee184788a16b74d128a48008",
      "a0d4feda038d47169c3743f4dd21f96f",
      "63353aa7b05749e2a97503b34fa8d28a",
      "9eff06c1561340479370cf20bb65dc73",
      "ebeb11a5b5e542aa89e2d263b7f0e3a1",
      "b12edb6dfbed41aea365201f10b73eed",
      "6330b77541634cebab328984587f1b31",
      "97fd7226fb734f54859ef5245edb67a3",
      "032878bd3ba04811acbd2c2a5e30ce26",
      "43917e70c935448eb5c232f2a51251c2",
      "c0b2f2a0ace84ea79d5c6d23c84ebb21",
      "a720d4dc9c774e35868f09560779c43a",
      "9431a810ec3a459cb4ade464be47c18a",
      "ff60780a22664218a70c33497ec6bab4",
      "9749dea2cf9f4ad284d2bdb1ef3b0bef",
      "148657f2a28940a7a45d371ede4a9cad",
      "5eef8eeca96f4e46bb17a6485077ea83",
      "d801367dd90e4f75a62e05a21ca14a11",
      "0ef695802aee4055903622cacf413214",
      "1b2175c29acd417396bc19545d13452a",
      "c0c71d41fb6241cbaea753feb96248ba",
      "7bf26cbe2b5a4c04a2f0bdc6f8b6df0c",
      "9d4ee6906720490d9c3869b87f08c96e",
      "8c44259d80144679b321d6f38a9dc0a9",
      "665ecc75ec2144b9918ae0c8df2930e7",
      "f402a99060634504939d7fb3d6d1b127",
      "3c37bfa848d14f25a86841ee04964d50",
      "47635fcc9800470482234c79a2f14abc",
      "b99fa0c09eb644459b666dd5c2624452",
      "a20b835cd53b4880841d93fecf74076a",
      "744d9e3a26bb440bbd025424f55dca2d",
      "8c29a3b6b9e5406280a6600cb55116ed",
      "0c895fe7d71d4e58806e9c3825d4f03d",
      "69bb2e37e2a44fdea49b2e68b1ff32d3",
      "89aac6d4e7794d1c87cd26b14ff7dd82",
      "40d08eaedc344363a2e38383aeed5de1",
      "cbf89b6605684b3f9658550f3d809d04",
      "832fa346aa31431ebac0ab5b712719c9",
      "3349bc5b72ae488d8f5d1f29ebedc0b5",
      "efba6df92deb464287b1ffc4b9b3f983",
      "a58d4c0c9aca473f8d51fafb1c9506e4",
      "f6326adb897748128081a8cc9297805c",
      "d069737f2b894d5ea93f2af6f70f7dc7",
      "f2bd1967977046f0b041609651f14a72",
      "94a926e101d8440ab33935ba792a4eee",
      "a38e735afc85451f9d13a1066fc00bbd",
      "b4a70d0d86134215a3bcfe84774fdd78",
      "88db4f3dd577493a997972a7a70b51e8",
      "b647090a6f1e4c469b779172f8d58819",
      "214eca00020e48948c906daf5d6b72e1",
      "d29ff839fc6a43f78020f67eef0ca485",
      "ebb2de1a9db94202b6c04085417eceba",
      "42788b38fcba4b39858f658d5cb8427a",
      "ee1075128290405896e262a91c81c906",
      "731aec8ddbdc4f91b17bddd97607223a",
      "70b595318bff4722af35d1481940a7f1",
      "322fc9e3b3dc4bc2a232acff22d91708",
      "3636ffd1366e445280ee46cd85450e78",
      "d8af7cc7317040fb8a1e103926e36530",
      "adbb864dbe9a4850b3d9a0c4b24a5ea4",
      "d270800c87c84939aa9db973d67baf4f",
      "9711692a414a40a39af235feb0fe56e4",
      "0210c1dd0268497aac4c9a4579f27f44",
      "8ba84749ed924ea7a9aaf565b88da760",
      "1badacb34ea947f59c9eb92d98527d3c",
      "450a1e0041f045508335d527bfd555f0",
      "a27861ce8ed94f05b6083ebe8a3294de",
      "a59b92e590f1414d8f476f644acd73ce",
      "16d279a1bed84be186986969ff8826d8",
      "638791608cee43008a152bb7197fc6d8",
      "7c8cc11e8fe24a64aa279f1f90151e2e",
      "70158ec45aed4746b404fdb331f434ec",
      "7491a08d8d3d456c8a2366fbc74625c0",
      "24726f3d6f5648d2929cad8b7ee1287d",
      "1cb30b233fb24374b6c027b2ca3436bc",
      "d3405ba6035c4aaa83afe0314c15ef19",
      "a37308f7395540ccbcafde66be5e731c",
      "9c3310e74bc741d49437fc48de9b6f94",
      "6b7bf93041fd443cafc43aca02462fcf",
      "25206b26bf8a4181a90dccb824bff161",
      "98ed4e7138754faeaea153e12916bb00",
      "bf7873c085a8486d9f538c7836a04219",
      "5972bd3a0bd7488caf80fa2383ce5c0e",
      "c2a2d2b0b11a4fe58a9ffda2922d8174",
      "1cff70428709495187c4f5fd188b2305",
      "b73bee810b60419b8e13d67b1c30bd45",
      "fd442bd66f8a423bbebca3333d2d0e83",
      "74d45fd5a19d4a5e90e3bfb5058ff91f",
      "eb2e10fd6214420790e2089da9de0a70",
      "a14c723d6a86430eaea57421353c6b55",
      "a9be21e11f154797ac69a57daa00cc57",
      "245154356dd74987b918eb28932462b8",
      "9b6407f45fb34642a8596b4468716dfa",
      "d05b7e4bae5c4c6bb78d52331429931b",
      "4e02fc2116de42b5b1963d88f7936b28",
      "7e2f1456e1b945dfb44c59e70359e634",
      "02822d39fbf74f5aa035b80d1a0bc96d",
      "65ab5fce47b3436da5830b2ebbea73ed",
      "ddf8e5cf8bb646a2bf79ed2254a82154",
      "4da86f2563cc4fe88d70ac9200f98e2a",
      "92ef0b098b454bd28a1d8dd8f2bbccbb",
      "0945877f203742299e13e4f13cd8aa3c",
      "f74e622011df4f8dbc3576eda7b2a575",
      "40dad8ade5454b00b20da93963278727",
      "9cbf7c9bcf684579b26091afcb296830",
      "4c9fbe5a1b2a46fc9401774527f42f58",
      "c6f13bee668f4bf5bf604fa2a613fedb",
      "6ebaa77e67084b049c1e8e80c379f31e",
      "df54035b37e843fa91de8a9fe795aca9",
      "196776ac3f45494d8704845de591b9ff",
      "29496b66bfa64ca980bb841b4304f277",
      "a15713ba1d104cbb85b66d30507fd7e0",
      "8c25abea9280492cb8aafc628df56da9",
      "5a0efb5e9bcf4a728ff0336ce68db2be",
      "e96cea1185154c14a567998da84dce20",
      "003c3822f2484756929403b4abed30c2",
      "ab91fdd717764467b90db7f0c74ee309",
      "60eab76823184af69a431050715c0d5d",
      "b17368eb71784aa18e443ade2435851b",
      "ab1737492d2349e68e24dd9c1e32e1f4",
      "84cfbc9d8fa44fd49be7b19258924cd1",
      "937154fcbfe3491c958a5afc6a9d9027",
      "ff25374d8a594299ade6838715cb7f52",
      "aa85752323a54e45a3eb37ff78ee7685",
      "c2be2a1eae17481aa5a6ba2df8758682",
      "93cd7323b4154e2da6eb7b3d5d3dcb4c",
      "2cf6b03b82824abd9d19c79bbba44ffe",
      "fb035b116a964bd0996f1e0fa8710687",
      "98f17ad2f15e4c9ea419c6532d2e4e90",
      "11860a2edd044aecb991b0fb21ac2dd6",
      "ed2f228e64db4600ae03555c020b021e",
      "408f36dd8d214a7e99dd8266391a63cc",
      "90f3ca86025c4615ab778781b3f57c86",
      "e2ee173cd35b48d5ad1fed945f246767",
      "83121f9863e044f5800b0f34b13615b3",
      "e7aba50e8ee3412cba72c777595b90aa",
      "23586682f2e945caaf9b28cf8dfdbf3c",
      "c7359961ec7c4da59ee13e76f7b9d536",
      "74fc8b18afa6499799d9ab79126e4be4",
      "b4e873465f8d4ef28813c37c190454df",
      "d20af625c7254743b32fff247f76b6d5",
      "47a038b1682144eeb636741efdb6eb84",
      "b037703aca8e4cf5bd6e686ec0ca804b",
      "235af876190b4843bca545af168c0a23",
      "ab2526929aa64a65b7caa0ea3b68343c",
      "bb8ae3110768415a8a997bdb1ecbcf37",
      "5d68013517c544f18d4fc91fc5ec8af7",
      "d3b0ea497f504a0dbbc20eed17799234",
      "3d3673c7dc9b43c09939b936c2ff413f",
      "45c3f150428844a4afeaa778d8b4f3eb",
      "fc82cc3dca694aada61eca910581ace4",
      "b5bf723c7fca4a3fb6b1814ad7e255e6",
      "7137d998702f4abdbe6ff56dd72d926e",
      "265811a10c374dd0b7b45bcf429918ad",
      "765d78463b6f4e96ba65a0a60df63383",
      "e4c78363a8224d8a9d0e00309f000501",
      "2991898a65d94a5198bd5d77ff681343",
      "e07515ba8b7a47c0b06f8f2b1cd2cabb",
      "a892194c9a414839b63876670436e915",
      "e186d41c92d14406b1e80a75a3f698a2",
      "512c5639298548c49826959397e35122",
      "5734b72f130b4d56b43f159d026cc626",
      "1b4bd0b05f5545fe80cf52d0f896d23a",
      "6c4116918a7141d0a26c31f604d13355",
      "14b36d6100d543f68b453b86d5bf3387",
      "1c4c34523586420ebf58eacd931f601e",
      "b18e1cee05424362bbed825cc81fc598",
      "a7adb819406f4fc4b5ee6086c28a9de0",
      "2e04e84a6f5643e0b9ddebfd277b56f2",
      "c4391b1f2e2f4efbbe95861c1bd0dbf3",
      "39cf438477a34c489e508114f9a20f6f",
      "f35daca6aca248529633b85b38ae44b4",
      "232b72f4b3994bc1891567a6cc17311e",
      "109427b71b274a64a92fc0df83df2fca",
      "707d0e956efc4d17a1f7b4376eb56374",
      "3cbb2663dafd4930a47fbc5ab2b8f22d",
      "e0d0967ad7d3450bb399f9bf9899652a",
      "63c7021134fa4b9aa6fd9679506f31e3",
      "9cc1efbabfc64fef8807e42f0f99ba99",
      "432bbac86bc6499e989afc4379ad9e18",
      "68d3937ba4b34527bec1695dced5f122",
      "1b93cee8daf943fa9e113dc73d1a63df",
      "d216b10b44f74319b8801c08221e0265",
      "fac72f5797b54c878a2897d56bf8c233",
      "910f86d53d32485fb96d6234c2e30184",
      "0affbf7a513b488d988cad40a2666ca1",
      "0b160e32cd374b2c9ab863211d13a7d3",
      "2e8fa5d5951c4327b70a7580c46304ef",
      "fc16d7dd482e449bb176ef05270b4819",
      "e9dafcaf137345878c7cc731c23f0325",
      "7edd7a7264cf4fcc854d445a8f859856",
      "d8300ed4568244bbbbb392b4fa4ff19f",
      "8aeb40afd0984bf890dd9826437b4748",
      "401319e9b3d54a92ab05a37f5049f98f",
      "97efb32f2f8b4a95b748ac6f0de6a0d7",
      "a3c99bb0bc8f4ca493438520aee01d60",
      "e4341d347f86416d9ad0e32286d9ae32",
      "8b5f3fe856ee4f308855c4a7fc7ae274",
      "6ad33c5bc6ff42cbacb12e75a182fcc0",
      "334912efee4a43ceb0233ad660538452",
      "81be2828e6264c1e8fa08819a0293254",
      "38428c8bfad945df8a5984657ddb83d9",
      "15d36322fa12420393385a13dcddf661",
      "9ca76967aa0d4bfaad778dc0c983621f",
      "15ffb522a43c4dab9cca94e76aabf400",
      "712a85bbfe974ec1a720f712d8ea7741",
      "4b587437e2684ac7af2bd988a12db123",
      "6b1a31cb45304c039b15ca9ae3ae2471",
      "c023e9b7d2a546629470d819c197e221",
      "92b8f7fe42754fb683641c4e8e30f14c",
      "8e8554ee6fdd47ae8c4cf5d984f9d551",
      "3d133888ce6f428980edbec9be8be61d",
      "7eb18647b5ac4563bc5d9ff542dd625e",
      "15aff2ef3b4d4cedac4733ca84748fe5",
      "af58ac81b5d442bfa8f812b404f7869d",
      "6b28a70cb1fd4e58b8b8d3b45a7fa10c",
      "b88c8d87abbf4b6793e31234bfba2cd5",
      "112ab1167e074ce6a7b5a4e4a53aa4de",
      "42644f6bc297406fb46ed3c188f3bfbb",
      "915b5b71ab4d435a9fe3d65b78d80a97",
      "bc9361cd73bc478ca958911a5ae77d22",
      "bb4a11aa81fb423a9e72155849735d3d",
      "2097adac8d654384a5b51e0ba3b087e5",
      "1f38a3a7907746d9a82f28e53ec7f49c",
      "f1e85967fb994d53bc0d55e0bac6ddcb",
      "f6f42fb0459a49f7bae59a173fc7e4a4",
      "e2592cad96f943ce9ebaea52480a39aa",
      "35669b1e821148a19798e981f8909ed7",
      "500f2065caae4335a5cdb432046f4533",
      "6f0b03ebf44b4e6e89d88397117cd280",
      "092e7322b59145a5b9268bd64a237566",
      "8e86d2d1a41e4393a12477bbcf44650b",
      "631803cbd3d6473397b44d6b2f5b52e3",
      "c2a4476bedf94f0991073237959d1c0d",
      "18a11a314c984cedb22a2659c6009286",
      "ebdff1815937463f8b6e7db8a91d4d71",
      "c99050443c3943f6a0c82eabb87df8a0",
      "e0ec128a81d54e1fb9077a4774dd9bdb",
      "f138cfc3bffc4b098d46f9e7525f0c7b",
      "c18fab6a00fb4a7098546a8a962c5259",
      "882443f0ddc146749fe84d6a7d0b205c",
      "54d00ade3e604db99d58cda5a29fcfd7",
      "ca96d978658d4bfcb94e1da398e54cd2",
      "31e2229b5e794e3e93e5552585be6212",
      "4b0e1242d8f744dfb8cd60182c268054",
      "c12b92f476e34b07b37149d3c2a04f64",
      "045cc81e1fdf4507a07ea8407ae81f12",
      "d8007ae6fd9b45bb9cb62be24732c204",
      "1aa4b7ead3a444d49546a6e3ba989b3a",
      "f5361a123afc4810a2c05a24dfe775ed",
      "7982e35e9c5a4491ae4582f1bc0d3b48",
      "e6fc25678e814d6e837c504b994d23c4",
      "1759c05403334f10a7bad39713ac78aa",
      "8ceb5b82f33b4da882eee5547c4eeff1",
      "35b16a2b2e7148f0a19273bbb795bfdd",
      "c19ee04a21b44ed099af31368a4f4b8c",
      "1d2d566450be4101acb1a7c93fab5158",
      "93fe7c3d654749569d2d3b2fb9addc03",
      "7afc1622f89b42e7a379135c74e69f22",
      "f20155dd07964fe9bb0c2ea8c34c2227",
      "0e6526803e374700bea95133cd8d0d9f",
      "01763f48d09f4e218c09a135ec5d4646",
      "cccdde1c2cc140acb0f825ce5a5de3bd",
      "fcd25f19432b4ebdac579d58b136a68a",
      "36241209297446ae9a39544aeba27807",
      "b551a16bb5d243398482832f7021753f",
      "b69d6bbc027b4beca4ab8c271cb01c75",
      "1f1b33c70fc44f578374e114f56bf690",
      "f639e4e12d9d4616b000a133a4b9995a",
      "4b37a0dcc12e401398aab6bdb428629b",
      "d0fa3e41381c40cf932b1310e10ce906",
      "4b8e186a7ab54c018c664a31b97bc3c9",
      "1f1d3b37fba246f3947ffe2ffc4e861e",
      "0dda446395df449a8378703b487c3ce4",
      "23238f51677643459982fc17eca29b86",
      "5720850d31e449aba489a8d18083a814",
      "66ac6cffa54a47d1b8f01d2cd7bd16da",
      "ad963d589fe64e33933aaa42f7af7f32",
      "50b5f3893739445fae80382c4fd7a7ea",
      "4dc7f9cebdfa4efead0ec4d76b582ac0",
      "40454628ef084d9ba827e4aa5ea168ba",
      "eb85a2f94af6422e92b0fe8d8f504b2a",
      "0e4bf74458f14507ad8c63184b8f639c",
      "498d10a40b21463ea78ffb26b99dedaf",
      "6eccc55fafb24df8954b86a53c41c766",
      "380f7a1849d94b4eb24eac0a2073a42e",
      "01a3ed3f2d074d028906c23ead77dc53",
      "1a2a53421f87466cb396f0494de05e4e",
      "964fb020bfc2494fa6f57228081f87df",
      "42998863a0cc43118195a91ad8d7529c",
      "5cf691ee483c43cc90038be0929cfe3e",
      "73c56702a8124b09a9c776c8ab05ba25",
      "a4b3658d53374a32986de07b59f8b13e",
      "550e96ff106f4faeb0501b0073ecdc83",
      "d4ffbf0816c7439dae6ac1dd77a707c1",
      "37cc8c1015b44ebe94492217fe2cfb21",
      "51f540b07a68471ea08bbc7f56d89b01",
      "b061afa922814c1d9268cb83029184f6",
      "9f45c602b19643c29d41dcf53597901f",
      "9ddb1cb6e2fa43d1b5d75e2f6ad368ca",
      "6b03a0e82c76465e97c2beb80ebfff0a",
      "5d85f42bc58c40198e51eeaf1f3992b0",
      "cce0044fbbbd469aac32e28e4fcaa959",
      "cebec516522442d7badf36f10862d4b3",
      "27e832e811504dedabcd938d8bd8ed0c",
      "f43d95cbd19c49428a7af4aec607bb00",
      "71506291032047308acbd3dc1e04b3a6",
      "c6d873d808714bc5889d130b67400148",
      "8bab54bf37d74a958a7c62b6793219ff",
      "f3e1d2d9cbd6476eb874eb74d6360c5f",
      "28a5ed1e18054bb19f3c7a51be8b6cb3",
      "20af7a82dae044efbd8ae22eca7de26e",
      "b431da1eb98d4310a4999638eba97be3",
      "97e4ca5a2d15432e85b2bf86ee414511",
      "784aab61e7af4a868279165d557c196f",
      "6a7b7a63f58e474ca2b7b052437ec65c",
      "9077098c9ec847ed9eb090d4f677866b",
      "bda89e3da6744ea48367d3e89ef1ac5e",
      "f4835fecf2274c45a32859b84931341b",
      "b4e6646033814191a3e52007b5fda237",
      "956a116e32fa4b698c325293b258cc97",
      "8584ddf6fb0a413c88cbe78aae1756ba",
      "5c49102759cb4fcca56119f38c1b2993",
      "bad9c644dc6c4d908c8e1740d81b1e39",
      "453a8433f3de450aae01b5a2c40fa5a5",
      "ded414571e4c4a6a8668397369738d1b",
      "89bdb10a3bca48e2bae6002875d02eea",
      "0249e4e5d9a34eaa9891bf0a5cfa9cb7",
      "3f7c447726de4153a3fd58419b12b8c0",
      "97cce54ccb8e4ea8a8f46c09cc5e5288",
      "c1ee693d57c845c5924e33aac2723e1e",
      "f60d8f1c05a34ae88eaa5d02d18d65ac",
      "3c1f4f05f8044ed18027c441f418922a",
      "48cdc050a96a484eacb7c41aa0c2acd5",
      "6d8e225ba73f4f90aa1e39fa57bc56a2",
      "9b12c9942664461db1b7a1d06d4265af",
      "974651589d0b4b5385674893057dd14e",
      "2160764994c942f9b207cb7abf33df34",
      "31b52b8e57b248f1bbf8b6b15bc99f3d",
      "6d8f171f8fe547fb89eda96758329d8e",
      "36cb4319c11b431ab8e2dc9d39a2f2ee",
      "0f80295092aa41b7a5461e290b09a810",
      "2ab937b9171441b586f727ac138b1256",
      "870db8e479ac4117b128425a6e4a6efb",
      "e0a7c5b651294493894080ce4d4295f9",
      "1fba11dc47ec4ed8b4243776f6196503",
      "1c20fed5cc704b33b44281de113ba2de",
      "f0626ff10b6a49f994992867ee81ae90",
      "0b702f5fb70f476494db4c55b3090b32",
      "dc77e9a6bba24893bd0c9c7bce19526d",
      "4ded965126e842b7ad1e98e5f319bbea",
      "65b30f642a494b5eb15a98627a50a148",
      "67d666f0cc7344e7b1ddff8e8fee120f",
      "e890585a7cb545a7960591f500657c2d",
      "2f14697332d14da5981076d3bd42c195",
      "84ae92c24108447389e55cc32b843225",
      "65ee145cb35545d1b252df87f77424ab",
      "ecf97fd443ae498c92e93c291f897ab3",
      "59c0d8074fd44b71aeb621d885d0961c",
      "95b425ec008a448fbd4db3ff7bea2baf",
      "c7bf6566134a43c8944f56df4a8bbbf3",
      "b708e3e237884d4a9f61dbbf7bf46c8f",
      "99ea01af849e4e35a30203e43bb1a934",
      "b910df4326104733ba826c4590a66461",
      "2b0831c9824a4d9ba1018086ef09907b",
      "040508eccb814108b608a8495e626b4b",
      "08432a5eaf624009ad20c9b7f6575e8b",
      "902d8e5d76ab4f23bcfef0aa47d1f510",
      "5982f5002b1543c0a8727289283bd45b",
      "3002747a2d354047900897b631d34510",
      "1e0a2dcb26704f4bafd31effa0f2157b",
      "71840ae2319a46c6bce2a76eefe48a8a",
      "37d51315475b405f9753f0741c0cc007",
      "7849704aeecf4ed489e3b4ab0fe1b778",
      "7d6215f265c344e3b8dcede1e72b59b2",
      "356f41b155914de6991dc65b32c4b7ed",
      "d546161479ff42d8853c100bfa0c22a8",
      "6560304a55094bd684d2a2fe331736ed",
      "d8d60f74f1a54930a05affa2f1f00bb8",
      "3b6016c2818c453d86d3e4ff0ff5a5cf",
      "1f0f016129e943a5a02136901bb663a3",
      "ab29acd3a9ad43f69c0c54dab88080fb",
      "d91f3ded702b4355ab5887febabdb116",
      "e24fb3315c914168a90cf77cebaf793a",
      "bdfcdff6eb0a4a69bff48459c70e2d82",
      "35ed140d7129404caef4a7959077a274",
      "64d3c39b49634ecea8657a34722ac9f3",
      "a026e0beee454a539d0a738a087c73f2",
      "0ea08df5cbf641e38ff7452593907e79",
      "73bf7e541e5647849a3d91c9448d1361",
      "8f39c3350598427a86e147e0908b06a6",
      "1bc0e4224f494568b6140bfc3469fb3f",
      "0b66ecf316294256ad74ca3587d4957b",
      "593b36fb3aba49ccaf4b714f0660ed3a",
      "81d5a0081ab94a04b82a00ed435017b1",
      "352fac45e5664b31b7dca4e57f6223e8",
      "686d4e0308114aa0a4cd328ddf32ba94",
      "0dcd245517d74e928ce671093a95ac15",
      "0f065fbdb2644b2086910eeb4e18f556",
      "dd811d3fb005484790dd8055ce9c5bc9",
      "3e6fef12a39643aeaf85a130a43c5fc8",
      "425a9933ba3d405f9290334082035b28",
      "e3b575db2cfa4b2281884dfbea825249",
      "23219610c6c947559fbe600edf9e052c",
      "7cd865712a614c5ab5b0ede106240561",
      "2f02ea7fdad14caba9ca8b0f20462d7a",
      "929068e9dbc24c9b8fd21aba5e32178b",
      "22087cd4143546828fd98a2b52964dc4",
      "e77b6921689745a58ad495f3b2bf9d93",
      "ae6c38aea3ba47ecac9be60461bee58b",
      "c552a89273754ee78b7487cafdae6a5b",
      "1e66177d383a4588b662038c93104614",
      "1454b30f0b5341dba38426a18242ffa5",
      "1a62f513419d414ebbaa175009dba2a9",
      "41fb03c460b645b18f993d9062152388",
      "a98e14e79f3d41d9a8edbdb65a58f838",
      "d07ea12a0aae429ea172798e94857415",
      "59556768213542c89c6af35d6c0cacd3",
      "6e5567fcaffc4c739c9761afb80eeb1d",
      "59ee13993f2d44bca66038099189d1b3",
      "98d25bf13beb4305a1b7d23be6a64209",
      "0a028f6f2ae14dc4bb22231658922c39",
      "8b7898e47fa14e98b0a8f4f0a02a089f",
      "992d95e4ac5747659c20178c0a1c7b17",
      "dfecb452035d4ce298f667801093644a",
      "f2cdbbc214454ffd97231f9a8d327710",
      "e0647f8757084a538b2e0cb38d9beae3",
      "eed19d5448db4f00b55f5c07523fcaf9",
      "38bf03609bd34b93a4397487cd9e82c6",
      "694fb11683d44a149d86cae335c5a84d",
      "275ee80e4687429797b185b446213f9f",
      "b9e2a8c1e81e40b38d23b358e884dbff",
      "9e18b787d0ed4c17afaae963f6ca57f4",
      "2e3856107911413d8c3b2a174b79ac0a",
      "4438030cbe4b48d5bd65b67d79324d94",
      "22d19b06ce014b9487fb7462984fe18a",
      "ab70ea5992054d68bb9a1d5c3ab35e06",
      "ed111317f2e14cf48eb925b25ade8197",
      "13d21245376b404c9df23142eb84da31",
      "4490f9e8d2584c3696820acd155852f4",
      "5d1a76a0a37042c6a7300cd5a6db50f7",
      "1ee6802cf908465bac5c102e992aa849",
      "d2c6a16691c847a59568c86cc6f0537b",
      "3ff000d5b96f4441bd6d132c241bbeb7",
      "0721cae005074cb8bed25907f6fe8e5b",
      "9d2e20449cbf4a3faf446b6e8eef995a",
      "190cfd41e7c04fa68c62cb3db2ddd3be",
      "824009bbd9714d5795b9de869fae60f6",
      "56daeefe3f214dc0894bf48c49dca019",
      "c37d7218538a421689ff975f927449f1",
      "7d96e18722de484398485ae557a978ec",
      "1fc31f2479eb489f84dea4222f9535fd",
      "97de492d5ea04b30b538a3df66844f8c",
      "2f7021c98ba64416b9a444c657258d5b",
      "1932577cae6c4972804969aa3e77e7f4",
      "5fc4c7e67dbd4be99ad4c8a0a641bf96",
      "224d235b49de43ddada695166a34eaae",
      "daba60ff0b774f998d335b5b45cf37d9",
      "2b253652ff774c57b3ce5b5eef9ca49e",
      "c31727189a094040a1a0d38d10f0670a",
      "4a0a0ca0364e439cbcc749a988e7ccb6",
      "242ed207b707460a80bebf274f7c8d78",
      "8a4a3eda3d5c4920ab727d09911f0327",
      "3743a31c31ba4c2c863d7e876d8b8ec8",
      "ab642720e2d048acac18438937686e1d",
      "2e21f9f08d9d4f63891c92d3ffb04160",
      "c23dd3ba96944266948fcf8da5ebb83f",
      "64001d8e48814f2c8111707eb994e174",
      "ecd621d6f9354ebf9a66d92ac9f067bb",
      "37018d2f5637491eb312d4d54ddada7e",
      "6a61fab1e8594b6785d292e997bbb626",
      "8d416ea35d4e40519687743d00fccf69",
      "54fd517510f14919ad47877bede9f945",
      "6d22ae01c98f478bb5d05cc8dff5383a",
      "e9117d3eb0144f40bd30b008ebea9c8a",
      "5326532bd75e4ef78885536b5321e437",
      "ffd263b38e814f50b9a6aaf809c5ddc2",
      "220f3ba7609a43f3b142bb4152bd0dc6",
      "4db92a5a40f94728a97ea215828018e5",
      "10ae437598d445db812ff7d6ca43e451",
      "4c95f183049244e38ff12a15fdf52cb9",
      "8f6a86937ac043a2b215c0a555978bab",
      "9bafcc9ac561491bb3959ce960fbd188",
      "7f49dd9b5a3c4df29c1e33b950186d09",
      "808840d5ce0747beb5f52d7f3c428acc",
      "53729dca2b784e5ead6e93d0026478e9",
      "028511cc37f140e5a6869de522ac2dd7",
      "a438e7a2f1ed4ee9abb013d5a8265872",
      "fb7d94509cbb4914b93c46cdc13c800b",
      "a3b2a260a22f4612a302f6001bf75055",
      "4ee53a315281456c8b0b68082b9f3f02",
      "26bd5768877b4500ba6cdc01a7a935bd",
      "88436c4eacd5421a8d7a03fe765a5fc1",
      "69d105255243465bb18e6157c3aff03b",
      "ecd17c940e2045a4a166b8c3b1b67e76",
      "581fe3fad90448929c76d5a3bcab8c4a",
      "1b00f29f4ee94df98e9e291eb85f8920",
      "c01fcb76f50544ea82ff819a741a4cc2",
      "34d96f22ea934782ab7f35b375fcdabf",
      "3161a4b79cff4bc6854862fd8ac0c412",
      "e8a8df75ebe44bd49cbc86acb875344c",
      "4635f7d1ab1b4cb899b153f9127b57b7",
      "84d078c1f6f04908941fe709b5345465",
      "6daefd0e1aa84c09b19ccb082daf6e44",
      "741ee7d0e041485da74f57b6c24c1eff",
      "1220c93a91bd40b3af16011a5334a9ea",
      "36544322763a4016aa1bbe5d711774a0",
      "aa5135342e0f4f0990d24eb74a009da2",
      "28ec0a4c258d450db3d080ecce357569",
      "eb2c9d73eb7a45f5859630bb9f3371b4",
      "3fb1ff4932104fdc9590f7cb414f1919",
      "4a6a87ddec2049669141dde19bcfe365",
      "3ba3f51d75a94486842eb1683897417f",
      "5c75245318f2410b875d1ea0f0e9026d",
      "bf3544204d354e68990cc161fb2e02b7",
      "dd6366c62f1f4859a3468d77ac51ec42",
      "aaa98af39983442282cfe1be2bf7059f",
      "073300b7f9e34a2293d05691e5d11574",
      "7b0a542197654454bd15f85b1d7681f1",
      "24ea4b54455c4cd49871edc8a64189fb",
      "9a9c333cecbe43fda40d122a42685600",
      "af92a86698b54f0fa912349e01887426",
      "f262bcfaa1ee4d7e93060682b916e2d3",
      "e43c938ccb8e44ffb9e6f516df8ca045",
      "064f105273c642b2b07aab67cbb849c8",
      "216b9a889831498885e53980acaecb43",
      "b78fe02d2d7847e2ab4ff6c3ed4df5a0",
      "26014797ea904d1d9ac10daa4a53729a",
      "dfc4fa04104247758fdc2d99947c9598",
      "4263d1038b49443b9d7deb73c9201bca",
      "288a3d2a5086433e9aa9a219a411ca2a",
      "0b5bd3b71d324c2fa3e6d3ed771d6e31",
      "d024aca616a0448b96a84482e540c012",
      "8a98779b3f134786b0e7010745245e02",
      "2d9c664dfd9e4629aceb5e4b159dc79a",
      "974266eec3ce47bbb83205de0aa3bd07",
      "a54bcb5b251c4b08a2178e034c834ab8",
      "003a592ed6e64b69990d881ccc5e1ebf",
      "4efc9db6719846f6acb8864f6a30ecd9",
      "c8ad3c4e5fb7492d97e7e7c532b83ad7",
      "1cfa9101dc1f4d89a5c31ce001f04ea7",
      "622f38c2bbc14e90adcc0de4c1f8d1dc",
      "ae12dceeb45b4b8abe2df730f9e890d4",
      "0ff02727405146b88beffa22a47728f7",
      "49e91ed76edf44c4ad11292bdf2b2f06",
      "26c91633036b418a9d8b1b5f6badd4b1",
      "cf365daf9d78449b9729a76d47d978ad",
      "71a694c99adf4c1cbe3a9d4992339e30",
      "f2883e85300b48afadcbfa9c9a77a10c",
      "9d041fd52bbb4a50a62a10260cd889a0",
      "6e5e93388f8f42fbbca9999587b19169",
      "118da1953d29452fa6c39ea587636949",
      "1d37d8eb301f439ea3867a0b560b1fed",
      "06a0ef19631e4ba6ba2b76f1b4076f7a",
      "bac233a5b88f46499bcf01d2110e31d3",
      "c77be99e7bd24034903d4d1081376c28",
      "d072eb4e76c74ba78e0ab587cb3a60ae",
      "450cacbb1df249cb9617f40e93b6946c",
      "3e6d6d5bece04f96825f0b689059178a",
      "43e112fb65554c3f8dacc4a30b489eb4",
      "40a4810f41a54be282807c4b1dfae9a6",
      "0c47f9940b86400db8d809855a563f54",
      "85bc8373c96b45e79db22139afac107c",
      "a5dd593fb7f84375945248a48a5df0e3",
      "3fdfa65dcd0945d6a50b24a01d989a48",
      "33021b3797c64317b71398e080774f91",
      "b888a4e496fe455eb65c109039a843e2",
      "004be539b80a4ed78e1993e594adc73a",
      "e1180333c82242c889fe1b79405b109d",
      "71229fa4665e4b9e968148f1c6257fe9",
      "e126d5f2d5c94155b9a3512155d1b7a0",
      "cdc56d675f6c4c5ab20cbf4a29b898d0",
      "8ef1d7ab672a4cdd8859f81384315954",
      "e7e841c8fc374f84a0a929d9a98b785b",
      "463f8bb6473e470b81b46dbc25edef42",
      "20d21bea43f8452e8b42925a74823175",
      "8bf9e7f1b5ec4586aa820a42efadc985",
      "8b58f9e91c2d403f9b614deba4146ba2",
      "b82f780c61484677a547c27dd1e5ee4d",
      "bdad7fc963354d72a3a8793c97987b9c",
      "b24b3105bd784cad86333b281608bebd",
      "11328f87afc0433f9f75c32dc413f6ee",
      "3cc4abd0c3ac40a5896d5de677f178c4",
      "c696d329c44f481198e918e26be5970e",
      "77d7276886fc4665921d421e897018d9",
      "b7395819fdd6492fb50fe9605c6cbf0f",
      "3736e509b559432196d1bc7d6bc42889",
      "cd0118f69ea64f7298a844c3bbdaf833",
      "a48cf5b7172c4c1d83661812429d31d8",
      "583827f9704b493d99902f944dd54a33",
      "b5bec7664b3f4f489b6353ce286a46cf",
      "b795dfad679c4517b13bfd68993de1db",
      "5dc0b815e0494ec29c6232b83a200dc5",
      "c03df61d2a5a4376b071de11fd820022",
      "57d08ce6179e49a8ad9653a355dc7349",
      "1e0cef4211a34b57a0512c7a92f6d2b4",
      "98cd85ec36d74ece936e93dbc7988fbb",
      "6e09cd87a1d248468352a44929f115da",
      "957685f9cbc94c50bdc92cd7e5848e4d",
      "b08df54ae4bf4442934f70dfbf2bb8e3",
      "8b20ad084532437cac6aece7d46b586d",
      "227f3eb9824a4d4c9dacdcf28013882d",
      "b7c577c4095c43efac283511ef849637",
      "d0bdc695166e40fba2bec19706f67b1e",
      "45ab8570032447e89fc3282cea3ff708",
      "10a358ed20054ada8322bb8f174ca241",
      "8fd58b2cfd9a48aa91463035f0c1d92b",
      "b5529b84fa0941d69afaf7b923a8f7cb",
      "0200fec2197046469a46f00ffbe7de5e",
      "ed5e72f1c5aa4a23b09d7811d7f59285",
      "9c891013ce474590a10841bd43519508",
      "1a4e20bc222d451b84fa73b46beba2c4",
      "983fedd3360648398ccf66d8c7b719cc",
      "7c13df2e6841426c81c8797745af851a",
      "fb9ab58ee4e04c98bc54eec56500f778",
      "e3402ae2503b42d9af0bbc15415fa521",
      "a23439c9d8cc407ba9e72207d0c43b85",
      "953587242c2e41958caf5cb7ca7eca07",
      "810b356f2aa84b7991f8977093b04815",
      "bcfd9d33ae2e449190a174c634b0a049",
      "15a9045dc6c44e1c9e28f99bbdb10eee",
      "2d5a961c90b64c799a62a85347149512",
      "3aa168dcf7eb444290bc949fb6f56ef3",
      "97b82f0f42f2433ba29cd577e44e18e4",
      "2ef41b46d17144fea5af5c47413cb282",
      "361e00db9be34e80a3ea6384e0ebf5e4",
      "05de471a0a074be5a29ee5568961dbca",
      "be7845bf7df2418aacb13db9edc5e8d5",
      "26d5ff9954bd48b687e6d81b4dbb2b12",
      "ec05dd6e5974463aa741aa83556c9bc2",
      "8f23cfa02bbb4c39a8654d69cafe83f4",
      "2f5a6a46fc2540dc9dd8be3f84a67c6f",
      "740e5b664bb846d48d314e58f61b34f4",
      "b9a3e8bed6e5454691c6c07e43a1bf0c",
      "746453dde6c5444aa5d974d42b9d0bb1",
      "ac2719f503114dd598a1322d471eaceb",
      "3ec1c8beba7c4703ac83c3457bd24f98",
      "9a49b3a61d034381a71f8d73454473e6",
      "d8329f411fad47a2bfbac9d48cc3eb6a",
      "61d3decc206c47e988a9e94cfce3976c",
      "2597216d0a78432ab4cc36ea6eea9c7a",
      "1110ff913520492fbf9c0282bcb83972",
      "33ac3512bd8f4e83b7fbe023fd3cf5e7",
      "3b47f80759174b4b9bcc33b022dda3bf",
      "5c503271050a46d6b3db7dce165b9786",
      "3884e3456ab14f0390994f4c3244c4e0",
      "8e071da7e141487ba85d33b8dfa487e0",
      "c9a8ea3d89ba435aa8a5ecf8e99f35c3",
      "1dc8bd90fb5041a98b0cb55431581815",
      "993d09ca1af64f358c60bd35e415faee",
      "89f90dfe1851488fa976cb3c5ddc16be",
      "56ebdf177c8b4ee1bcdc709e182c532d",
      "f1cbbb83d9cc428982b9cb78d7066426",
      "8fe8b09cbd9546bda61ec8b4ced29c4a",
      "dc3f15fc7c5442008b41c73566c831b5",
      "2fb77a70269746b5aaf5b03ed287ea6b",
      "9cf9bc0641f44318b33a744ed53b272b",
      "428eae04489545ccb73dc7902d1ec303",
      "1f63d985eead41deb7726b849873d698",
      "b06e2f6ad9c1483d96c8fa7ae31f7e81",
      "8f396fee80184835b8abc23d60bbb4bf",
      "302a0d15816a483cb70700d6eab45189",
      "1a832fecae1c4cc1805ba66be5d09c37",
      "97ec6b6d52e04a0f916aae254695ba1e",
      "81f1309aaa864b3492d1ef3f2b003714",
      "35ea28b9c89b45bf91ce2b1e1ad867d9",
      "08c25bd15c3143d3ad449fa5e4bb1989",
      "0dba449db3fa4608907a16cd78500ac3",
      "d883a6e809aa42e29cb0bc6778ac8ae4",
      "c86c773b4e054e0681d118992d752520",
      "dc43b64dc51544369f779bd0a8ed50fa",
      "c9d316720c764cbb98b2a0bbd5d8391f",
      "0dfa4d562b54460aa7a1c80117aa988d",
      "6e470032eb644caa839207a37e048416",
      "725d3a8bcd0f476e9e8235a4fa2fb4c7",
      "1732c4fbedd3485494f1265955d8e53c",
      "754d36058f6e447486cadef31bdce511",
      "cb75aacabad84e2abbad924d6d869342",
      "c1e0495ee32545859aa8e396b9a534e8",
      "81521572b2fb46fe9a56bc15cc2a3646",
      "df121adab2d147d587e11118bd3b9ddd",
      "fd9de4a0411047edac17d2426a984f16",
      "0a26d24afe5b43aa8685436e7ab6e677",
      "65f3d2e22c3f42a4bc806d7a1f383049",
      "548d82b2ead4481198b9c145c432237f",
      "bde82ee1432f4be083e697b824017271",
      "89b8c8d3bb884ff68ba1475688a993a8",
      "4e7b434acc9d418f88665bc537fe001f",
      "54790ae1a5c04f4bad9543bf9017eced",
      "be2688be414d41f4884f9b937dd3017b",
      "f52cee95ba1f446cbd00a3302dc3c680",
      "5f6efd5b2c374a8eba56bf7a9124d3d1",
      "d30fa7ba2ac84967b5dceec78de2ade0",
      "e720ed350e47428998887651343981c7",
      "a906b1ce59ae4b139f49e125b28dd638",
      "06eb9d3ae9b24c55a0c2b6ad6171eacd",
      "54c4e48aaa724c679857939952fd1cc3",
      "995fdf7ae6d04b2f906bbc21e2b80ef4",
      "74e7647b37c24b3aa7308c353291de11",
      "fd4e2c3c2ce64e94855aeeea0e0fc08d",
      "1842a5d64dde43799f67f3efadf344f3",
      "c751b714af9844488d5a2108fe5df2f3",
      "9ca1a40b84a747d1895d14f356c12c9b",
      "694cd761bc2e4948ba4885c3f3ce0d40",
      "515bf6ef396d418b87234d34aa690d0e",
      "0497ab94693145b999007bfaec95baa7",
      "d54421c67049430f997f970e90e965a6",
      "5441ea1e653e40088fbb5586d85774ad",
      "8cc550f85745423c9677007b1ee60c1f",
      "0b847d3b6ac043369ebad00842dcfcba",
      "94391707ea31485d8898858046f0eeb9",
      "e9f635bb61da4409b8a072a6510725dd",
      "e8b0442fa566494d8cc8aa6170c69cac",
      "5d2aa73ffc804f0ab3bc5bb822a3e281",
      "f44931088d074b35a382a39fe3312357",
      "281224c5c3a441a48e1ba228be512ffb",
      "60a940498c4d457b89895a91b47c116a",
      "ac21c920912647d0ba1c6866a1b47a06",
      "05c204390b464437887fd65adba7d051",
      "a1f619c1b35a4320aa6cbdb746c5e9f3",
      "f2e8487324264f85a9799ef80bb44fd4",
      "966af3a0b5be40c19e3c1084acb6b69f",
      "43a197dd268d4b90b9f5fc6247f88f63",
      "508185b0b7504442845d41838368204e",
      "067fd12d37864e298a7664abfbf616da",
      "5024b5b377374cc48ac09475a3a631d9",
      "514146229df14e14bec50e3a4aef2817",
      "9e844ef7b4ae4713bd8cb8b16cfb1ae8",
      "19422154c9904efda9e91022c9d83fd3",
      "ed70bed871f6436da2e75431f8ae77ed",
      "9c658d5c1f0f4f6aab6e304d6d96a5c2",
      "94531c4781c4445a90f4faf9deec2024",
      "abb49bacf4a94479a65e3dc1779dbba0",
      "29e2fd4b12ff494580e84c0a3a27565d",
      "1ea43880a92d499aaa784744c1be1bf3",
      "19eeea1ccffa4ac296e9dcad953bbc20",
      "ef4c93dd1e2648bd8cd8ba3ec00013cf",
      "bcf7f0783de04ed9bbc7a9e03ee84e84",
      "d6dc13e775bc4788acf6bed04a5bde15",
      "3fb68d9ccbcc4beeaf9ff8f3dd6e3e44",
      "6e550de7fa384c318fc550a27cc0438d",
      "385141ea2a97453c9e9e8c6b213b427b",
      "c21f6ac4ff5f477695e11f72d642bbc6",
      "314b3ef4fca3460d8dd06a7d57f4e390",
      "2e7d5f4023974aba94a8f9dec18e51ab",
      "42b8b2fb66d64dbcade9ed6872d817aa",
      "9ed9e753875a4b5bb60bcb0f3eb05d97",
      "6ad2a1dd71284514b87aba49cf7bea61",
      "fe0f77ca44d741b6921612b0a25d3bd9",
      "a34e1fdbea67454fa10209ec5296a7d4",
      "e12e2f6f5163495293ae425b99a6310e",
      "ddcc31e956aa49209d5299992b2cb1c9",
      "c6f2a1cb362d40b5bba42b3e134dcd6a",
      "ae3dec48f8ae4275baeda8cd0d0cb00a",
      "ef1cef58228c41bfae937d208a20e7b3",
      "826ec0b42103466abad63673478938fb",
      "ec9790aa6426444e962f182c4dfe3b51",
      "cb6ad85835a14061aa2a3a03c06d5eee",
      "9deea31950574fedb40b3ebf74d65325",
      "4593135ece1e4811bd25d5ffd31fa3fa",
      "2427a1afc6d94494b249112f849c380d",
      "5f9be65eafe04cc3a9b623ca6eeb66af",
      "116e6cee239842f39ee0227ed8b5a28f",
      "26f0396891de4f3e8e0ac5009233bad3",
      "bc0ae8abfb9546b4865f2895beee4c9c",
      "cc4672fafbb744f183e46061c72bb234",
      "a42b58de9424484090d0bcc401da6936",
      "4eb4492551264c36bf8fad3613677608",
      "6173cb27831949c29a140b3ddd624e52",
      "bbd48a13090847a8baad08c19aec52fa",
      "d98e940feaee4884b85e6a41cd8dad34",
      "4d062be9e4f2468bb087b933344e836e",
      "52eb513926684d128ddfb85004e08a99",
      "6d59366408704d0aaddd1fc20f447e32",
      "d9af8ed68e764769b691191fdcec7e27",
      "26f3417d47a64a009b2d69c4d683168f",
      "fe2c369e4596431c992d903805c67bde",
      "e4f0d7fd360842af9d2d20fa97632599",
      "55fa9b5d332a4424978bef216fe3adfd",
      "31f42a6ed1fb469da14bd31598b647fb",
      "9c15153d49a747f8af85e93c1a648bb4",
      "3b6287493a8045f18ce7d5794c009e10",
      "1f4df4caebc045fc88639b2352835601",
      "7dfdab6e29644a4b86438572a4a4e7b3",
      "0719c82a35634b6dac7a11f6d008d508",
      "7e710da0d4bb460cb24c2e836cdb8e9a",
      "a4936da49bb048e49ce0ba1167d538f4",
      "00974d4534254ffba7224bcf74425c77",
      "39f934b2a64e4f59aa1f2445e3e1b93a",
      "7f8811fcab8441f8b8f24d1d3a6b5523",
      "266484f6a29e4844aba179802df5ae6e",
      "1db37779c1e3426a894d74a5cb558721",
      "4005cab2c5bb4e61a64eb39539b38eff",
      "25fc25f7d36f4d83974f3a9cab773ca3",
      "2358194606bf42ecac3de3f47018ca27",
      "6bdeb3651ed84981b66858f86e1f44af",
      "34758e67455b4fddb3f777b42e2fe33f",
      "4768a06ac6a949eea9188f4af001c0d1",
      "f871ae228fe54ffcbbe5cc6fbc7b1cb7",
      "f95388ae19344de695d0407337e6637a",
      "4a29e275b89144af8c36c3829b84a672",
      "37ace1867e48428cb5ef9bea216c93e3",
      "0a63fd05b6b347e69d10716e7efeedac",
      "98c26b44912e47f7bae1b7cfee326258",
      "9d4b3d20f2934797aa31426e9e2bb742",
      "9942621111a34162b57164bb03c33cbf",
      "36931cea42c748e48d5812138599be91",
      "ff346e40cfc44939ae29418ae47c5bb9",
      "2deb3e4a6f514ab88cc445cfd1eec61d",
      "0ff0e3ac3e89436a9dfddbe5b02762b2",
      "d7e40431077648319d72832b5ac2850d",
      "c6ebaa5c762e4a4598ffefa8bf4dbdc7",
      "34b7cbf46c37417297c987510b92f6a6",
      "449500b961ca499f81560dd8e32e8ff6",
      "036e4cff12b04fe6a3d922393f215c8f",
      "ee3d557c9b0042a6b9d24eef06482ef8",
      "083694dc0bfc4874ab59348282ecd1d4",
      "a7408902bc004252834a0cf3ca02416f",
      "5ddc9eaed1f343659f2e6d8dfc71fabb",
      "b4621ac3597a47bc9c73f954b21b6a9c",
      "a57bdaf42e484aa89df7e6d656efb74b",
      "c4f862c00add4efd961b4c7eedccc9ef",
      "740be6140b204ae698082d0add4ec42c",
      "ec3fd3c72e7049c1b4cc118010df9814",
      "a25da7f7545147dd952e4332bcba4917",
      "c0c3cfa791b04f638a805517fbd9f4a8",
      "9a2ae2fcb5ff46d0977cf312005ce2d4",
      "e11e447f3b804d7887e5d08bc1da4d48",
      "a4c0278c82124b76ab41ef1e8a714699",
      "809ee9e7d22e40a1abd8544e80310901",
      "87e81b1d60ef4d0db9eb4ba73e68730f",
      "b373a364f932473d84d4e89d41845002",
      "8aacf0b3291f429cb3dcba10e0781a92",
      "84881d48cac3486b87f9e0b1d2d57d3b",
      "fd24acadaf394ad2a0ed9f7253a82425",
      "ddd4203f80e3494b8a491a9c07b9bd68",
      "26650e21252e4aedb873c75f70d57351",
      "164e9eaa1c6e4199a9911967133ab412",
      "8dc5bf80ed07465db6e81f6216dc9cf8",
      "e1bc464ba1a74188a617ba4642734ab3",
      "960747aac94b4584b52531f5e2f51fb7",
      "52d0dcf277fc4d918a1318d57e9668fa",
      "06f4fc7824d64b0fbf34846c6f48c809",
      "e366243f1ff14dac918c9f3bad118fca",
      "363c59d547934c31888bd41f032138b3",
      "294d241dc4fc4b96aafc93dc66c5a0b5",
      "a5838166c7ed47098f8ebd33b2f49548",
      "6cac09a320384406a2fd9b0cf2a664a4",
      "6dc2ec62a6de428ca0afab3709622587",
      "265cd62bd1fb47bea78346df41142be7",
      "1ffc9fa686a24a6191f94cf236599124",
      "21e1b53836d54140b4b1ec46baf5c1fe",
      "d5c0f58b13424479ac2568a88518533e",
      "f436265aa0294c658eb480269626e28c",
      "f730afc89c4841f79afdb52c349b47db",
      "d69ee0c6fd0a48d9868221778ddf1c1d",
      "4b55aee6fc154ad78df39d8427a37b67",
      "852064df6b9c4942bd7aa2e0d97c6ada",
      "be692dbbcc454c69b309eb5974b275a1",
      "2c34de580789464d9ac0ad42eb2c5efb",
      "9ea1e53c82b04b99bf0ab5a54263233e",
      "a38ee7d4424341608d20b5558839ad61",
      "5dcef4849f7f4b7f8aa470fd8dc415de",
      "623d09c5ea904cf18ee50f028888c98a",
      "70635843ab9d454cb3a2786738a328ba",
      "6d63dc1032b542c2b91704127e3e709a",
      "01fc3180649747d193ab8994a968aa1d",
      "8d44d22509fa40bebe869b1a33f007c9",
      "59a4e9ed421d4b678637884dd4d70534",
      "a848ed805fdd4ca7b91e5751885cbcdb",
      "650a4e3230a14dbd852394fa6eb47d8e",
      "48decba33ff542a8990574582a04a372",
      "76a9a0d3761348d1ac3542c7b132216d",
      "dd280e66291f4c7d87a42fcc28a547a2",
      "b081de2271114f408bb61e65bab8de65",
      "1209baba4e98449bae8dd893def414a3",
      "a248bb99eb1e4555b53442c5c9f1e11e",
      "19327bb4a1cf4e699d4618085f0da440",
      "575815320cc943309612ccf7a136003f",
      "13f4248a330e464b9c24ae6c8d04b4f0",
      "c6e9936f259448cebf568c28190fefe3",
      "00d881ce81dc422096319298d362ea55",
      "67c5ea3694ba45c1b74fe5f4f8e7c4e0",
      "b5973402409d41fd9da3384b667044d6",
      "c9761f5cf0c846b29bb2a6103463d66f",
      "dc832604dc5c4a6692bdb9cac1b22044",
      "20160732fa914b19aab3f5dfd945c4d7",
      "79146d757cd942b1a9f6474c3c45614d",
      "fde9fd17345d48fb9441443fb224a224",
      "0dd670586a104656996f2e82cd3c6116",
      "2af7c4abbce84e9a91b1a15674649d67",
      "82f566efa8c042a48481b400f600bc3d",
      "ca68944bdbc743c9abb10e1ffcb9c52f",
      "e56aacf1dca146fb85fac1708a8a03cc",
      "3106551538044d19912ad8c005ce89fd",
      "bf1424230f024011a8e8610d7bfbe4cf",
      "dae8153b49d544e6a2fcd3036b83a122",
      "4c5b578641964ff0b18111202087aff0",
      "becc48d53c4544ea99c018dfdccc5d12",
      "58d13fa757644754bafa0a03c8a91d24",
      "d7b9a58ec9e544bcb91e42c890e2a121",
      "652e3f7220964b5e9586694bfe64e143",
      "51efbe2b695c43cabfaf7a619ada56b5",
      "c0d7e0ec8641417f9484f32eac15deaa",
      "82b55a81b4b54fe7bf3f72f50f1ceea1",
      "e74800d247a24b3598107cfb3d4d4720",
      "225c4b56f02945dca79a37acb707e137",
      "3236dab40eba4b9b8215307651cf5d20",
      "eeb18cda85a64d1cb33dbac14cd56930",
      "cc8a6c7407254376b18e89f8a21098b0",
      "fc0f71f545414a3f90a67a774fd714d1",
      "d64c506f716647cb86d1acfe9ed50cef",
      "72685e08c9764892b86916cc6d32f3f5",
      "a61fbf717d6647d9ae72b62be87a9613",
      "d1ff895e7e75457b9380498dada63a94",
      "65fa116e5f5b4c5cba2ae2bf662aea28",
      "b582f412cdc24486a3fc3f351e5276fd",
      "c3ba82fcc2c1403db6d4bd44e6b19358",
      "3d960a5298604e578c6f1307d8344ecc",
      "ec88371e1bf64c9f86902c32a09886ba",
      "197ceab1d92f4b449f6450b8f74fccce",
      "4776ede2768b478fbd42b7039866a63f",
      "b21fe75554454a58bd937fe56b9c7ff7",
      "b36cbf158d444d0ab50a5a521f3751cb",
      "669383a1e9014ae182fab3e5dfdd69db",
      "1b4129fb3a164b6d924f25bed1bb1e88",
      "d546290a73c4468a88bccf6bd180cd1b",
      "e12a764e224c413285003b73f9040030",
      "6aff2427e55444c79c85b2333574a555",
      "3b82c42eb9324e3e84d293166d083b8f",
      "ec336bffedb94c7f8b28ab52780dd813",
      "c7e0a7e0101043b7981b5c66cd2af5b5",
      "2ac9ea7e922943738ba59d30272c9c71",
      "7cf3da7f99604aeb9f47982d01dde2a2",
      "743d8c9ec04943188fa5b08d65458bb3",
      "0deaa09650444fe08c1dcad8c3b7f4f4",
      "5723c5292f5145d79256e05efe13c434",
      "376112f5d0e04bd98eedf47d5f881e7e",
      "66b47ee45a6e48f6901d2ab041cea36a",
      "df5a65b4a567452fae4d69e1ac64b874",
      "8c947d2024894474bb0b03035ac30feb",
      "870c8bc58bb34cf0939d0d1af500aaad",
      "8cb64f67ac7a4cf58b3fa177cbe1415e",
      "ff80bdb3aaa24079a4e1997b8090fd91",
      "72c045fa68bc4478bdd89339f4646842",
      "e9123846c6aa4496a021b8d5009a64b5",
      "ff01917cd1774d3786f2161a30d2ddd2",
      "e1ecb2b5e2f94913ae4a64c8e414ccd8",
      "f2ac7ff0db6b4b739a233144128bedd0",
      "4bdc947c142b487e8b8a45d936284cc9",
      "b0854f5e739148b59e99febbfd70c24d",
      "722139fe17f84b22ae952e06ada34279",
      "ec345b1b7dd64323b7afb145d5aa7b37",
      "5f5efe8f0e514e398744591734789cb7",
      "c264a6a43b6a4ffda4536100ffd467d7",
      "d2f3b5f947634d3284995f59ab4a6ea5",
      "4876a76460a44624b18c95bb1a32116d",
      "ca87ce2e92bb4767a7aa1cc270a4cb23",
      "35efc9e79ced495c83b050cda56a847c",
      "54c63ca289bb4d65ad8caaa20e918566",
      "72febc287c6a4fb6863e745f207a89ea",
      "f072b0dedcee4d569d84926162251cc9",
      "d7319fa3a4e741199a5f3617bb1ae40b",
      "288a26454356499caf65ccf647c77977",
      "b5c03bd849844eb8b8ddde01ff299323",
      "514ab1c6a8fc44c78b92650c91bcf7e0",
      "2f384f9eafac4518b91e7d02f8cf6a98",
      "8b907caa704943bc8b1f2107793aee75",
      "9fd30d26ce2d40cc9d1d8e1cb88e9095",
      "347e307057ef45b9beed340af03f487f",
      "0a3b1b75585246d6ae31fc686ff895da",
      "949ae1107fd040c48b980a5930504023",
      "00463f198dba41abbc2a409fea89b66c",
      "c58e48f934ac46ecabe0322501084889",
      "194fceea257b446584f7959ea73e7c57",
      "740546ad41ef4ffba3f891c77ec0d360",
      "d7628dc2509340faa5ed65c72695c252",
      "d262b123c5ab4621b5032743fd6969cd",
      "01d5bf1aa92846c2827db0417ba7117a",
      "d965e18040c14ba48f9e28d4b90e781c",
      "0431af1a187446c3981a3948df65bb64",
      "a47be403bbb449be9c3444a0e06543c1",
      "fdf343e8cf3c4c8fad58c03c6920e945",
      "87026be309f14ddfa81d4b0a0435ad34",
      "bb7943326b6d407f98b71eea28d5e5da",
      "ea3f7167faca4b7096b025ae86a9894f",
      "d680b232e6a8490fb8eedf66c13d7d31",
      "4040dd5879d34d5babd03a8c61a9b313",
      "a6d9d059b8a04d589c4ecfd54c32226e",
      "f18639259fce4b3ca6bd3a9b43b0ea22",
      "104685563e3c453ab18f4636340d6897",
      "542d7520c614481baf1fb5e074a051c1",
      "630b5d7a20044d6bb64ef9c34c614e5d",
      "dd6cc8c86b804966af9c521ccbbb3e49",
      "3413ac67ff0d4e6bbdb33bcfa27e2791",
      "7d91b3554a0d46409094cc0eacf68105",
      "9326fcd81acc47e19a69560cbce97e29",
      "996a101966b74a84b19752921bbc1b51",
      "fe217e7dba7b4235a9b2c57193eef4e8",
      "9d530c5fbecd49d3a7dc0f84c193e589",
      "33780e4eb216431db50383c90b3ee9dc",
      "9410207ce0ad4eee98e5bd0f14731391",
      "6a982b2e3a384919bc45ba0572521594",
      "c0cbde5a69d845829a9f1ccba303d8c1",
      "b6fb9d6f50da4185a7687c78ef726911",
      "bb4e25a862244644ab9c2201a39de1e6",
      "b9ade77896a7442daa39ae3c64f11fa2",
      "6f962d451278445fbe787503a607dde2",
      "3a678c1d043d407a8752d56c66c29d00",
      "5868190042464d5bab317f7076eb8d5e",
      "a892524b6f8b4362b308cf66b09ca161",
      "410e1e20dbff4f2993b109dcf3d7321c",
      "e6550781580c43dcbe124f362c4d7a2f",
      "fdb9d783f00e4ab6a052b7de98a4abb5",
      "39aa5feed2a54f108df303fe20598439",
      "2ca385516123422db6564f3244dbb847",
      "840769ededd94f7d9ff9a1958f814053",
      "bac69dc97e7c468199a67a506a668223",
      "3c10f1807d02428e8517738c634615cc",
      "dc6c19131a524ec4bf20ed90240c06d6",
      "67a979267bf84994b452f0bedee6aedc",
      "7ba8234576b34d949bdd63e1ace299fd",
      "b1ad731c918c4d77a15f65f6f5c2a4ac",
      "515d3e7e00b540ecb56dd08906242243",
      "a76ebc470cda422caeced51a1bb6badf",
      "f7df5a81e0394267b09d18c2c3dd9bec",
      "caadd591d6e245728254d2b5d626d775",
      "b5a51ae312ba42db963d8cd8e1f87a0f",
      "0d66ed65312544aa900a7fd58adf385d",
      "f0cac98f51624bab84ba0294c22f269c",
      "f71d580d3c8541e9bbd8d08f7793667f",
      "138137ca54ed469097f7f46deaf9d391",
      "93133bb581fe4f96b4ca73777e12aebe",
      "d47d95cc41834923b0ce37176b75e561",
      "923702b909f9469b815f50df3e5dd9f5",
      "dade48b0e5524295aee8d2134f8f874a",
      "843a8ee0e66d4bd99ae73bae3d9e692d",
      "01416f46106f432d9a6b5f335fea698e",
      "f0285ad7e6ac4729951e2019c1c2e76a",
      "a820ffa7cb0e4f8ba5b25e5c9228e048",
      "22789fdcf5b5411ab605b83dd559e92f",
      "8c9a9a2a519c472c83d78f0cc3cb7628",
      "9e911b453f154900b4656699c85304cb",
      "d635346e247043678ab327c538e6a712",
      "dbf49e2eac344f60be9e135f40076dc7",
      "94baaf3ab804473da5dcc82faeaba4ad",
      "ee48147db97040648dd587d750fc2c22",
      "63b150ece27b432e8a05fdb0ee31a16d",
      "94ba051f8cbb4cccab19cc865106feb3",
      "4d3d973acbb44b419fdd30a068e0c556",
      "e1a02e4a99bf426a87e2499ae3d53e3b",
      "028a18aa3dc54e9db0f4cf3fa282b24b",
      "29c33c07cf344803a9faabda9ef91f75",
      "c9e4a540d8e1494b9be36b52bb80f9c0",
      "be11c3fb20174a15aeed475e2efdf14c",
      "f7bfd6d9722d4bfda9aa3bc82da829ce",
      "1419c827ac024476bbe2b8d79a18a16b",
      "2094e6d496ff42788ee861925d3dd360",
      "f321f8b2d2604a9ba638dd97103f311c",
      "63c6287a53074c20bd20a5191cf2c951",
      "d06243d88a1d4746a9fc0a49496c3379",
      "da47bd8967d74148b9d039021c950021",
      "ada1b0b95ffe4480acc0e5aee1200ccc",
      "a48133db150b457baa48165ea84b103e",
      "c05611e830bf48f7b4fd20dc7fba5da1",
      "cd81ee4fc1bb4a90bd44e6d9a34ae9ae",
      "5a0dcb6cffca4ed6910bc2d04d070aa7",
      "2073bcfab8424db9903f250fa61c1ac3",
      "fb2a3ed72df94b678409fe25587cd6e4",
      "ed8d50611b9d4aebbf2785e63338de9e",
      "9c6276fb4e6b405fb46dee83169a10b0",
      "216764dfe17f4642bac3282759413f6a",
      "0f088726311648af91b478ddc145140f",
      "8469689a013a4381960f21d7402cc51f",
      "d23c7bb708e043b6a3db6c9e1569cb78",
      "eac63cc8f6374529ada1959f2df00960",
      "31dc4d55261b41f2be2995033f45ee37",
      "cbf73dc3071248ff92f9b0cdd71cac45",
      "57d247fcf7d84032be4153076204169c",
      "fa183eb070044682b11ae72f46a7e4ed",
      "e9de73b645ac42cf8e403fe44d1275ff",
      "b7ba87c1129741dd95f107b934e593f3",
      "271e2c9dd1384c558ce3fdb017aa7654",
      "b9a1ac147ffa43c79f83d816992e0656",
      "c3a37e08d1b14b4eb159213bea510529",
      "dd65c6f29683483683616862015e76b2",
      "8d16894fca8b44f8a4474a9bbb724ee8",
      "17e06502cdb74af6bf6ae39579087d50",
      "a4f5f392e35045b2935aad2d95f7d19f",
      "39d83fb7daec48e3acf4cca70cf14262",
      "309a24754a5d41bb8b405b99ded68a6a",
      "8ab566b8f2f2494bbfd5ece5410980fe",
      "39339ea338954d71b582fe2ae4561486",
      "11b50bed669944f9b4ad29ac05db86c4",
      "31ab278988844162a4513620c8a14a72",
      "4dd909d9ced64922922a83d236f3d71f",
      "5bbb5088138e4e58b2e4260c5d962c6c",
      "68ed89ce970c448b96e921a6d56a88bd",
      "0476e4264b6d45199fda5aed8d0ce495",
      "999401e52e1e4023a0baa947e96d5223",
      "d1580496ca814ce19898562bba5c8105",
      "0a71ce15582542359255f28a963fda13",
      "562e9b18e2dc4dd4a9ae8ce2eff21b95",
      "d039484794da496fadcf021ebb88bc58",
      "635938ef1340479785acc5c00b1c0605",
      "214a4458185444babe36cc5333bfd3b5",
      "b6f76539e1ca411b9ed26b800c5d7aed",
      "49069f0037004f6a969decffe351e988",
      "f0a549f9aa0d4c7f8fcfc9a69ba5706b",
      "88fc231c744742eeb673abdcd2ea90a5",
      "f1cfe7ebc10e4bedae24be09c21aaa49",
      "715d51bf568c4f27bab94b63a4e08351",
      "3f1af61198e34bf89c49b9ded4441222",
      "22ed11fa923f4229a6988e10bb8b80f7",
      "ba108091763346f6bba495df4892c59b",
      "d2b75756a4bf4fcd8c566c698079830e",
      "89edee3c488f43f39240b5b3940cb00f",
      "f4133df0346843cba38a2e2d7b9c5297",
      "3bf1c0ffbb754384b352a14a535579b6",
      "dceae2ad6dfd4f91b9655d2cd0701c0c",
      "73108978f3294d988e85facd3a831ddd",
      "39c868ec1db9492e8cae503e2f8e9b6f",
      "32141b2c3c654e378c3f46c476532ba9",
      "5aba64fd38274cfe87465e88529bad19",
      "c308aecce05e47f08257fd0e9ba8ba91",
      "cf35f728fcdc4862b52a33897a790228",
      "fa802dbdace2463c8ec0baf4c4dd3310",
      "bb00908759c24f9f9e2f4fa20dfe3aeb",
      "79d27f8d00e740e2955def9a2b07252a",
      "983e19d2bcdb48a592c39a3f2a62ec9c",
      "46a0ce72568a41f681a4127de49a4dc1",
      "4efbfffa827e429891d007e34cde8933",
      "6b5b11aa0f0d42abbebe624c464be33e",
      "8fc7b9b81d3a46bf92dd959ec50e3c11",
      "95bd9431264a437d87ffd41698f1c3f6",
      "088c3de6307e40eaacc5f79a93057797",
      "ce3721ddcdb143469b87fd1ddc287fcb",
      "9c8b67be62f74e198febb5e58641d901",
      "68b4f75218234419a93fbcf6df1f8130",
      "9c4240ee277144d3885084eae2f01251",
      "ce5afbbbe75647d19494ec8ed1362d7c",
      "d1623b61df3f44beb59daab48e38f808",
      "00f0e926d31643179ff50f5a027abc82",
      "609f468594134311bcdf9e8ecd6255f1",
      "5e9af56df6db4816b1fbdf09ce662dee",
      "161d7ffa53764707a098ba63e2dfdc36",
      "3e049b061f1f4584a16a5041fe38e7c8",
      "a17508a261034b77bf533e89dab21c6c",
      "ab906ce98b3946a9ad96ee1cbee0b3ae",
      "abb8dde107da4df39a3a8925dfb5d9eb",
      "9931ace09a7e4dc1889613d9f6dea766",
      "cde223314a76442e90ca26bfaf9b9fdb",
      "c530017e27164f3b869f734b47c37acf",
      "4597f5860e31455cb9908057d216d38f",
      "69045eef5f0143cd97bb1c18d6af26bc",
      "c915c8a4b0054bbeb35233dfd2a640a6",
      "aae66102cb894addb728305494de1ee3",
      "29562a9245484e55b147964d0f53c42c",
      "6021bbb6be2841bc8004758137c43283",
      "44b70328c528413da83d5059d57f3f64",
      "273cc691d86c42568331436a2485f01c",
      "56220867092a482eab6cdc6919eadc3a",
      "ed9d2c071967453481bc54095468b827",
      "854d2b5b8c724ee7aa6108172076c570",
      "8afaa80f8f3b41f9ac345059ec60aaf6",
      "241992bee3db487ab9065550d5a31c6c",
      "8bd63f2508644a7e90189a7b671aab70",
      "a9cc21cd78304d1fa9c9cc67f5cce11e",
      "4d0478d2face424e891dba9c7cc2d0f2",
      "3f3834a6ca574104b9b6098a4b3c8f49",
      "76e732f699f540b08851caaae13b3833",
      "62c841cd20e24a799555574589d4684d",
      "1fe01ed2494640d88d71fd2a4fc430fb",
      "ae0f00dd8c2e40f98537679631ef2d7d",
      "0d48d454223c461a814a5859f4a92940",
      "4dc89ded42cb4ba0affc0c4a79e25721",
      "80b03a67f32a446eb0a9e5548874f2f7",
      "da725a5dd2f84e5eafde04d7ba89260a",
      "67a2401822f94f87b030471660d1eccc",
      "d2626e00fb91409da8a85d81e890811c",
      "89812902423d42d8950f98816f1fbd4f",
      "80aa80cc433c445894442d777325d570",
      "b6881bcf59b64c43a2668da5a06f1420",
      "ca59f5bf986148e8b1e8f8c4ac501205",
      "ba7d4e98102e49238fa47be723c76a34",
      "5bb9ec77752748f3bf1312fc92402f50",
      "5222660613a84f30aa217bc51ca3eeb7",
      "3f1a1f9e590149e6aa75fbaecf04e538",
      "d5ee3547d766466abc3367b487727859",
      "34e438a467ea46c8b09e7b1548c54cb8",
      "f4292d8d0ea8459096f5f243342dbd91",
      "812dce484b4a482bbd662f4ebb0dec52",
      "5a3572889f4741d787b6d14ee1eb5a67",
      "65323285de5f4ac79d1c62132663485b",
      "83ced5e5b262449cac358e9e5f639113",
      "e0e19e57f9e24d0fad7800873c2a55cb",
      "119d28e72c4442189af199991146b574",
      "1b6362c9f3a7419cab726dc6745cfac0",
      "d3df3b485612469c96ebb9d57b210d90",
      "3e08ce824ee6478a90e0d6ce36b86501",
      "2534823657e64fc889803c5cef3f775b",
      "38200e765e47408e872bc1b1ec455183",
      "e4425643e9464c63ae1271437776a1bd",
      "dad2c32af018426bad1a118fe0643aa9",
      "4b01916bc8c14d928da61129665ddba8",
      "1be521ac29c04e34b665f290adf78799",
      "5a271aaa9d30497aad0d2f1f315c5b8f",
      "d75f23dc5ab140a7b75a50d72ab429bd",
      "8e77e753fc494f7696146265bc50c354",
      "163a00a87a8940d49064461f19651365",
      "89235c732f4343dbb347d90358770dd4",
      "bdc650b750b94dcd832411356937fe82",
      "1fc6564fca824e25ad78d1762716a3e1",
      "e4d3fe404a4a47e089a0fb74e9fe582e",
      "5c9b2fdf92434ec49ee6a9cb595c50d1",
      "7b76830a1a984d90ace6b17af0576c03",
      "3602a016141846a88a0b59ca728b3bef",
      "d851828fe4734eb3a83df5da41427d96",
      "c9ae59db53e149d1a5db947b6646fc83",
      "f6265d2a17fe4fb0b2cf39fac6bc5a5d",
      "f4f0c44f58ae42a085fdb156b8124db9",
      "50a430d55f3a4ab09629309c88813705",
      "220bc986dcce4104b96d888b29885c93",
      "77599cba43594e0f93045fe14f8c94d4",
      "4fcd5d60dfc64b2bb5015145633edd5b",
      "5a3f15ae359048b5936e9812c08f6f38",
      "8add2b51b11c464d95953468dba5a744",
      "a209b53bde2b4f009b64e3d8bb85b41f",
      "0fcc140b1c8740cbacfd9e56b8c7f9dc",
      "962f8887c0c3474a91a3098d64a67859",
      "389875f82e1d4998af360402ddf114be",
      "7da7b2fee10c4c09b9877689acfb258b",
      "b96d93fb08aa4788b2c0f979f440f8b0",
      "51a4d4588a4e452088a2e5c1de22f3a1",
      "280d0cd8f8b84b569159e896bd31516b",
      "3032449742104e0d84af3986032e4ad1",
      "633ca70b94ee4e158785b0d0f264d54f",
      "bca474597c8747ad9f9ac9ff6267d24d",
      "269ff2702f42414eaefa11c63e858aec",
      "54c2795078a04b1f9acf2d6c0d6c5365",
      "2016c51acde245468875f678d286e3c0",
      "fd7e124f0534430dbf90c51c2fbdc423",
      "c11308fa80444c94b4754e1bc4040365",
      "56e7ee2254bf4756b5d123c5a4d97e97",
      "38f0f14d917f416797e43999a20f67c0",
      "cdfa5d8dd1af46cbae0b2cf342ba848a",
      "f19f247158df45f4b98e80b510ea1db8",
      "041ca9f6864241e5940720d9fa7c7330",
      "70ec1e8ff173420191aee2d15d0a11bb",
      "9843da8d8ebd44e4ab7d9e2fb1c2eaf3",
      "8f594f93e1a8448abbd8cf29edb4ddf6",
      "d368c8a157004bd7ada0889ffbd5f4c4",
      "020d3f1386fa4eb4bec22db01b904c5e",
      "cdd34d836ae940ea8c968fb658066ffa",
      "18a8f382d33f42d0ab10dc8e65fc6b6f",
      "40502fb2bc5a4ff2b63e1a31a826307e",
      "608e987cf6554a29948819b1d8c454ed",
      "ac3eb11144fd4433bcfda4eb76542fcd",
      "64bee82fbf0b46baabf101bc03680e70",
      "eaf73a67988d43339485777816cfed4f",
      "dfccb3eff6db45f7b722bdf4132e87e6",
      "26c554d023664b6a8e8dbe281f53a518",
      "27c8e6481bcb41bc9ad22b8930e9386c",
      "15bd0e42541c4ac18d5a8f378c1a9a9f",
      "cc35ea0743754c188f5b44c98c3ba7b1",
      "0ffe800358c941e39c422c6dfc6b7876",
      "39a733dcb85146ad846371aecb1cbeaa",
      "1226cf6a6cdc4cdebe1250def5b8b9ae",
      "ea6cdac5bea84f99a16acb3c6329e872",
      "8b5769cbdfb34ae48a7b9de439849789",
      "dc00661d18644a5ebbce07dcd2a10b0e",
      "37fc45449074416ca68befb4b37feb27",
      "48bdd2ff5ac9448db3e927ab176b057f",
      "bc63d39dbd9c4cfe8e328a5b1346d894",
      "c9bb937559174c41aad91f3e2249264d",
      "96e7bbd0c30a4a8e8a013a5a43e10529",
      "86f2b2755c1049fba7a767c34729f93e",
      "f266f90d47184315a407e270a1b5be47",
      "20ca39e668c248d7a0e9d1d98a7bde6f",
      "d550c9c9ade94416bcb5c55426b38f7a",
      "6d1ac773e9b140dc8d6085bc11761121",
      "109bed396a6d4f21b2558d09342ae456",
      "f8c227a31f3b4266aeec791f6f631144",
      "374fb76c294c438bb47fba502aa620b4",
      "b9a0df68f1534287a138ee906f1ac564",
      "056112082d29410e828fa03f064a73f7",
      "0ac76a6f15cd4d54bbbb1c471b873366",
      "fadf064ccdff4b339c67f180cbdfc4e7",
      "60b440ed91cd4183970aba82a339268a",
      "14017571e11a47e0bc769b60de01dabc",
      "65afaffaab99430689912eeaecfb62e9",
      "d6fb08421c7b493586f54bf97f6ee8d1",
      "775a781ee5a24b3fb9b1cf9be8c5d2f0",
      "38844cf534a64951bc41eec6fe914a19",
      "2fde5906062c431ca69f60a8d8102ab9",
      "0df66a0f85924000992a895ad51019f0",
      "1e5fbf15d0a24df68e481804c55246d5",
      "d10280d20a6f4a7bb0421eb06c10f0e8",
      "4e242459d93d41489b734b76fa34e4c2",
      "612a8c5656134fd293eda1b8178b7c61",
      "27c5cfdd9c254c45bb4f0e95a927beb6",
      "fffb97975d784f8e93fa7e2a3e2dd422",
      "e381c175b12c499dbe6790a750a6bd5b",
      "94dddff660864a86aac3fa57400c049b",
      "578c8022bb0f4dbaae7ec04a70be5834",
      "0133b6463386436999e58302a71562b6",
      "29b73f9d23a04086a8cdedd466ce4e18",
      "46e97d3dbaf740c9bf5eff334aa4b070",
      "627acc482f6045678f6c6adee321b914",
      "2dcc9b600b3646c7ac2f7fef31be7357",
      "8c6c32f89d62498085e966b5a2838711",
      "c344c724088047ccb8a02e3143ad8ee7",
      "37b8cfca65b945cca001954f70f3528c",
      "1466e0d5e61b43988c93b5e3dbd04b84",
      "ba19ab5bd51144d19ca66a50c4a424bc",
      "e1dc536dc9ec403d8e229abcd25a4c2c",
      "cb0e078822dd4ad4a8848587e3d381a6",
      "3a18148649d34c499cc7de8de95b117e",
      "e6c780a4c38b4ea18afbf5d7d9f54256",
      "18abd44e6681478aa110f225026e3c60",
      "59a1675cb97e438193dcfeb4d140e030",
      "bbc099f84c3549be8587975f04c0e96b",
      "9b4ec742816b4845a25687a432dc0ef1",
      "0df80931e4d0415abd5ae138d1428963",
      "0406a4da47774c45ba3df92ea5c4ef31",
      "0be97ecb51dd4c7d8c84ab1b7c514400",
      "bd62db7151444dd6a52c74f54f2fb128",
      "3bd3f0f396b74829887914d712d9edbb",
      "236e3b0b6ac3436cbef79a852de4f473",
      "a224c9c090834d8a892bcd279907f0da",
      "1535a673b6a740739267ae415ed778ab",
      "a5f60d5b459a4a06b71e4f0b8c49ae59",
      "c3515127600141aaa30d1359b77f5111",
      "0f60b6cdfa584e56ab4879bd53cf71e0",
      "519813a3d2d34571976d87823b36ecf8",
      "aef3cc74695e401ca05dadf3a29ce1a3",
      "0b0eef3030ea463b9c0e59f43949812b",
      "cf852d61ebe04d7eb6bf12f48674c79c",
      "76c4fd9c087446ec9e4db1cfb320d844",
      "ffbaeea91a35458a99074afdfd1f2b00",
      "fbe87b0d04d44859a13e3ae0a76406d4",
      "d7f4cee7d71b459f82491f5430743fa5",
      "3a4b7888d1974bbf9d5bd7b6ea356a2f",
      "abaf8efbc44d46679646a359ab786456",
      "5044fdd8643742bb9594266e3b2f5b2e",
      "251e0ef476914a0f8611e2fc0b3a8cc7",
      "6a9dd545b8154e309635dc73e584b318",
      "3a7564a979184a72ab8554a6e99cb4ad",
      "7afa17876b97434a8692dff29a383fb1",
      "08f5e57b2eca4558a138ea8211150618",
      "0b39bb33a6bf4163af72a09ad2628f6b",
      "c3b4da61e59d4248a29db3d16ccd82c6",
      "79111370ce254335a2b39186c9184130",
      "249a740e620b4cdd80c8a4ef3276e6e5",
      "ad0901d5134f4dd08325874efb781d58",
      "8383fe32f98f44f9b3fb42f1f966a44d",
      "978511d37e80404bac16a51b649b6fea",
      "642f85c657e84db5819b3f8e3a64fe7d",
      "ebf64a2d3f124437845977fffbc4db7f",
      "b68d0d17f5cf4dc0b55dead0923a047d",
      "0e26b2c77a534e318b38a05c0a577a9f",
      "99aeea30de2440ee9df6c01745975bb0",
      "5e95ad314f1c435688ae3839574a273d",
      "73168eb2889b42d2a8f88320d8ec8d5b",
      "71b9589e870040639366f3c37f5e6f04",
      "945381a603f5450f960f082a8b8176ba",
      "486e1bdc051a4a9cbdf522bc971fa97c",
      "e3ce2af2c0e5420a949b98280e313b95",
      "230e3b1febff482faf3e594394c40f48",
      "0b0d87700bd84c39a143ff46a8ab0830",
      "4003b8eda8284e718b9473bdb70106fb",
      "a28a3c5cd40e401b86dcb4051b4af3d4",
      "3fea9b5466fa444aa450f150f8dd349a",
      "bb445f47be4140e6b28fdc5849772f24",
      "25d62b6858a6428385a71896b2e78da9",
      "905fddbcd7524e909a541825c38eefa3",
      "08b413fd582b407e98eea9e315c15076",
      "165d2c46f6da4028bed3398053a16f7a",
      "be2ac0644e61418ea110b8b3eb5f7b00",
      "4423e0cf9fcb4504b0ee1ebc8848b836",
      "d4aac358a2394e05a8905f818c1772b7",
      "90dab3f12189418ab5da4d48ae9392d5",
      "4e713d0b4f7d4d66a3cbd6c9310f0072",
      "833708021b964354934a61a15d7c3424",
      "842e4bc82d8c45bcab32637986cf4f77",
      "02ad32329bc54e8e848cfba996e5efa8",
      "b5ddc158ab4f4a46b98928b430235fcc",
      "68aee18fc7954cbb9193f8c22ad985cb",
      "a0523262eb254f2e879a6efe4caf26dd",
      "f48e2d0b645f47ab95d090087f3dfeb6",
      "47e06933d11c41e8944c931b6d07600f",
      "e338a8574293445b9309974c95f124e2",
      "daa66bacffb54c808b6f3066a4cc753d",
      "ca1cec5982714c5ba079a707578a3c98",
      "71f7de2d0565440284a9518c439fffd1",
      "8933db2149564870a50762d8dd510312",
      "6d7a5a38062040eebc2a10ff43f6f480",
      "d6f37f76497244b59ee87ba84b09006e",
      "506f609017514fafbea3cfe7c7ec94fa",
      "5fc132fd39794e48831c586553ecbbcb",
      "e9f2218db1ed4c5a99b38d279fc6d66e",
      "ced4893af1e443aba2c8a8744b8e4424",
      "84332e48458b4c2c85ddc95d431413f8",
      "e127b044cf4845c7ade2a6457a72c2d1",
      "aae41890b2f543b4aa04b173278e60e2",
      "2901e06a9b6f46689493e671dc1d6ab8",
      "84828611577f4691ade4324238232a4b",
      "eec5145ec0ae4f0dbdb4170ab670c038",
      "e43d563bd3c14690bcdd82fea829785b",
      "635906f09c2240fcb796cde004bf6742",
      "f31aadc7f2a9456e9c8ce5d78e99d762",
      "7c12c8b33e0c497f91d84589c66bf139",
      "e3b123e2ee004d298575e8fb50e9ed0e",
      "da0d23e0726e431aa434258564be7a28",
      "1fbcb7ff4e924098beefd7098c3cd3e1",
      "e9b25132e6484cab8fa3dc5633e7652f",
      "f67f7903e4f64705b4dad3301b042663",
      "51753b1b508e4663a9c1ad41ef0f63b7",
      "555c9080907d4649b44ca2ddba1292ff",
      "00c60cded84f4685ab1e74d2f569014b",
      "16894412f3eb40f49ba675824c34c587",
      "b97538b25b634f539c996b3646188faf",
      "e4ffe8ef7b044d0a9023376257f94030",
      "f55fda145e6e4ed7abeb26a4413a54ff",
      "923eeb91877349ce85edb67098b5f237",
      "18b6a2cf256c469d83585351c14d94e0",
      "69bccdb556df4a678953e97f81824d96",
      "2f06b4cd6c214feeaee445aaf6a153f4",
      "d6787f62a4fe4e8eafb3867e5780c281",
      "86e538d95b2c4fa980bb9236445a1e25",
      "d461c9301e694d9ab733abe490fb48f9",
      "a73b37d8fd7648dbb9c8c0e777dc9b02",
      "8844b4f9e0964a3aaef3a526869b822a",
      "4daa8691274b437c9451170f8da7e057",
      "b7177a40789945eaa13b24a875cb2e85",
      "b1968cc6939141debfdbf231c788d6e1",
      "1710fe10ff4c40a0905df1e20c464970",
      "b389cc19f5b84811b0f05e438ad1dba3",
      "d97716d5b06440c797b4c67fb31872d2",
      "a8161e4dca9b407fb709531b10e8eb25",
      "dc30b202e6484a25a3732667cf0c9cd9",
      "c2a943db6a9e4e909d6e85cc1b3a6714",
      "72ff241cb8d04271aabca28b224ac523",
      "778fb5052dc54933b5a13c8a9c2d2a4f",
      "8021e30f036e4aeaa36739a947135eff",
      "a5c52346bfbd4973bb2d8734e01a0253",
      "3125d363b1f94394b88c1e6df2df7dcd",
      "a1b9e2e5009c4f1b9b6941cbc965355c",
      "516cc6e142bb4a31aa500895c1d9b752",
      "72577d54534445b38ed0fa134299c7c4",
      "42ffbd58f68d45c38e343c7b1a3abc5f",
      "ad43ee40283741e28c3aa0509dca121f",
      "00f190fd7ce347dabae326673d6d5875",
      "998c15c3307a45059625da9138786bf7",
      "f7d9d1334ac4448dad781655d157ac21",
      "4e0b27a42fdb4a28ab47fbff33c40381",
      "e28a9fa13ec54267ad35aca40bc9074e",
      "fac407f6f8c14c2b96d11433e443446a",
      "4bbdccce344d4813b97823440c51f7f5",
      "a4df2aca70cd429b8eb9e3d36ab04d5a",
      "7ad8e3cfdb034889a29c5032027d9d68",
      "8935706b26e642b28a10f712da8f2200",
      "e561f42c9a4245e7a9cc5ca3e22477e2",
      "52266ddcd2714317ada07b0b54aa33c2",
      "4eb0e5c10b6149b38f563796fcc04f4d",
      "0d33b5f37c7f41688d6157d3a416a092",
      "4c3d002c5ec249a8b70c07750c4efedb",
      "c5a3a40a2d144b6aaf7d5c79dc11b36b",
      "ac9450fa8ad44c1cb51ddb7e7a7a4bde",
      "63e061d309f54b55b7a99e98a1347c6f",
      "a863667b51484fd5b6eef86d87a2f3c5",
      "03c79b72e9e84bff9863698f52355357",
      "8cf7cade613d4c0995065e0013feae66",
      "c92c288691314a649bd75b2125bc6e20",
      "a4a9919eb36e4407a2fd2408add45586",
      "79c31958e53c497ca91de5236c889110",
      "3965da6fee734b368a477dde832ed5d9",
      "d908a30dc0ee4f8691382a1ea174573e",
      "3da0fa83bb9146328adaad4566a763b8",
      "c6a739c5c7d649a08d6fa8686be059db",
      "fb13353919d448c98a1c2e617a20def7",
      "f7165bc4ef484e19849b2f06b20d8823",
      "7680e84e76204c66b188f120debf68c1",
      "6719ea7ad29d42dca1790f3b1cdc925c",
      "d3ac400c23544da59bacb2a653ddfe66",
      "bbc47bb2c294432995761904586cfe2d",
      "a127f828622f49f297bd47e7cb75f2b4",
      "bfe9489b61954a029378c7ec9d17b861",
      "82f1349441cb406486e7090c73645b97",
      "dc62279797e3441d93407001ebaae14c",
      "a8670ed6e8dc4feea243476d700e83f2",
      "5ae74a5a02b9429b8fa40a8331ad786e",
      "071e5d40548e412fa8a5958205056fc9",
      "19e2bee03151479db7ff0e18f377e646",
      "87edd0e0dc054e81a112a3917578c45d",
      "e380aa4b7187496783c0726654eca89b",
      "c736c37a02064e6381928eda7cd9dae9",
      "20ab199c7a81408c8a31d90051734e23",
      "f26898799c454277af5f2e8c400dcc52",
      "4c68b7fdf34549b9835fe2a8ab27d1a3",
      "f87f4acb62c7489f965110a50fdaf603",
      "d1d423867b104d01b39b2ce2938c7b1c",
      "f1d19947a25b43e0a56bcab2b8607bd1",
      "d3aed2a029f44c54b07f61fd2734572c",
      "d4f7ca56b07f4925aee71a4208e4c01a",
      "981f4dc028764b57a63a7c3de295f574",
      "8de8559097284c4dac943939f64c4eb8",
      "ffa846883e7d479a819ed59716031973",
      "545c2854953446f69043d60d269ae670",
      "7f245d66dcfa4aa88d341b6e7ffd9706",
      "d6afa08a357443c1a4c375cae30d6631",
      "1401b0a8958a4ac7a902f39fd6809be2",
      "1b3052a1dcb844b78dfa1fc88cc7bc9d",
      "ac2af9d8f811465d80dbd879506f8603",
      "14b37514be3547b2afb34f11ecedffbe",
      "5d8e5ef27a964f009d28029665ec242f",
      "572ec5cbdfe34e0e882b4eac8f23f4c1",
      "6dbe4ef4c24c49f88005dc92ab6f6299",
      "da7bc532d94747e9ba7a026a795bf083",
      "a22a383ee6b649faa871bb6d1e721c44",
      "45a4d5ab758344eaab28d8d173f41a12",
      "d9c33ef808334b188f819e1050e89648",
      "2310b4d135964c00b4615c1cebf2612d",
      "29aaba2870614ad4b826fbe6b92489f2",
      "a225dd0b1f514acaab2b06a9330362d6",
      "9ecd1d80469c458fa7ef5e9b2d0a7249",
      "6604dd4ee9344741b1f79fc6bda55b35",
      "c354cb52fbbb40c3ad42a9a048975609",
      "9b7ec817c5b64eb7b8cc632a6eb158d2",
      "d99dbe7c38594594a03756699f07aed0",
      "592eaae749104b82be1a605c95752b7b",
      "102769da9d89467dafbb20999d286c8d",
      "08de11d46230492f95c28e156d395653",
      "7aae6414167a4d41934cfae03c699736",
      "a523574b37c24e00847e2afc7e1d59c2",
      "ba791707ed2f4b5b880b07097ace3c49",
      "63763489bd3846b8ba4ee6f159abaf7a",
      "939e5cb6bc1847f48922816b3dfe9d97",
      "010783af1d554e33ab37d4210b334c6c",
      "1c1067475c2d483d89e8b04bf01fec32",
      "2671096df559460fa076adbb0eb9f3a8",
      "5bfb5957185f4735b6b1f118b3f9aba0",
      "60fa9a29c2bd4c27b35d377d4ba04d32",
      "ca0a1ba5132641fdafb32d95a0839f90",
      "20c1ab65720d49209044abd3c6b8036f",
      "559a31e9fbf5498e9c1f8ed0c247eae8",
      "381e23a47f09433fb9601e721c3ab00e",
      "00c71c569dde4d64b0ac45dac36049e2",
      "cf4376ef9613405db979dba8186ed612",
      "d3586928328642d0b33a0b1cf8ee8470",
      "9c92bc1f4c864191a1cfbc3a31f22d7c",
      "2c947211004a4830939836731e875d1a",
      "d04325a3de864665a96448605932e14a",
      "1aa10f9152a44965aaa8e3399d4033df",
      "35542b7e03dc4049a302a8f1227c4de0",
      "c139fb1921d145c6a6c9e3c36dcee90c",
      "de00e49034ed47db8d190e0489d9e053",
      "379419e2bdae4151b0ffc9eafba44059",
      "464c8d25e62349c8bdf81a93e8b3f979",
      "33b7efcbc7764d10bf8d6af59fb266af",
      "110cbe3c678f474a8faf0c5b9869c3a5",
      "a525bb38f5b64976b2a8dd764088bcca",
      "92e13073ea5142d4a175bbe75ae515fb",
      "2576563a1e504106acf9bd476042427c",
      "61b7241416cb4af79e6fddda83b4e2b4",
      "d978551c873b4df9bfcc4da90f57e624",
      "adede640a8a040c781aa318578648c44",
      "36b7d97f458d401e83e419693786b58f",
      "3e16b94c52b54cdead46eaff00679e9b",
      "97ee5c3d396446369c21ddceea0b5d45",
      "5401a43266a049b9bbb390644c6af481",
      "f9a405be1dd546b6a80855fbee71fa9e",
      "97c1064a28384864b24fe3f2a6f7ebda",
      "6b8de683be434837a32cde1776df997d",
      "75278600f5524c74b49500451abe8f98",
      "922dd8fa012143b6989ab4eb735e0d16",
      "c8fb371f36c44091881801a75ea80c5c",
      "42d310a8db734d588cd30035dee8d5e2",
      "b04d8c8e719e49bf8f9f4aa17b8b238b",
      "aa67024fb6204b858b84f95394056047",
      "6ac5d24ace954e01bcf14a4875fa08a3",
      "8b81c66a7065468e984a860da13b368c",
      "d2add7b38b284982b88a66bf89d4b028",
      "3c83f6c1632a4766860f076ac15f69b7",
      "58741b72b2c74246986c076040ad2bed",
      "39bc64caec004307b103fefe638898ac",
      "08d0b9ae8f934c52a080c3db68fec42f",
      "ab7f2f2ec7c9417abac56cbf5684db67",
      "a02b81c2a0b142629ed132c8c9172bff",
      "bbe6905024a747c5b335b549c6cb7811",
      "21fa706a11cb43a3b33d05a744f92a47",
      "054ed40464ed414ca383c647a408dc0d",
      "06d87637146f4681920bf24fb6e08463",
      "ba164ab4ed5a4a189662f9ee72775a10",
      "62a9bfff294d45daa7fcfff48f59b2dc",
      "b1d6c5c354094aadb4dfaa7c85da3652",
      "427b886378ae4509a75376b2393c0ea9",
      "5928b40e6a624cc9b88c4d2305629267",
      "87559c8b7ec14b09a2c24ba84b41b370",
      "b8576df450824c3ea8f2730e7e4e4679",
      "d57bb1b4f77344b3bd6331a58c3acd96",
      "d620b364a4d54a168340693a93a77191",
      "6c6a3d2829b8464482d1687b623fbbe3",
      "2b65954658bb4e2abef55c0d5ceea6a1",
      "bc55333aa82a476fa73e63b1cc850b57",
      "5e625c3bf3e243678eaf4402eb1b776b",
      "af928ccf402d4ef1b1be9c13ae3099a7",
      "010b74b65e4b4a38b4480f910911eadd",
      "92fe8dbf771e41d786a176a54d515e17",
      "14fa9329b1ff4122a0196f2509e9e90b",
      "e6635f32147c41638cf655217375875a",
      "5e6fbb82428a4a7db91f3407c68ee391",
      "381c12362e02497aafe73cab24423703",
      "f13462aba0d54a45a83adad798af794a",
      "665ad53ba6744990b71314b6387da988",
      "4e7bf08e1dc14e36b9ba66f98e510691"
     ]
    },
    "id": "n3dXLwIHMejs",
    "outputId": "17509147-3289-4e54-ffbb-fae4f7f61010"
   },
   "outputs": [],
   "source": [
    "from src.data import MMLUDataset\n",
    "\n",
    "# Load MMLU validation set\n",
    "dataset = MMLUDataset(split=\"validation\")\n",
    "print(f\"Loaded {len(dataset)} examples\")\n",
    "\n",
    "# Sample for experiment\n",
    "NUM_SAMPLES = 2000  # Increased for better AUROC (was 300)\n",
    "examples = dataset.sample(NUM_SAMPLES, seed=42)\n",
    "print(f\"Using {len(examples)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoCv-p1MMejt"
   },
   "source": [
    "## 3. Generate Answers & Check Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6qrcgwC6Meju",
    "outputId": "4054e876-ea40-4feb-c434-f7d33c1e3234"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def generate_answer(model, tokenizer, prompt, max_new_tokens=32):\n",
    "    \"\"\"Generate model's answer to a question.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,  # Greedy for reproducibility\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    generated = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "    return generated.strip()\n",
    "\n",
    "def check_correctness(generated: str, example) -> bool:\n",
    "    \"\"\"Check if generated answer matches correct answer.\"\"\"\n",
    "    correct_answer = example.choices[example.answer]\n",
    "    correct_letter = chr(65 + example.answer)  # A, B, C, D\n",
    "    \n",
    "    generated_lower = generated.lower().strip()\n",
    "    \n",
    "    # Check for letter match\n",
    "    if generated_lower.startswith(correct_letter.lower()):\n",
    "        return True\n",
    "    \n",
    "    # Check for answer text match\n",
    "    if correct_answer.lower() in generated_lower:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Generate answers for all examples\n",
    "print(\"Generating model answers...\")\n",
    "prompts = []\n",
    "correctness = []\n",
    "\n",
    "for example in tqdm(examples):\n",
    "    prompt = example.format_prompt(style=\"multiple_choice\")\n",
    "    prompts.append(prompt)\n",
    "    \n",
    "    generated = generate_answer(model, tokenizer, prompt)\n",
    "    is_correct = check_correctness(generated, example)\n",
    "    correctness.append(int(is_correct))\n",
    "\n",
    "correctness = np.array(correctness)\n",
    "print(f\"\\nAccuracy: {correctness.mean():.1%} ({correctness.sum()}/{len(correctness)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeqsinqWMejv"
   },
   "source": [
    "## 4. Extract Hidden States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7LXZCXeMejv"
   },
   "outputs": [],
   "source": [
    "# Extract from middle layer only (where uncertainty signal is strongest)\n",
    "num_layers = loader.config.num_layers\n",
    "LAYER = num_layers // 2  # Middle layer\n",
    "\n",
    "print(f\"Extracting from layer {LAYER} (out of {num_layers} total)\")\n",
    "\n",
    "extractor = HiddenStateExtractor(model, tokenizer)\n",
    "hidden_states = extractor.extract(\n",
    "    texts=prompts,\n",
    "    layers=[LAYER],\n",
    "    batch_size=8,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "# Shape: (num_examples, 1, hidden_dim) -> (num_examples, hidden_dim)\n",
    "X = hidden_states[:, 0, :]\n",
    "y = correctness\n",
    "\n",
    "print(f\"Hidden states shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AS_kvbZhMejw"
   },
   "source": [
    "## 5. Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# K-Fold Cross-Validation Setup\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "NUM_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"Using {NUM_FOLDS}-fold stratified cross-validation\")\n",
    "print(f\"Total examples: {len(y)}\")\n",
    "print(f\"Each fold will use ~{len(y)//NUM_FOLDS} examples for testing\")\n",
    "print()\n",
    "\n",
    "# Initialize k-fold splitter\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# We'll store results from each fold\n",
    "# Structure: results[architecture_name] = {'auroc': [fold1, fold2, ...], 'brier': [...], 'ece': [...]}\n",
    "fold_results = {}\n",
    "\n",
    "print(\"K-fold split preview:\")\n",
    "for fold_idx, (train_val_idx, test_idx) in enumerate(skf.split(np.zeros(len(y)), y)):\n",
    "    # Further split train_val into train and val (80/20)\n",
    "    train_size = int(0.8 * len(train_val_idx))\n",
    "    print(f\"  Fold {fold_idx + 1}: {train_size} train, {len(train_val_idx) - train_size} val, {len(test_idx)} test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross-Validation Training Loop\n",
    "\n",
    "Train each probe architecture using k-fold CV for robust evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# K-Fold Training Loop\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "from src.probes import CalibratedProbe, build_default_network\n",
    "\n",
    "def compute_ece(confidences, labels, num_bins=10):\n",
    "    \"\"\"Compute Expected Calibration Error.\"\"\"\n",
    "    bin_boundaries = np.linspace(0, 1, num_bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(num_bins):\n",
    "        mask = (confidences > bin_boundaries[i]) & (confidences <= bin_boundaries[i + 1])\n",
    "        if mask.sum() > 0:\n",
    "            bin_conf = confidences[mask].mean()\n",
    "            bin_acc = labels[mask].mean()\n",
    "            ece += mask.sum() * abs(bin_conf - bin_acc)\n",
    "    return ece / len(confidences)\n",
    "\n",
    "# Dictionary to store results from all folds\n",
    "# Structure: fold_results[architecture_name][metric] = [fold1_value, fold2_value, ...]\n",
    "fold_results = {}\n",
    "\n",
    "# Define architectures to test\n",
    "architectures = {\n",
    "    'Linear': {'hidden_dim': None},\n",
    "    'MLP': {'hidden_dim': 256},\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"Training with {NUM_FOLDS}-Fold Cross-Validation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Loop through folds\n",
    "for fold_idx, (train_val_idx, test_idx) in enumerate(skf.split(np.zeros(len(y)), y)):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Fold {fold_idx + 1}/{NUM_FOLDS}\")\n",
    "    print('='*70)\n",
    "    \n",
    "    # Split train_val into train and val\n",
    "    np.random.seed(RANDOM_STATE + fold_idx)  # Different seed per fold\n",
    "    np.random.shuffle(train_val_idx)\n",
    "    train_size = int(0.8 * len(train_val_idx))\n",
    "    train_idx = train_val_idx[:train_size]\n",
    "    val_idx = train_val_idx[train_size:]\n",
    "    \n",
    "    print(f\"Train: {len(train_idx)}, Val: {len(val_idx)}, Test: {len(test_idx)}\")\n",
    "    \n",
    "    # Get data for this fold\n",
    "    X_train_fold = X[train_idx]\n",
    "    y_train_fold = y[train_idx]\n",
    "    X_val_fold = X[val_idx]\n",
    "    y_val_fold = y[val_idx]\n",
    "    X_test_fold = X[test_idx]\n",
    "    y_test_fold = y[test_idx]\n",
    "    \n",
    "    # Train each architecture on this fold\n",
    "    for arch_name, arch_config in architectures.items():\n",
    "        print(f\"\\n  Training {arch_name}...\")\n",
    "        \n",
    "        # Build network\n",
    "        network = build_default_network(\n",
    "            input_dim=X.shape[1],\n",
    "            hidden_dim=arch_config['hidden_dim']\n",
    "        )\n",
    "        probe = CalibratedProbe(network=network)\n",
    "        \n",
    "        # Train\n",
    "        probe.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            X_val_fold, y_val_fold,\n",
    "            batch_size=32,\n",
    "            num_epochs=100,\n",
    "            patience=10,\n",
    "            use_scheduler=True,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        confidences = probe.predict(X_test_fold)\n",
    "        predictions = (confidences > 0.5).astype(int)\n",
    "        \n",
    "        auroc = roc_auc_score(y_test_fold, confidences)\n",
    "        brier = brier_score_loss(y_test_fold, confidences)\n",
    "        ece = compute_ece(confidences, y_test_fold)\n",
    "        accuracy = (predictions == y_test_fold).mean()\n",
    "        \n",
    "        print(f\"    AUROC: {auroc:.4f}, Brier: {brier:.4f}, ECE: {ece:.4f}, Acc: {accuracy:.3f}\")\n",
    "        \n",
    "        # Store results\n",
    "        if arch_name not in fold_results:\n",
    "            fold_results[arch_name] = {'auroc': [], 'brier': [], 'ece': [], 'accuracy': []}\n",
    "        \n",
    "        fold_results[arch_name]['auroc'].append(auroc)\n",
    "        fold_results[arch_name]['brier'].append(brier)\n",
    "        fold_results[arch_name]['ece'].append(ece)\n",
    "        fold_results[arch_name]['accuracy'].append(accuracy)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"K-Fold Cross-Validation Complete!\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Report Aggregated K-Fold Results\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AGGREGATED RESULTS (Mean \u00b1 Std across folds)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create results table\n",
    "results_table = []\n",
    "for arch_name, metrics in fold_results.items():\n",
    "    row = {\n",
    "        'Architecture': arch_name,\n",
    "        'AUROC': f\"{np.mean(metrics['auroc']):.4f} \u00b1 {np.std(metrics['auroc']):.4f}\",\n",
    "        'Brier': f\"{np.mean(metrics['brier']):.4f} \u00b1 {np.std(metrics['brier']):.4f}\",\n",
    "        'ECE': f\"{np.mean(metrics['ece']):.4f} \u00b1 {np.std(metrics['ece']):.4f}\",\n",
    "        'Accuracy': f\"{np.mean(metrics['accuracy']):.3f} \u00b1 {np.std(metrics['accuracy']):.3f}\",\n",
    "    }\n",
    "    results_table.append(row)\n",
    "\n",
    "df = pd.DataFrame(results_table)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Store mean values for later comparison\n",
    "results = {}\n",
    "for arch_name, metrics in fold_results.items():\n",
    "    results[arch_name] = {\n",
    "        'auroc': np.mean(metrics['auroc']),\n",
    "        'auroc_std': np.std(metrics['auroc']),\n",
    "        'brier': np.mean(metrics['brier']),\n",
    "        'brier_std': np.std(metrics['brier']),\n",
    "        'ece': np.mean(metrics['ece']),\n",
    "        'ece_std': np.std(metrics['ece']),\n",
    "        'accuracy': np.mean(metrics['accuracy']),\n",
    "        'accuracy_std': np.std(metrics['accuracy']),\n",
    "    }\n",
    "\n",
    "print(\"\\n\u2713 Results stored in 'results' dictionary\")\n",
    "print(\"  Access via: results['Linear']['auroc']\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKyA8qAGMejw"
   },
   "source": [
    "## 6. Define Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-OKgk6NSDRp"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.modules.pop(\"src.probes\", None)\n",
    "sys.modules.pop(\"src.probes.architectures\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSiLywC_SEcM"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.probes\n",
    "importlib.reload(src.probes)\n",
    "\n",
    "import src.probes.architectures\n",
    "importlib.reload(src.probes.architectures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "al_i-5NgMejw"
   },
   "outputs": [],
   "source": [
    "from src.probes import (\n",
    "    CalibratedProbe,\n",
    "    build_default_network,\n",
    "    build_attention_network,\n",
    "    build_residual_network,\n",
    "    build_bottleneck_network,\n",
    "    build_multihead_network,\n",
    "    build_gated_network,\n",
    "    build_sparse_network,\n",
    "    build_heteroscedastic_network,\n",
    "    build_bilinear_network,\n",
    "    build_contrastive_network,\n",
    "    build_hierarchical_network,\n",
    "    build_sparse_attention_multihead_network,\n",
    ")\n",
    "from src.probes.architectures import build_hierarchical_network\n",
    "import torch.nn.functional as F\n",
    "\n",
    "INPUT_DIM = X.shape[1]  # Hidden dimension (3584 for Qwen2.5-7B)\n",
    "\n",
    "# Compute spurious direction for ContrastiveProbe\n",
    "# Use full dataset (not X_train) since this is for architecture definition\n",
    "X_t = torch.tensor(X, dtype=torch.float32)\n",
    "y_t = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Separate correct and incorrect examples\n",
    "correct_vecs = X_t[y_t == 1]    # Correct predictions\n",
    "incorrect_vecs = X_t[y_t == 0]  # Incorrect predictions\n",
    "\n",
    "# Compute direction of errors vs correct predictions\n",
    "spurious_direction = incorrect_vecs.mean(0) - correct_vecs.mean(0)\n",
    "\n",
    "# Normalize for contrastive penalty\n",
    "spurious_direction = F.normalize(spurious_direction, dim=0)\n",
    "\n",
    "# Final shape: (1, INPUT_DIM)\n",
    "spurious_directions = spurious_direction.unsqueeze(0)\n",
    "\n",
    "\n",
    "# Define all architectures to test\n",
    "ARCHITECTURES = {\n",
    "    \"Linear\": lambda: build_default_network(INPUT_DIM, hidden_dim=None),\n",
    "    \"Default MLP\": lambda: build_default_network(INPUT_DIM, hidden_dim=256),\n",
    "    \"Attention\": lambda: build_attention_network(INPUT_DIM, num_chunks=16, num_heads=4),\n",
    "    \"Residual\": lambda: build_residual_network(INPUT_DIM, hidden_dim=256, num_blocks=3),\n",
    "    \"Bottleneck\": lambda: build_bottleneck_network(INPUT_DIM, bottleneck_dim=64),\n",
    "    \"MultiHead\": lambda: build_multihead_network(INPUT_DIM, num_heads=4, head_dim=128),\n",
    "    \"Gated\": lambda: build_gated_network(INPUT_DIM, hidden_dim=256, num_layers=2),\n",
    "    \"Sparse (k=256)\": lambda: build_sparse_network(INPUT_DIM, k=256, hidden_dim=128),\n",
    "    \"Heteroscedastic\": lambda: build_heteroscedastic_network(INPUT_DIM, hidden_dim=256),\n",
    "    \"Bilinear\": lambda: build_bilinear_network(INPUT_DIM, num_factors=32, hidden_dim=128),\n",
    "    \"Contrastive\": lambda: build_contrastive_network(INPUT_DIM, spurious_directions=spurious_directions, dropout=0.1),\n",
    "    \"Hierarchical\": lambda: build_hierarchical_network(INPUT_DIM, num_chunks=16, hidden_dim=256, dropout=0.1),\n",
    "    # Hybrid: Combines Sparse + Attention + MultiHead\n",
    "    \"SparseAttnMH (Hybrid)\": lambda: build_sparse_attention_multihead_network(\n",
    "        INPUT_DIM, \n",
    "        num_chunks=16, \n",
    "        num_attention_heads=4,\n",
    "        num_expert_heads=4,\n",
    "        expert_hidden_dim=64,\n",
    "        dropout=0.1\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(f\"Testing {len(ARCHITECTURES)} architectures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yg0FMSULMejy"
   },
   "source": [
    "## 7. Train All Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rg7FdAA5Mejy"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "def compute_ece(confidences, labels, num_bins=10):\n",
    "    \"\"\"Compute Expected Calibration Error.\"\"\"\n",
    "    bin_boundaries = np.linspace(0, 1, num_bins + 1)\n",
    "    ece = 0.0\n",
    "\n",
    "    for i in range(num_bins):\n",
    "        mask = (confidences > bin_boundaries[i]) & (confidences <= bin_boundaries[i + 1])\n",
    "        if mask.sum() > 0:\n",
    "            bin_conf = confidences[mask].mean()\n",
    "            bin_acc = labels[mask].mean()\n",
    "            ece += mask.sum() * abs(bin_conf - bin_acc)\n",
    "\n",
    "    return ece / len(confidences)\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "# Training settings - NO early stopping, use scheduler for better convergence\n",
    "NUM_EPOCHS = 200\n",
    "PATIENCE = None  # Disable early stopping - train for full epochs\n",
    "\n",
    "for name, build_fn in ARCHITECTURES.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training: {name}\")\n",
    "    print('='*50)\n",
    "\n",
    "    # Build network and probe\n",
    "    network = build_fn()\n",
    "    probe = CalibratedProbe(network=network)\n",
    "\n",
    "    # Count parameters\n",
    "    num_params = sum(p.numel() for p in probe.parameters())\n",
    "    print(f\"Parameters: {num_params:,}\")\n",
    "\n",
    "    # Train with NO early stopping\n",
    "    history = probe.fit(\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        batch_size=32,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        patience=PATIENCE,  # None = no early stopping\n",
    "        use_scheduler=True,  # Cosine annealing LR\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # Evaluate on test set\n",
    "    confidences = probe.predict(X_test)\n",
    "    predictions = (confidences > 0.5).astype(int)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = (predictions == y_test).mean()\n",
    "    auroc = roc_auc_score(y_test, confidences)\n",
    "    brier = brier_score_loss(y_test, confidences)\n",
    "    ece = compute_ece(confidences, y_test)\n",
    "\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"auroc\": auroc,\n",
    "        \"brier\": brier,\n",
    "        \"ece\": ece,\n",
    "        \"num_params\": num_params,\n",
    "        \"best_epoch\": history[\"best_epoch\"],\n",
    "        \"confidences\": confidences,\n",
    "    }\n",
    "\n",
    "    print(f\"\\nTest Results:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  AUROC:    {auroc:.3f}\")\n",
    "    print(f\"  Brier:    {brier:.4f}\")\n",
    "    print(f\"  ECE:      {ece:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qThZ5EM-Mejz"
   },
   "source": [
    "## 8. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgmRyjg9Mejz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create results DataFrame\n",
    "df = pd.DataFrame({\n",
    "    name: {\n",
    "        \"Accuracy\": f\"{r['accuracy']:.3f}\",\n",
    "        \"AUROC\": f\"{r['auroc']:.3f}\",\n",
    "        \"Brier Score\": f\"{r['brier']:.4f}\",\n",
    "        \"ECE\": f\"{r['ece']:.4f}\",\n",
    "        \"Parameters\": f\"{r['num_params']:,}\",\n",
    "    }\n",
    "    for name, r in results.items()\n",
    "}).T\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ARCHITECTURE COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "al0uKZXhMejz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "names = list(results.keys())\n",
    "colors = sns.color_palette(\"husl\", len(names))\n",
    "\n",
    "# 1. AUROC comparison\n",
    "ax1 = axes[0, 0]\n",
    "aurocs = [results[n][\"auroc\"] for n in names]\n",
    "bars = ax1.barh(names, aurocs, color=colors)\n",
    "ax1.set_xlabel(\"AUROC (higher is better)\")\n",
    "ax1.set_title(\"Discrimination: AUROC\")\n",
    "ax1.set_xlim(0.5, 1.0)\n",
    "for bar, val in zip(bars, aurocs):\n",
    "    ax1.text(val + 0.01, bar.get_y() + bar.get_height()/2, f\"{val:.3f}\", va='center')\n",
    "\n",
    "# 2. Brier Score comparison\n",
    "ax2 = axes[0, 1]\n",
    "briers = [results[n][\"brier\"] for n in names]\n",
    "bars = ax2.barh(names, briers, color=colors)\n",
    "ax2.set_xlabel(\"Brier Score (lower is better)\")\n",
    "ax2.set_title(\"Calibration: Brier Score\")\n",
    "for bar, val in zip(bars, briers):\n",
    "    ax2.text(val + 0.005, bar.get_y() + bar.get_height()/2, f\"{val:.4f}\", va='center')\n",
    "\n",
    "# 3. ECE comparison\n",
    "ax3 = axes[1, 0]\n",
    "eces = [results[n][\"ece\"] for n in names]\n",
    "bars = ax3.barh(names, eces, color=colors)\n",
    "ax3.set_xlabel(\"ECE (lower is better)\")\n",
    "ax3.set_title(\"Calibration: Expected Calibration Error\")\n",
    "for bar, val in zip(bars, eces):\n",
    "    ax3.text(val + 0.005, bar.get_y() + bar.get_height()/2, f\"{val:.4f}\", va='center')\n",
    "\n",
    "# 4. Parameters vs AUROC (efficiency)\n",
    "ax4 = axes[1, 1]\n",
    "params = [results[n][\"num_params\"] for n in names]\n",
    "for i, name in enumerate(names):\n",
    "    ax4.scatter(params[i], aurocs[i], s=150, c=[colors[i]], label=name, edgecolors='black')\n",
    "ax4.set_xlabel(\"Number of Parameters\")\n",
    "ax4.set_ylabel(\"AUROC\")\n",
    "ax4.set_title(\"Efficiency: Parameters vs Performance\")\n",
    "ax4.set_xscale('log')\n",
    "ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"architecture_comparison.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: architecture_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnuFOi2EMejz"
   },
   "source": [
    "## 9. Reliability Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGtYtZ5RMejz"
   },
   "outputs": [],
   "source": [
    "def plot_reliability_diagram(confidences, labels, title, ax, num_bins=10):\n",
    "    \"\"\"Plot reliability diagram.\"\"\"\n",
    "    bin_boundaries = np.linspace(0, 1, num_bins + 1)\n",
    "    bin_centers = (bin_boundaries[:-1] + bin_boundaries[1:]) / 2\n",
    "\n",
    "    bin_accs = []\n",
    "    bin_confs = []\n",
    "    bin_counts = []\n",
    "\n",
    "    for i in range(num_bins):\n",
    "        mask = (confidences > bin_boundaries[i]) & (confidences <= bin_boundaries[i + 1])\n",
    "        if mask.sum() > 0:\n",
    "            bin_accs.append(labels[mask].mean())\n",
    "            bin_confs.append(confidences[mask].mean())\n",
    "            bin_counts.append(mask.sum())\n",
    "        else:\n",
    "            bin_accs.append(np.nan)\n",
    "            bin_confs.append(np.nan)\n",
    "            bin_counts.append(0)\n",
    "\n",
    "    # Plot\n",
    "    ax.bar(bin_centers, bin_accs, width=0.08, alpha=0.7, label='Accuracy')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', label='Perfect calibration')\n",
    "    ax.set_xlabel('Confidence')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "# Plot reliability diagrams for all architectures (4x4 grid for 13 architectures)\n",
    "num_archs = len(results)\n",
    "ncols = 4\n",
    "nrows = (num_archs + ncols - 1) // ncols  # Ceiling division\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(16, 4*nrows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, r) in enumerate(results.items()):\n",
    "    if i < len(axes):\n",
    "        plot_reliability_diagram(\n",
    "            r[\"confidences\"], y_test,\n",
    "            f\"{name}\\nECE={r['ece']:.4f}\",\n",
    "            axes[i]\n",
    "        )\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(len(results), len(axes)):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"reliability_diagrams.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: reliability_diagrams.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tQOCYVPMejz"
   },
   "source": [
    "## 10. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-k2NDEWMej0"
   },
   "outputs": [],
   "source": [
    "# Find best architectures for each metric\n",
    "best_auroc = max(results.items(), key=lambda x: x[1][\"auroc\"])\n",
    "best_brier = min(results.items(), key=lambda x: x[1][\"brier\"])\n",
    "best_ece = min(results.items(), key=lambda x: x[1][\"ece\"])\n",
    "best_efficiency = max(results.items(), key=lambda x: x[1][\"auroc\"] / np.log10(x[1][\"num_params\"]))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest Discrimination (AUROC): {best_auroc[0]}\")\n",
    "print(f\"  AUROC = {best_auroc[1]['auroc']:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Calibration (Brier): {best_brier[0]}\")\n",
    "print(f\"  Brier = {best_brier[1]['brier']:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Calibration (ECE): {best_ece[0]}\")\n",
    "print(f\"  ECE = {best_ece[1]['ece']:.4f}\")\n",
    "\n",
    "print(f\"\\nMost Efficient (AUROC/log(params)): {best_efficiency[0]}\")\n",
    "print(f\"  AUROC = {best_efficiency[1]['auroc']:.4f}, Params = {best_efficiency[1]['num_params']:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTES\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "- Lower Brier/ECE = better calibration (confidence matches accuracy)\n",
    "- Higher AUROC = better discrimination (separating correct/incorrect)\n",
    "- SparseProbe is most interpretable (shows which dimensions matter)\n",
    "- HeteroscedasticProbe handles varying example difficulty\n",
    "- For production: prioritize calibration (Brier/ECE)\n",
    "- For research: prioritize AUROC and interpretability\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvihzqsdMej0"
   },
   "source": [
    "## 11. Sparse Probe Analysis (Interpretability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fvg23sKGMej0"
   },
   "outputs": [],
   "source": [
    "# If SparseProbe performed well, analyze which dimensions it selected\n",
    "from src.probes.architectures import TopKSparseNetwork\n",
    "\n",
    "# Retrain sparse probe to access its learned importance weights\n",
    "sparse_network = build_sparse_network(INPUT_DIM, k=256, hidden_dim=128)\n",
    "sparse_probe = CalibratedProbe(network=sparse_network)\n",
    "sparse_probe.fit(X_train, y_train, X_val, y_val, num_epochs=200, patience=None, verbose=False)\n",
    "\n",
    "# Get importance scores using the new API\n",
    "importance = sparse_probe.network.get_importance_scores().cpu().numpy()\n",
    "\n",
    "# Find top dimensions\n",
    "top_k = 20\n",
    "top_indices = np.argsort(importance)[-top_k:][::-1]\n",
    "top_scores = importance[top_indices]\n",
    "\n",
    "print(f\"Top {top_k} most important dimensions for confidence:\")\n",
    "print(\"=\"*40)\n",
    "for idx, score in zip(top_indices, top_scores):\n",
    "    print(f\"  Dim {idx:4d}: importance = {score:.4f}\")\n",
    "\n",
    "# Plot importance distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(top_k), top_scores)\n",
    "plt.xlabel(\"Rank\")\n",
    "plt.ylabel(\"Importance Score\")\n",
    "plt.title(f\"Top {top_k} Dimensions\")\n",
    "plt.xticks(range(top_k), top_indices, rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(importance, bins=50, edgecolor='black')\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Importance Distribution (All Dimensions)\")\n",
    "# Show threshold for top-256 dimensions\n",
    "sorted_importance = np.sort(importance)[::-1]\n",
    "if len(sorted_importance) > 256:\n",
    "    threshold = sorted_importance[255]\n",
    "    plt.axvline(threshold, color='r', linestyle='--', label=f'Top 256 threshold ({threshold:.3f})')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"sparse_probe_importance.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: sparse_probe_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Geometric Analysis: Linear Separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Use test set for visualization (cleaner, no training bias)\n",
    "X_viz = X_test\n",
    "y_viz = y_test\n",
    "\n",
    "print(\"Running PCA...\")\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_viz)\n",
    "print(f\"Explained variance: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "print(\"Running t-SNE (this may take a few minutes)...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "X_tsne = tsne.fit_transform(X_viz)\n",
    "\n",
    "# Plot both visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# PCA visualization\n",
    "ax1 = axes[0]\n",
    "correct_mask = y_viz == 1\n",
    "incorrect_mask = y_viz == 0\n",
    "\n",
    "ax1.scatter(X_pca[correct_mask, 0], X_pca[correct_mask, 1], \n",
    "           c='green', label='Correct', alpha=0.6, s=20)\n",
    "ax1.scatter(X_pca[incorrect_mask, 0], X_pca[incorrect_mask, 1], \n",
    "           c='red', label='Incorrect', alpha=0.6, s=20)\n",
    "ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} var)')\n",
    "ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} var)')\n",
    "ax1.set_title('PCA: Hidden State Geometry')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# t-SNE visualization\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(X_tsne[correct_mask, 0], X_tsne[correct_mask, 1], \n",
    "           c='green', label='Correct', alpha=0.6, s=20)\n",
    "ax2.scatter(X_tsne[incorrect_mask, 0], X_tsne[incorrect_mask, 1], \n",
    "           c='red', label='Incorrect', alpha=0.6, s=20)\n",
    "ax2.set_xlabel('t-SNE Dimension 1')\n",
    "ax2.set_ylabel('t-SNE Dimension 2')\n",
    "ax2.set_title('t-SNE: Hidden State Geometry')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"geometric_analysis.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: geometric_analysis.png\")\n",
    "print(\"\\nObservation: If correct/incorrect clusters are well-separated,\")\n",
    "print(\"this explains why linear probes work well (linearly separable task).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Error Analysis: When Do Probes Fail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which examples all probes get wrong\n",
    "# Get predictions from Linear and Hierarchical probes\n",
    "linear_probe_name = \"Linear\"\n",
    "hierarchical_probe_name = \"Hierarchical\"\n",
    "\n",
    "linear_conf = results[linear_probe_name][\"confidences\"]\n",
    "hierarchical_conf = results[hierarchical_probe_name][\"confidences\"]\n",
    "\n",
    "linear_pred = (linear_conf > 0.5).astype(int)\n",
    "hierarchical_pred = (hierarchical_conf > 0.5).astype(int)\n",
    "\n",
    "# Find different error categories\n",
    "both_correct = (linear_pred == y_test) & (hierarchical_pred == y_test)\n",
    "both_wrong = (linear_pred != y_test) & (hierarchical_pred != y_test)\n",
    "linear_only_correct = (linear_pred == y_test) & (hierarchical_pred != y_test)\n",
    "hierarchical_only_correct = (linear_pred != y_test) & (hierarchical_pred == y_test)\n",
    "\n",
    "print(\"Error Analysis:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Both correct:              {both_correct.sum():4d} ({both_correct.mean():.1%})\")\n",
    "print(f\"Both wrong:                {both_wrong.sum():4d} ({both_wrong.mean():.1%})\")\n",
    "print(f\"Only Linear correct:       {linear_only_correct.sum():4d} ({linear_only_correct.mean():.1%})\")\n",
    "print(f\"Only Hierarchical correct: {hierarchical_only_correct.sum():4d} ({hierarchical_only_correct.mean():.1%})\")\n",
    "\n",
    "# Visualize confidence distributions for different error types\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Both correct\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(linear_conf[both_correct], bins=20, alpha=0.5, label='Linear', color='blue')\n",
    "ax1.hist(hierarchical_conf[both_correct], bins=20, alpha=0.5, label='Hierarchical', color='orange')\n",
    "ax1.set_xlabel('Confidence')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title(f'Both Correct (n={both_correct.sum()})')\n",
    "ax1.legend()\n",
    "ax1.axvline(0.5, color='red', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Both wrong\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(linear_conf[both_wrong], bins=20, alpha=0.5, label='Linear', color='blue')\n",
    "ax2.hist(hierarchical_conf[both_wrong], bins=20, alpha=0.5, label='Hierarchical', color='orange')\n",
    "ax2.set_xlabel('Confidence')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title(f'Both Wrong (n={both_wrong.sum()})')\n",
    "ax2.legend()\n",
    "ax2.axvline(0.5, color='red', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Only Linear correct\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(linear_conf[linear_only_correct], bins=20, alpha=0.5, label='Linear', color='blue')\n",
    "ax3.hist(hierarchical_conf[linear_only_correct], bins=20, alpha=0.5, label='Hierarchical', color='orange')\n",
    "ax3.set_xlabel('Confidence')\n",
    "ax3.set_ylabel('Count')\n",
    "ax3.set_title(f'Only Linear Correct (n={linear_only_correct.sum()})')\n",
    "ax3.legend()\n",
    "ax3.axvline(0.5, color='red', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Only Hierarchical correct\n",
    "ax4 = axes[1, 1]\n",
    "ax4.hist(linear_conf[hierarchical_only_correct], bins=20, alpha=0.5, label='Linear', color='blue')\n",
    "ax4.hist(hierarchical_conf[hierarchical_only_correct], bins=20, alpha=0.5, label='Hierarchical', color='orange')\n",
    "ax4.set_xlabel('Confidence')\n",
    "ax4.set_ylabel('Count')\n",
    "ax4.set_title(f'Only Hierarchical Correct (n={hierarchical_only_correct.sum()})')\n",
    "ax4.legend()\n",
    "ax4.axvline(0.5, color='red', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"error_analysis.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: error_analysis.png\")\n",
    "print(\"\\nObservation: If 'Only Hierarchical correct' is very small,\")\n",
    "print(\"this shows that hierarchical architecture doesn't help over linear.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Dimensionality Analysis: How Many Dimensions Matter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PCA to understand intrinsic dimensionality of uncertainty signal\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_train)\n",
    "\n",
    "cumsum_var = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# Find how many components needed for 90%, 95%, 99% variance\n",
    "dims_90 = np.argmax(cumsum_var >= 0.90) + 1\n",
    "dims_95 = np.argmax(cumsum_var >= 0.95) + 1\n",
    "dims_99 = np.argmax(cumsum_var >= 0.99) + 1\n",
    "\n",
    "print(\"Intrinsic Dimensionality Analysis:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total dimensions: {X_train.shape[1]}\")\n",
    "print(f\"Dimensions for 90% variance: {dims_90} ({dims_90/X_train.shape[1]:.1%} of total)\")\n",
    "print(f\"Dimensions for 95% variance: {dims_95} ({dims_95/X_train.shape[1]:.1%} of total)\")\n",
    "print(f\"Dimensions for 99% variance: {dims_99} ({dims_99/X_train.shape[1]:.1%} of total)\")\n",
    "\n",
    "# Plot explained variance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scree plot\n",
    "ax1 = axes[0]\n",
    "ax1.plot(range(1, 51), pca_full.explained_variance_ratio_[:50], 'bo-')\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Explained Variance Ratio')\n",
    "ax1.set_title('Scree Plot (First 50 Components)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative variance\n",
    "ax2 = axes[1]\n",
    "ax2.plot(range(1, min(500, len(cumsum_var))+1), cumsum_var[:500], 'r-', linewidth=2)\n",
    "ax2.axhline(0.90, color='blue', linestyle='--', label=f'90% ({dims_90} dims)')\n",
    "ax2.axhline(0.95, color='green', linestyle='--', label=f'95% ({dims_95} dims)')\n",
    "ax2.axhline(0.99, color='orange', linestyle='--', label=f'99% ({dims_99} dims)')\n",
    "ax2.set_xlabel('Number of Components')\n",
    "ax2.set_ylabel('Cumulative Explained Variance')\n",
    "ax2.set_title('Cumulative Variance Explained')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0.8, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"dimensionality_analysis.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: dimensionality_analysis.png\")\n",
    "print(\"\\nObservation: If uncertainty can be captured in few dimensions,\")\n",
    "print(\"this explains why simple probes work (low intrinsic dimensionality).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Layer-Wise Analysis: Which Layer Encodes Uncertainty Best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hidden states from multiple layers and compare\n",
    "layer_results = {}\n",
    "\n",
    "# Test layers: early, middle, late, final\n",
    "test_layers = [\n",
    "    num_layers // 4,      # Early (Q1)\n",
    "    num_layers // 2,      # Middle (Q2)\n",
    "    3 * num_layers // 4,  # Late (Q3)\n",
    "    num_layers - 1        # Final\n",
    "]\n",
    "\n",
    "print(\"Extracting and evaluating layer-wise probes...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for layer_idx in test_layers:\n",
    "    print(f\"\\nLayer {layer_idx}/{num_layers-1}:\")\n",
    "    \n",
    "    # Extract from this layer\n",
    "    layer_hiddens = extractor.extract(\n",
    "        texts=prompts,\n",
    "        layers=[layer_idx],\n",
    "        batch_size=8,\n",
    "        show_progress=False,\n",
    "    )\n",
    "    \n",
    "    X_layer = layer_hiddens[:, 0, :]\n",
    "    \n",
    "    # Split data\n",
    "    X_train_l, X_temp_l, y_train_l, y_temp_l = train_test_split(\n",
    "        X_layer, y, test_size=0.4, random_state=42, stratify=y\n",
    "    )\n",
    "    X_val_l, X_test_l, y_val_l, y_test_l = train_test_split(\n",
    "        X_temp_l, y_temp_l, test_size=0.5, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    # Train simple linear probe\n",
    "    network = build_default_network(X_layer.shape[1], hidden_dim=None)\n",
    "    probe = CalibratedProbe(network=network)\n",
    "    \n",
    "    history = probe.fit(\n",
    "        X_train_l, y_train_l,\n",
    "        X_val_l, y_val_l,\n",
    "        batch_size=32,\n",
    "        num_epochs=100,\n",
    "        patience=10,\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    confidences_l = probe.predict(X_test_l)\n",
    "    auroc_l = roc_auc_score(y_test_l, confidences_l)\n",
    "    brier_l = brier_score_loss(y_test_l, confidences_l)\n",
    "    ece_l = compute_ece(confidences_l, y_test_l)\n",
    "    \n",
    "    layer_results[layer_idx] = {\n",
    "        'auroc': auroc_l,\n",
    "        'brier': brier_l,\n",
    "        'ece': ece_l,\n",
    "    }\n",
    "    \n",
    "    print(f\"  AUROC: {auroc_l:.4f}, Brier: {brier_l:.4f}, ECE: {ece_l:.4f}\")\n",
    "\n",
    "# Visualize layer-wise performance\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "layers = list(layer_results.keys())\n",
    "aurocs = [layer_results[l]['auroc'] for l in layers]\n",
    "briers = [layer_results[l]['brier'] for l in layers]\n",
    "eces = [layer_results[l]['ece'] for l in layers]\n",
    "\n",
    "# AUROC vs Layer\n",
    "ax1 = axes[0]\n",
    "ax1.plot(layers, aurocs, 'bo-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Layer Index')\n",
    "ax1.set_ylabel('AUROC')\n",
    "ax1.set_title('Discrimination by Layer')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(max(aurocs), color='red', linestyle='--', alpha=0.3, label=f'Best: Layer {layers[aurocs.index(max(aurocs))]}')\n",
    "ax1.legend()\n",
    "\n",
    "# Brier vs Layer\n",
    "ax2 = axes[1]\n",
    "ax2.plot(layers, briers, 'go-', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Layer Index')\n",
    "ax2.set_ylabel('Brier Score')\n",
    "ax2.set_title('Calibration by Layer')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(min(briers), color='red', linestyle='--', alpha=0.3, label=f'Best: Layer {layers[briers.index(min(briers))]}')\n",
    "ax2.legend()\n",
    "\n",
    "# ECE vs Layer\n",
    "ax3 = axes[2]\n",
    "ax3.plot(layers, eces, 'ro-', linewidth=2, markersize=8)\n",
    "ax3.set_xlabel('Layer Index')\n",
    "ax3.set_ylabel('ECE')\n",
    "ax3.set_title('Expected Calibration Error by Layer')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.axhline(min(eces), color='red', linestyle='--', alpha=0.3, label=f'Best: Layer {layers[eces.index(min(eces))]}')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"layer_analysis.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: layer_analysis.png\")\n",
    "\n",
    "best_auroc_layer = layers[aurocs.index(max(aurocs))]\n",
    "print(f\"\\nBest layer for AUROC: {best_auroc_layer} (AUROC={max(aurocs):.4f})\")\n",
    "print(\"\\nObservation: Middle layers often perform best for uncertainty,\")\n",
    "print(\"confirming prior research (Azaria & Mitchell 2023).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Summary of Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"KEY FINDINGS: When Are Complex Probes Necessary?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. ARCHITECTURE COMPARISON:\")\n",
    "print(\"   \" + \"-\"*60)\n",
    "auroc_range = max([r['auroc'] for r in results.values()]) - min([r['auroc'] for r in results.values()])\n",
    "print(f\"   AUROC range across architectures: {auroc_range:.4f}\")\n",
    "print(f\"   Best: {best_auroc[0]} ({best_auroc[1]['auroc']:.4f})\")\n",
    "print(f\"   Simplest (Linear): {results['Linear']['auroc']:.4f}\")\n",
    "if auroc_range < 0.05:\n",
    "    print(\"   \u2192 All architectures perform similarly (task is linearly separable!)\")\n",
    "else:\n",
    "    print(\"   \u2192 Complex architectures provide benefit\")\n",
    "\n",
    "print(\"\\n2. GEOMETRIC STRUCTURE:\")\n",
    "print(\"   \" + \"-\"*60)\n",
    "print(f\"   PCA 2D variance explained: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "if pca.explained_variance_ratio_.sum() > 0.15:\n",
    "    print(\"   \u2192 Correct/incorrect are well-separated in 2D\")\n",
    "    print(\"   \u2192 Explains why linear probes work well\")\n",
    "else:\n",
    "    print(\"   \u2192 Low 2D separation, task may be complex\")\n",
    "\n",
    "print(\"\\n3. INTRINSIC DIMENSIONALITY:\")\n",
    "print(\"   \" + \"-\"*60)\n",
    "print(f\"   Dimensions for 90% variance: {dims_90}/{X_train.shape[1]} ({dims_90/X_train.shape[1]:.1%})\")\n",
    "if dims_90 < X_train.shape[1] * 0.1:\n",
    "    print(\"   \u2192 Low intrinsic dimensionality\")\n",
    "    print(\"   \u2192 Simple probes sufficient\")\n",
    "else:\n",
    "    print(\"   \u2192 High intrinsic dimensionality\")\n",
    "    print(\"   \u2192 Complex probes may help\")\n",
    "\n",
    "print(\"\\n4. ERROR ANALYSIS:\")\n",
    "print(\"   \" + \"-\"*60)\n",
    "disagreement_rate = (linear_only_correct.sum() + hierarchical_only_correct.sum()) / len(y_test)\n",
    "print(f\"   Disagreement rate: {disagreement_rate:.1%}\")\n",
    "if disagreement_rate < 0.05:\n",
    "    print(\"   \u2192 Probes make same mistakes\")\n",
    "    print(\"   \u2192 No benefit from complexity\")\n",
    "else:\n",
    "    print(\"   \u2192 Probes complement each other\")\n",
    "    print(\"   \u2192 Ensembling may help\")\n",
    "\n",
    "print(\"\\n5. LAYER-WISE PERFORMANCE:\")\n",
    "print(\"   \" + \"-\"*60)\n",
    "print(f\"   Best layer: {best_auroc_layer} (AUROC={max(aurocs):.4f})\")\n",
    "print(f\"   Layer {LAYER} (current): {results[linear_probe_name]['auroc']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONCLUSION:\")\n",
    "print(\"=\"*70)\n",
    "print(\"Linear probes are sufficient when:\")\n",
    "print(\"  - Task is linearly separable in hidden space (PCA shows clear separation)\")\n",
    "print(\"  - Low intrinsic dimensionality (< 10% of features needed)\")\n",
    "print(\"  - All probes make similar errors (no complementarity)\")\n",
    "print(\"\\nComplex probes help when:\")\n",
    "print(\"  - High intrinsic dimensionality\")\n",
    "print(\"  - Different architectures capture different error patterns\")\n",
    "print(\"  - Multi-scale or sequential structure in the data\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Layer-Ensemble Probe: Multi-Layer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Layer-Ensemble probe which requires multi-layer extraction\n",
    "print(\"Testing Layer-Ensemble Probe (requires multi-layer extraction)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract from 4 layers\n",
    "ensemble_layers = [\n",
    "    num_layers // 4,      # Early (Q1)\n",
    "    num_layers // 2,      # Middle (Q2)\n",
    "    3 * num_layers // 4,  # Late (Q3)\n",
    "    num_layers - 1        # Final\n",
    "]\n",
    "\n",
    "print(f\"Extracting from layers: {ensemble_layers}\")\n",
    "\n",
    "# Extract multi-layer hidden states\n",
    "ensemble_hiddens = extractor.extract(\n",
    "    texts=prompts,\n",
    "    layers=ensemble_layers,\n",
    "    batch_size=8,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "print(f\"Multi-layer hidden states shape: {ensemble_hiddens.shape}\")\n",
    "\n",
    "# Flatten: (batch, num_layers, hidden) -> (batch, num_layers * hidden)\n",
    "X_ensemble = ensemble_hiddens.reshape(ensemble_hiddens.shape[0], -1)\n",
    "print(f\"Flattened shape: {X_ensemble.shape}\")\n",
    "\n",
    "# Split data\n",
    "X_train_ens, X_temp_ens, y_train_ens, y_temp_ens = train_test_split(\n",
    "    X_ensemble, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "X_val_ens, X_test_ens, y_val_ens, y_test_ens = train_test_split(\n",
    "    X_temp_ens, y_temp_ens, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# Build layer-ensemble network\n",
    "from src.probes import build_layer_ensemble_network\n",
    "\n",
    "network = build_layer_ensemble_network(\n",
    "    input_dim=X_ensemble.shape[1],\n",
    "    num_layers=len(ensemble_layers),\n",
    "    layer_probe_hidden=64,  # Small MLP per layer\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "probe_ensemble = CalibratedProbe(network=network)\n",
    "\n",
    "# Count parameters\n",
    "num_params_ens = sum(p.numel() for p in probe_ensemble.parameters())\n",
    "print(f\"\\nLayer-Ensemble parameters: {num_params_ens:,}\")\n",
    "\n",
    "# Train\n",
    "print(\"\\nTraining Layer-Ensemble probe...\")\n",
    "history_ens = probe_ensemble.fit(\n",
    "    X_train_ens, y_train_ens,\n",
    "    X_val_ens, y_val_ens,\n",
    "    batch_size=32,\n",
    "    num_epochs=200,\n",
    "    patience=None,\n",
    "    use_scheduler=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "confidences_ens = probe_ensemble.predict(X_test_ens)\n",
    "predictions_ens = (confidences_ens > 0.5).astype(int)\n",
    "\n",
    "accuracy_ens = (predictions_ens == y_test_ens).mean()\n",
    "auroc_ens = roc_auc_score(y_test_ens, confidences_ens)\n",
    "brier_ens = brier_score_loss(y_test_ens, confidences_ens)\n",
    "ece_ens = compute_ece(confidences_ens, y_test_ens)\n",
    "\n",
    "print(f\"\\nLayer-Ensemble Test Results:\")\n",
    "print(f\"  Accuracy: {accuracy_ens:.3f}\")\n",
    "print(f\"  AUROC:    {auroc_ens:.3f}\")\n",
    "print(f\"  Brier:    {brier_ens:.4f}\")\n",
    "print(f\"  ECE:      {ece_ens:.4f}\")\n",
    "\n",
    "# Get learned layer weights\n",
    "layer_weights = probe_ensemble.network.get_layer_weights().numpy()\n",
    "\n",
    "print(f\"\\nLearned Layer Weights:\")\n",
    "for i, (layer_idx, weight) in enumerate(zip(ensemble_layers, layer_weights)):\n",
    "    layer_name = [\"Early\", \"Middle\", \"Late\", \"Final\"][i]\n",
    "    print(f\"  Layer {layer_idx:2d} ({layer_name:6s}): {weight:.4f}\")\n",
    "\n",
    "# Compare to single-layer linear probe\n",
    "print(f\"\\nComparison to Single-Layer Linear:\")\n",
    "print(f\"  Linear (middle layer): AUROC={results['Linear']['auroc']:.4f}, Brier={results['Linear']['brier']:.4f}\")\n",
    "print(f\"  Layer-Ensemble:        AUROC={auroc_ens:.4f}, Brier={brier_ens:.4f}\")\n",
    "\n",
    "improvement_auroc = auroc_ens - results['Linear']['auroc']\n",
    "improvement_brier = results['Linear']['brier'] - brier_ens  # Lower is better\n",
    "\n",
    "print(f\"\\nImprovement:\")\n",
    "print(f\"  AUROC: {improvement_auroc:+.4f}\")\n",
    "print(f\"  Brier: {improvement_brier:+.4f}\")\n",
    "\n",
    "if improvement_auroc > 0.01:\n",
    "    print(\"  \u2192 Layer-ensemble provides meaningful improvement!\")\n",
    "else:\n",
    "    print(\"  \u2192 Single layer is sufficient (minimal benefit from ensembling)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize learned layer weights\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "layer_names = [f\"Layer {idx}\\n({'Early' if i==0 else 'Middle' if i==1 else 'Late' if i==2 else 'Final'})\" \n",
    "               for i, idx in enumerate(ensemble_layers)]\n",
    "\n",
    "ax.bar(layer_names, layer_weights, color=['lightblue', 'blue', 'darkblue', 'navy'], \n",
    "       edgecolor='black', linewidth=1.5)\n",
    "ax.set_ylabel('Ensemble Weight', fontsize=12)\n",
    "ax.set_title('Learned Layer Weights for Uncertainty Prediction', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim([0, max(layer_weights) * 1.2])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (name, weight) in enumerate(zip(layer_names, layer_weights)):\n",
    "    ax.text(i, weight + 0.01, f'{weight:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"layer_ensemble_weights.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: layer_ensemble_weights.png\")\n",
    "print(\"\\nInterpretation:\")\n",
    "if layer_weights[1] > max(layer_weights[0], layer_weights[2], layer_weights[3]):\n",
    "    print(\"  \u2192 Middle layer dominates (confirms prior research)\")\n",
    "elif abs(layer_weights[0] - layer_weights[1]) < 0.05 and abs(layer_weights[2] - layer_weights[3]) < 0.05:\n",
    "    print(\"  \u2192 Weights are relatively balanced (all layers contribute)\")\n",
    "else:\n",
    "    print(f\"  \u2192 Layer {ensemble_layers[layer_weights.argmax()]} is most important\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Task Type Analysis: When Do Probes Fail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze probe performance across different MMLU subject categories\n",
    "print(\"Analyzing probe performance by task type...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define subject categories\n",
    "subject_categories = {\n",
    "    'STEM': ['abstract_algebra', 'astronomy', 'college_biology', 'college_chemistry',\n",
    "             'college_computer_science', 'college_mathematics', 'college_physics',\n",
    "             'computer_security', 'conceptual_physics', 'electrical_engineering',\n",
    "             'elementary_mathematics', 'high_school_biology', 'high_school_chemistry',\n",
    "             'high_school_computer_science', 'high_school_mathematics',\n",
    "             'high_school_physics', 'machine_learning'],\n",
    "    'Humanities': ['formal_logic', 'high_school_european_history', 'high_school_us_history',\n",
    "                   'high_school_world_history', 'prehistory', 'world_religions',\n",
    "                   'philosophy', 'moral_scenarios'],\n",
    "    'Social Sciences': ['high_school_geography', 'high_school_government_and_politics',\n",
    "                        'high_school_macroeconomics', 'high_school_microeconomics',\n",
    "                        'high_school_psychology', 'econometrics', 'sociology',\n",
    "                        'us_foreign_policy', 'public_relations'],\n",
    "    'Other': ['anatomy', 'business_ethics', 'clinical_knowledge', 'college_medicine',\n",
    "              'human_aging', 'human_sexuality', 'medical_genetics', 'nutrition',\n",
    "              'professional_accounting', 'professional_law', 'professional_medicine',\n",
    "              'professional_psychology', 'virology', 'global_facts', 'jurisprudence',\n",
    "              'logical_fallacies', 'management', 'marketing', 'miscellaneous',\n",
    "              'moral_disputes', 'security_studies']\n",
    "}\n",
    "\n",
    "# Get subject for each example from metadata\n",
    "# The examples already have metadata with 'subject' field!\n",
    "example_subjects = [ex.metadata['subject'] for ex in examples]\n",
    "\n",
    "# Categorize each example\n",
    "example_categories = []\n",
    "for subj in example_subjects:\n",
    "    for category, subjects in subject_categories.items():\n",
    "        if subj in subjects:\n",
    "            example_categories.append(category)\n",
    "            break\n",
    "    else:\n",
    "        example_categories.append('Other')\n",
    "\n",
    "example_categories = np.array(example_categories)\n",
    "\n",
    "# Analyze probe performance by category using test set\n",
    "# Get predictions from linear probe\n",
    "linear_conf = results[\"Linear\"][\"confidences\"]\n",
    "linear_pred = (linear_conf > 0.5).astype(int)\n",
    "\n",
    "# Map test indices back to categories\n",
    "# Get test set category distribution\n",
    "# We need to track which indices went to test set\n",
    "# Use the same random state as train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_, test_idx = train_test_split(\n",
    "    np.arange(len(X)), test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "_, test_idx_final = train_test_split(\n",
    "    test_idx, test_size=0.5, random_state=42, stratify=y[test_idx]\n",
    ")\n",
    "\n",
    "test_categories = example_categories[test_idx_final]\n",
    "\n",
    "# Compute metrics by category\n",
    "category_results = {}\n",
    "\n",
    "for category in ['STEM', 'Humanities', 'Social Sciences', 'Other']:\n",
    "    mask = test_categories == category\n",
    "    if mask.sum() < 10:  # Skip if too few examples\n",
    "        continue\n",
    "\n",
    "    cat_y = y_test[mask]\n",
    "    cat_conf = linear_conf[mask]\n",
    "    cat_pred = linear_pred[mask]\n",
    "\n",
    "    # Compute metrics\n",
    "    cat_acc = (cat_pred == cat_y).mean()\n",
    "    cat_auroc = roc_auc_score(cat_y, cat_conf) if len(np.unique(cat_y)) > 1 else np.nan\n",
    "    cat_brier = brier_score_loss(cat_y, cat_conf)\n",
    "    cat_ece = compute_ece(cat_conf, cat_y)\n",
    "\n",
    "    category_results[category] = {\n",
    "        'n_examples': mask.sum(),\n",
    "        'model_accuracy': cat_y.mean(),\n",
    "        'probe_accuracy': cat_acc,\n",
    "        'auroc': cat_auroc,\n",
    "        'brier': cat_brier,\n",
    "        'ece': cat_ece\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{category}:\")\n",
    "    print(f\"  Examples: {mask.sum()}\")\n",
    "    print(f\"  Model Accuracy: {cat_y.mean():.3f}\")\n",
    "    print(f\"  Probe AUROC: {cat_auroc:.3f}\")\n",
    "    print(f\"  Probe ECE: {cat_ece:.4f}\")\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "categories = list(category_results.keys())\n",
    "n_examples = [category_results[c]['n_examples'] for c in categories]\n",
    "model_accs = [category_results[c]['model_accuracy'] for c in categories]\n",
    "aurocs = [category_results[c]['auroc'] for c in categories]\n",
    "eces = [category_results[c]['ece'] for c in categories]\n",
    "\n",
    "# Sample sizes\n",
    "ax1 = axes[0, 0]\n",
    "ax1.bar(categories, n_examples, color='skyblue', edgecolor='black')\n",
    "ax1.set_ylabel('Number of Examples')\n",
    "ax1.set_title('Test Set Distribution by Category')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Model accuracy by category\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(categories, model_accs, color='lightgreen', edgecolor='black')\n",
    "ax2.set_ylabel('Model Accuracy')\n",
    "ax2.set_title('Model Performance by Task Type')\n",
    "ax2.set_ylim([0, 1])\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Probe AUROC by category\n",
    "ax3 = axes[1, 0]\n",
    "ax3.bar(categories, aurocs, color='lightcoral', edgecolor='black')\n",
    "ax3.set_ylabel('Probe AUROC')\n",
    "ax3.set_title('Probe Discrimination by Task Type')\n",
    "ax3.set_ylim([0.5, 1.0])\n",
    "ax3.axhline(np.mean(aurocs), color='red', linestyle='--', label='Mean', linewidth=2)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "ax3.legend()\n",
    "\n",
    "# Probe ECE by category\n",
    "ax4 = axes[1, 1]\n",
    "ax4.bar(categories, eces, color='plum', edgecolor='black')\n",
    "ax4.set_ylabel('Probe ECE')\n",
    "ax4.set_title('Probe Calibration by Task Type')\n",
    "ax4.axhline(np.mean(eces), color='purple', linestyle='--', label='Mean', linewidth=2)\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('task_type_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: task_type_analysis.png\")\n",
    "print(\"\\nKey Finding:\")\n",
    "best_category = categories[aurocs.index(max(aurocs))]\n",
    "worst_category = categories[aurocs.index(min(aurocs))]\n",
    "print(f\"  Best probe performance: {best_category} (AUROC={max(aurocs):.3f})\")\n",
    "print(f\"  Worst probe performance: {worst_category} (AUROC={min(aurocs):.3f})\")\n",
    "print(f\"\\n  \u2192 Probes may work better on {'objective' if best_category == 'STEM' else 'subjective'} tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Distribution Shift: Do Probes Transfer Across Datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if probe trained on MMLU transfers to TriviaQA and GSM8K\n",
    "print(\"Testing probe transfer across datasets...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# We already have a trained linear probe on MMLU\n",
    "trained_probe = CalibratedProbe(network=build_default_network(X.shape[1], hidden_dim=None))\n",
    "\n",
    "# Load the trained weights from results\n",
    "# For simplicity, retrain on full MMLU\n",
    "print(\"\\nRetraining probe on MMLU training set...\")\n",
    "trained_probe.fit(X_train, y_train, X_val, y_val, num_epochs=100, patience=10, verbose=False)\n",
    "\n",
    "mmlu_auroc = roc_auc_score(y_test, trained_probe.predict(X_test))\n",
    "mmlu_ece = compute_ece(trained_probe.predict(X_test), y_test)\n",
    "print(f\"MMLU (in-domain): AUROC={mmlu_auroc:.3f}, ECE={mmlu_ece:.4f}\")\n",
    "\n",
    "# Test on TriviaQA\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Testing on TriviaQA (out-of-domain)...\")\n",
    "\n",
    "from src.data import TriviaQADataset\n",
    "triviaqa = TriviaQADataset(split=\"validation\")\n",
    "triviaqa_examples = triviaqa.sample(500, seed=42)  # Smaller sample\n",
    "\n",
    "# Generate answers and extract hidden states\n",
    "print(\"Generating TriviaQA answers...\")\n",
    "triviaqa_prompts = []\n",
    "triviaqa_correctness = []\n",
    "\n",
    "for example in tqdm(triviaqa_examples[:100]):  # Limit to 100 for speed\n",
    "    prompt = example.format_prompt(style=\"qa\")\n",
    "    triviaqa_prompts.append(prompt)\n",
    "    \n",
    "    generated = generate_answer(model, tokenizer, prompt, max_new_tokens=50)\n",
    "    is_correct = triviaqa.check_answer(generated, example.answers)\n",
    "    triviaqa_correctness.append(int(is_correct))\n",
    "\n",
    "triviaqa_correctness = np.array(triviaqa_correctness)\n",
    "print(f\"TriviaQA Model Accuracy: {triviaqa_correctness.mean():.1%}\")\n",
    "\n",
    "# Extract hidden states\n",
    "print(\"Extracting TriviaQA hidden states...\")\n",
    "triviaqa_hiddens = extractor.extract(\n",
    "    texts=triviaqa_prompts,\n",
    "    layers=[LAYER],\n",
    "    batch_size=8,\n",
    "    show_progress=False,\n",
    ")\n",
    "X_triviaqa = triviaqa_hiddens[:, 0, :]\n",
    "y_triviaqa = triviaqa_correctness\n",
    "\n",
    "# Test probe (no retraining!)\n",
    "triviaqa_conf = trained_probe.predict(X_triviaqa)\n",
    "triviaqa_auroc = roc_auc_score(y_triviaqa, triviaqa_conf) if len(np.unique(y_triviaqa)) > 1 else np.nan\n",
    "triviaqa_ece = compute_ece(triviaqa_conf, y_triviaqa)\n",
    "\n",
    "print(f\"TriviaQA (out-of-domain): AUROC={triviaqa_auroc:.3f}, ECE={triviaqa_ece:.4f}\")\n",
    "\n",
    "# Test on GSM8K\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Testing on GSM8K (math reasoning, out-of-domain)...\")\n",
    "\n",
    "from src.data import GSM8KDataset\n",
    "gsm8k = GSM8KDataset(split=\"test\")\n",
    "gsm8k_examples = gsm8k.sample(100, seed=42)  # Even smaller (harder task)\n",
    "\n",
    "print(\"Generating GSM8K answers...\")\n",
    "gsm8k_prompts = []\n",
    "gsm8k_correctness = []\n",
    "\n",
    "for example in tqdm(gsm8k_examples):\n",
    "    prompt = example.format_prompt(style=\"cot\")\n",
    "    gsm8k_prompts.append(prompt)\n",
    "    \n",
    "    generated = generate_answer(model, tokenizer, prompt, max_new_tokens=200)\n",
    "    is_correct = gsm8k.check_answer(generated, example.answer)\n",
    "    gsm8k_correctness.append(int(is_correct))\n",
    "\n",
    "gsm8k_correctness = np.array(gsm8k_correctness)\n",
    "print(f\"GSM8K Model Accuracy: {gsm8k_correctness.mean():.1%}\")\n",
    "\n",
    "# Extract hidden states\n",
    "print(\"Extracting GSM8K hidden states...\")\n",
    "gsm8k_hiddens = extractor.extract(\n",
    "    texts=gsm8k_prompts,\n",
    "    layers=[LAYER],\n",
    "    batch_size=8,\n",
    "    show_progress=False,\n",
    ")\n",
    "X_gsm8k = gsm8k_hiddens[:, 0, :]\n",
    "y_gsm8k = gsm8k_correctness\n",
    "\n",
    "# Test probe\n",
    "gsm8k_conf = trained_probe.predict(X_gsm8k)\n",
    "gsm8k_auroc = roc_auc_score(y_gsm8k, gsm8k_conf) if len(np.unique(y_gsm8k)) > 1 else np.nan\n",
    "gsm8k_ece = compute_ece(gsm8k_conf, y_gsm8k)\n",
    "\n",
    "print(f\"GSM8K (out-of-domain): AUROC={gsm8k_auroc:.3f}, ECE={gsm8k_ece:.4f}\")\n",
    "\n",
    "# Visualize transfer results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "datasets = ['MMLU\\n(in-domain)', 'TriviaQA\\n(QA)', 'GSM8K\\n(Math)']\n",
    "aurocs_transfer = [mmlu_auroc, triviaqa_auroc, gsm8k_auroc]\n",
    "eces_transfer = [mmlu_ece, triviaqa_ece, gsm8k_ece]\n",
    "\n",
    "# AUROC comparison\n",
    "ax1 = axes[0]\n",
    "bars1 = ax1.bar(datasets, aurocs_transfer, color=['green', 'orange', 'red'], \n",
    "                edgecolor='black', linewidth=1.5)\n",
    "ax1.set_ylabel('AUROC', fontsize=12)\n",
    "ax1.set_title('Probe Transfer: Discrimination', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim([0.5, 1.0])\n",
    "ax1.axhline(0.7, color='gray', linestyle='--', alpha=0.5, label='Acceptable threshold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "for bar, val in zip(bars1, aurocs_transfer):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# ECE comparison\n",
    "ax2 = axes[1]\n",
    "bars2 = ax2.bar(datasets, eces_transfer, color=['green', 'orange', 'red'],\n",
    "                edgecolor='black', linewidth=1.5)\n",
    "ax2.set_ylabel('ECE', fontsize=12)\n",
    "ax2.set_title('Probe Transfer: Calibration', fontsize=14, fontweight='bold')\n",
    "ax2.axhline(0.1, color='gray', linestyle='--', alpha=0.5, label='Acceptable threshold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "for bar, val in zip(bars2, eces_transfer):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.002,\n",
    "             f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"distribution_shift_analysis.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: distribution_shift_analysis.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "transfer_drop_triviaqa = mmlu_auroc - triviaqa_auroc\n",
    "transfer_drop_gsm8k = mmlu_auroc - gsm8k_auroc\n",
    "\n",
    "print(f\"AUROC drop on TriviaQA: {transfer_drop_triviaqa:+.3f}\")\n",
    "print(f\"AUROC drop on GSM8K: {transfer_drop_gsm8k:+.3f}\")\n",
    "\n",
    "if abs(transfer_drop_triviaqa) < 0.05 and abs(transfer_drop_gsm8k) < 0.05:\n",
    "    print(\"\\n\u2192 Probes transfer well across tasks!\")\n",
    "    print(\"  Uncertainty representations are task-agnostic\")\n",
    "elif transfer_drop_triviaqa > 0.1 or transfer_drop_gsm8k > 0.1:\n",
    "    print(\"\\n\u2192 Probes fail under distribution shift!\")\n",
    "    print(\"  Task-specific calibration needed\")\n",
    "else:\n",
    "    print(\"\\n\u2192 Moderate transfer performance\")\n",
    "    print(\"  Some task-specificity in uncertainty representations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize learned layer weights\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "layer_names = [f\"Layer {idx}\\n({'Early' if i==0 else 'Middle' if i==1 else 'Late' if i==2 else 'Final'})\" \n",
    "               for i, idx in enumerate(ensemble_layers)]\n",
    "\n",
    "ax.bar(layer_names, layer_weights, color=['lightblue', 'blue', 'darkblue', 'navy'], \n",
    "       edgecolor='black', linewidth=1.5)\n",
    "ax.set_ylabel('Ensemble Weight', fontsize=12)\n",
    "ax.set_title('Learned Layer Weights for Uncertainty Prediction', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim([0, max(layer_weights) * 1.2])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (name, weight) in enumerate(zip(layer_names, layer_weights)):\n",
    "    ax.text(i, weight + 0.01, f'{weight:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"layer_ensemble_weights.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: layer_ensemble_weights.png\")\n",
    "print(\"\\nInterpretation:\")\n",
    "if layer_weights[1] > max(layer_weights[0], layer_weights[2], layer_weights[3]):\n",
    "    print(\"  \u2192 Middle layer dominates (confirms prior research)\")\n",
    "elif abs(layer_weights[0] - layer_weights[1]) < 0.05 and abs(layer_weights[2] - layer_weights[3]) < 0.05:\n",
    "    print(\"  \u2192 Weights are relatively balanced (all layers contribute)\")\n",
    "else:\n",
    "    print(f\"  \u2192 Layer {ensemble_layers[layer_weights.argmax()]} is most important\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Loss Function Comparison: Why Brier Loss Over BCE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Brier loss vs Binary Cross-Entropy (BCE) loss\n",
    "print(\"Comparing Brier Loss vs BCE Loss...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# Build two identical networks\n",
    "network_brier = build_default_network(X.shape[1], hidden_dim=256)\n",
    "network_bce = build_default_network(X.shape[1], hidden_dim=256)\n",
    "\n",
    "# Probe with Brier loss (default in CalibratedProbe)\n",
    "probe_brier = CalibratedProbe(network=network_brier)\n",
    "\n",
    "# Probe with BCE loss\n",
    "from torch.nn import BCELoss\n",
    "probe_bce = CalibratedProbe(network=network_bce, loss_fn=BCELoss())\n",
    "\n",
    "print(\"\\nTraining with Brier loss...\")\n",
    "history_brier = probe_brier.fit(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    batch_size=32,\n",
    "    num_epochs=100,\n",
    "    patience=10,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\"Training with BCE loss...\")\n",
    "history_bce = probe_bce.fit(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    batch_size=32,\n",
    "    num_epochs=100,\n",
    "    patience=10,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Evaluate both\n",
    "conf_brier = probe_brier.predict(X_test)\n",
    "conf_bce = probe_bce.predict(X_test)\n",
    "\n",
    "# Compute metrics\n",
    "auroc_brier = roc_auc_score(y_test, conf_brier)\n",
    "brier_brier = brier_score_loss(y_test, conf_brier)\n",
    "ece_brier = compute_ece(conf_brier, y_test)\n",
    "\n",
    "auroc_bce = roc_auc_score(y_test, conf_bce)\n",
    "brier_bce = brier_score_loss(y_test, conf_bce)\n",
    "ece_bce = compute_ece(conf_bce, y_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBrier Loss:\")\n",
    "print(f\"  AUROC:       {auroc_brier:.4f}\")\n",
    "print(f\"  Brier Score: {brier_brier:.4f}\")\n",
    "print(f\"  ECE:         {ece_brier:.4f}\")\n",
    "\n",
    "print(f\"\\nBCE Loss:\")\n",
    "print(f\"  AUROC:       {auroc_bce:.4f}\")\n",
    "print(f\"  Brier Score: {brier_bce:.4f}\")\n",
    "print(f\"  ECE:         {ece_bce:.4f}\")\n",
    "\n",
    "print(f\"\\nDifferences (Brier - BCE):\")\n",
    "print(f\"  AUROC:       {auroc_brier - auroc_bce:+.4f}\")\n",
    "print(f\"  Brier Score: {brier_brier - brier_bce:+.4f} (lower is better)\")\n",
    "print(f\"  ECE:         {ece_brier - ece_bce:+.4f} (lower is better)\")\n",
    "\n",
    "# Visualize calibration differences\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Reliability diagrams\n",
    "plot_reliability_diagram(conf_brier, y_test, \n",
    "                        f'Brier Loss (ECE={ece_brier:.4f})', \n",
    "                        axes[0, 0])\n",
    "plot_reliability_diagram(conf_bce, y_test, \n",
    "                        f'BCE Loss (ECE={ece_bce:.4f})', \n",
    "                        axes[0, 1])\n",
    "\n",
    "# Confidence histograms\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(conf_brier, bins=20, alpha=0.5, label='Brier', color='blue', edgecolor='black')\n",
    "ax3.hist(conf_bce, bins=20, alpha=0.5, label='BCE', color='red', edgecolor='black')\n",
    "ax3.set_xlabel('Confidence')\n",
    "ax3.set_ylabel('Count')\n",
    "ax3.set_title('Confidence Distribution Comparison')\n",
    "ax3.legend()\n",
    "ax3.axvline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Training curves\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(history_brier['val_loss'], label='Brier (validation)', linewidth=2)\n",
    "ax4.plot(history_bce['val_loss'], label='BCE (validation)', linewidth=2)\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Validation Loss')\n",
    "ax4.set_title('Training Dynamics')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('brier_vs_bce_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: brier_vs_bce_comparison.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if ece_brier < ece_bce - 0.01:\n",
    "    print(\"\u2713 Brier loss produces better-calibrated probes!\")\n",
    "    print(f\"  ECE improvement: {ece_bce - ece_brier:.4f}\")\n",
    "elif ece_bce < ece_brier - 0.01:\n",
    "    print(\"\u2717 BCE loss produces better calibration (unexpected!)\")\n",
    "else:\n",
    "    print(\"\u2248 Both losses produce similar calibration\")\n",
    "\n",
    "if abs(auroc_brier - auroc_bce) < 0.01:\n",
    "    print(\"\\n\u2713 Discrimination (AUROC) is similar for both losses\")\n",
    "    print(\"  \u2192 Loss function affects calibration, not discrimination\")\n",
    "else:\n",
    "    print(f\"\\n! AUROC differs by {abs(auroc_brier - auroc_bce):.3f}\")\n",
    "\n",
    "print(\"\\nWhy Brier loss works better:\")\n",
    "print(\"  1. Directly optimizes calibration (squared error on probabilities)\")\n",
    "print(\"  2. Less sensitive to extreme confidences (no log term)\")\n",
    "print(\"  3. BCE penalizes wrong predictions heavily \u2192 overconfidence\")\n",
    "print(\"  4. Brier encourages probabilistic predictions matching true frequencies\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. Deep Mechanistic Analysis: Why Do Middle Layers Work Best?\n",
    "\n",
    "**Research Question**: Why do middle layers (layer 16/32) outperform final layers for uncertainty detection?\n",
    "\n",
    "**Hypothesis**: Final layers specialize for task completion, collapsing uncertainty signals into task-specific features. Middle layers maintain richer, more separable uncertainty representations.\n",
    "\n",
    "**Approach**:\n",
    "1. Extract hidden states from ALL layers (sample 12 evenly-spaced layers)\n",
    "2. For each layer, analyze:\n",
    "   - Probe performance (AUROC, calibration)\n",
    "   - Linear separability (correct vs incorrect)\n",
    "   - Cluster structure quality\n",
    "   - Intrinsic dimensionality\n",
    "3. Identify geometric changes from early \u2192 middle \u2192 late \u2192 final\n",
    "4. Provide mechanistic explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Deep Layer-wise Mechanistic Analysis\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Total layers: {num_layers}\")\n",
    "print(f\"Analyzing 12 evenly-spaced layers...\\n\")\n",
    "\n",
    "# Sample 12 evenly-spaced layers (including first, middle, last)\n",
    "analyzed_layers = np.linspace(0, num_layers-1, 12, dtype=int).tolist()\n",
    "print(f\"Layers to analyze: {analyzed_layers}\")\n",
    "\n",
    "# Store comprehensive results\n",
    "layer_analysis = {\n",
    "    'layer_idx': [],\n",
    "    # Performance metrics\n",
    "    'auroc': [],\n",
    "    'brier': [],\n",
    "    'ece': [],\n",
    "    'accuracy': [],\n",
    "    # Geometric metrics\n",
    "    'linear_separability': [],  # Fisher discriminant ratio\n",
    "    'svm_margin': [],  # SVM decision boundary margin\n",
    "    'silhouette': [],  # Cluster quality\n",
    "    'pca_2d_variance': [],  # Variance explained by top 2 PCs\n",
    "    'intrinsic_dim_90': [],  # Dims needed for 90% variance\n",
    "    'mean_cosine_sim_correct': [],  # Avg similarity within correct examples\n",
    "    'mean_cosine_sim_incorrect': [],  # Avg similarity within incorrect examples\n",
    "    'between_class_distance': [],  # Distance between correct/incorrect centroids\n",
    "}\n",
    "\n",
    "print(\"\\nExtracting hidden states and computing metrics...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for layer_idx in tqdm(analyzed_layers, desc=\"Analyzing layers\"):\n",
    "    # Extract from this layer\n",
    "    layer_hiddens = extractor.extract(\n",
    "        texts=prompts,\n",
    "        layers=[layer_idx],\n",
    "        batch_size=8,\n",
    "        show_progress=False,\n",
    "    )\n",
    "    \n",
    "    X_layer = layer_hiddens[:, 0, :]  # (num_examples, hidden_dim)\n",
    "    \n",
    "    # Split data\n",
    "    X_train_l, X_temp_l, y_train_l, y_temp_l = train_test_split(\n",
    "        X_layer, y, test_size=0.4, random_state=42, stratify=y\n",
    "    )\n",
    "    X_val_l, X_test_l, y_val_l, y_test_l = train_test_split(\n",
    "        X_temp_l, y_temp_l, test_size=0.5, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    # === 1. PERFORMANCE METRICS ===\n",
    "    # Train simple linear probe\n",
    "    network = build_default_network(X_layer.shape[1], hidden_dim=None)\n",
    "    probe = CalibratedProbe(network=network)\n",
    "    \n",
    "    probe.fit(\n",
    "        X_train_l, y_train_l,\n",
    "        X_val_l, y_val_l,\n",
    "        batch_size=32,\n",
    "        num_epochs=100,\n",
    "        patience=10,\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "    confidences_l = probe.predict(X_test_l)\n",
    "    predictions_l = (confidences_l > 0.5).astype(int)\n",
    "    \n",
    "    auroc_l = roc_auc_score(y_test_l, confidences_l)\n",
    "    brier_l = brier_score_loss(y_test_l, confidences_l)\n",
    "    ece_l = compute_ece(confidences_l, y_test_l)\n",
    "    acc_l = (predictions_l == y_test_l).mean()\n",
    "    \n",
    "    # === 2. GEOMETRIC METRICS ===\n",
    "    \n",
    "    # Linear separability: Fisher discriminant ratio\n",
    "    # Ratio of between-class variance to within-class variance\n",
    "    correct_vecs = X_train_l[y_train_l == 1]\n",
    "    incorrect_vecs = X_train_l[y_train_l == 0]\n",
    "    \n",
    "    mean_correct = correct_vecs.mean(axis=0)\n",
    "    mean_incorrect = incorrect_vecs.mean(axis=0)\n",
    "    between_class_dist = np.linalg.norm(mean_correct - mean_incorrect)\n",
    "    \n",
    "    # Within-class variance\n",
    "    var_correct = np.var(correct_vecs, axis=0).mean()\n",
    "    var_incorrect = np.var(incorrect_vecs, axis=0).mean()\n",
    "    within_class_var = (var_correct + var_incorrect) / 2\n",
    "    \n",
    "    # Fisher ratio (higher = more separable)\n",
    "    fisher_ratio = between_class_dist / (np.sqrt(within_class_var) + 1e-8)\n",
    "    \n",
    "    # SVM margin (train linear SVM, get margin)\n",
    "    # Use subset for speed\n",
    "    subset_size = min(500, len(X_train_l))\n",
    "    X_subset = X_train_l[:subset_size]\n",
    "    y_subset = y_train_l[:subset_size]\n",
    "    \n",
    "    svm = SVC(kernel='linear', C=1.0)\n",
    "    svm.fit(X_subset, y_subset)\n",
    "    # Margin = 2 / ||w|| for linear SVM\n",
    "    svm_margin = 2.0 / (np.linalg.norm(svm.coef_) + 1e-8)\n",
    "    \n",
    "    # Silhouette score (cluster quality)\n",
    "    silhouette = silhouette_score(X_subset, y_subset, metric='euclidean')\n",
    "    \n",
    "    # PCA variance explained\n",
    "    pca_layer = PCA(n_components=min(100, X_train_l.shape[1]))\n",
    "    pca_layer.fit(X_train_l)\n",
    "    pca_2d_var = pca_layer.explained_variance_ratio_[:2].sum()\n",
    "    cumsum_var_layer = np.cumsum(pca_layer.explained_variance_ratio_)\n",
    "    intrinsic_dim_90 = np.argmax(cumsum_var_layer >= 0.90) + 1\n",
    "    \n",
    "    # Cosine similarity within classes\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    \n",
    "    # Sample to avoid memory issues\n",
    "    n_sample = min(200, len(correct_vecs))\n",
    "    correct_sample = correct_vecs[:n_sample]\n",
    "    incorrect_sample = incorrect_vecs[:n_sample]\n",
    "    \n",
    "    cos_sim_correct = cosine_similarity(correct_sample).mean()\n",
    "    cos_sim_incorrect = cosine_similarity(incorrect_sample).mean()\n",
    "    \n",
    "    # Store results\n",
    "    layer_analysis['layer_idx'].append(layer_idx)\n",
    "    layer_analysis['auroc'].append(auroc_l)\n",
    "    layer_analysis['brier'].append(brier_l)\n",
    "    layer_analysis['ece'].append(ece_l)\n",
    "    layer_analysis['accuracy'].append(acc_l)\n",
    "    layer_analysis['linear_separability'].append(fisher_ratio)\n",
    "    layer_analysis['svm_margin'].append(svm_margin)\n",
    "    layer_analysis['silhouette'].append(silhouette)\n",
    "    layer_analysis['pca_2d_variance'].append(pca_2d_var)\n",
    "    layer_analysis['intrinsic_dim_90'].append(intrinsic_dim_90)\n",
    "    layer_analysis['mean_cosine_sim_correct'].append(cos_sim_correct)\n",
    "    layer_analysis['mean_cosine_sim_incorrect'].append(cos_sim_incorrect)\n",
    "    layer_analysis['between_class_distance'].append(between_class_dist)\n",
    "\n",
    "print(\"\\n\u2713 Analysis complete!\")\n",
    "print(f\"Analyzed {len(analyzed_layers)} layers\")\n",
    "\n",
    "# Convert to arrays for plotting\n",
    "for key in layer_analysis:\n",
    "    if key != 'layer_idx':\n",
    "        layer_analysis[key] = np.array(layer_analysis[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "layers = layer_analysis['layer_idx']\n",
    "\n",
    "# Identify middle layer (best AUROC)\n",
    "best_layer_idx = layers[np.argmax(layer_analysis['auroc'])]\n",
    "\n",
    "# Plot 1: AUROC across layers\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.plot(layers, layer_analysis['auroc'], 'o-', linewidth=2.5, markersize=8, color='#2E86AB')\n",
    "ax1.axvline(best_layer_idx, color='red', linestyle='--', alpha=0.5, label=f'Best: Layer {best_layer_idx}')\n",
    "ax1.set_xlabel('Layer Index', fontsize=11)\n",
    "ax1.set_ylabel('AUROC', fontsize=11)\n",
    "ax1.set_title('Probe Performance by Layer', fontsize=12, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Linear separability (Fisher ratio)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.plot(layers, layer_analysis['linear_separability'], 'o-', linewidth=2.5, markersize=8, color='#A23B72')\n",
    "ax2.axvline(best_layer_idx, color='red', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('Layer Index', fontsize=11)\n",
    "ax2.set_ylabel('Fisher Discriminant Ratio', fontsize=11)\n",
    "ax2.set_title('Linear Separability (Higher = More Separable)', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Silhouette score (cluster quality)\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "ax3.plot(layers, layer_analysis['silhouette'], 'o-', linewidth=2.5, markersize=8, color='#F18F01')\n",
    "ax3.axvline(best_layer_idx, color='red', linestyle='--', alpha=0.5)\n",
    "ax3.set_xlabel('Layer Index', fontsize=11)\n",
    "ax3.set_ylabel('Silhouette Score', fontsize=11)\n",
    "ax3.set_title('Cluster Quality', fontsize=12, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: PCA 2D variance\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "ax4.plot(layers, layer_analysis['pca_2d_variance'], 'o-', linewidth=2.5, markersize=8, color='#6A994E')\n",
    "ax4.axvline(best_layer_idx, color='red', linestyle='--', alpha=0.5)\n",
    "ax4.set_xlabel('Layer Index', fontsize=11)\n",
    "ax4.set_ylabel('Variance Explained (2D)', fontsize=11)\n",
    "ax4.set_title('2D Projection Quality', fontsize=12, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Intrinsic dimensionality\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "ax5.plot(layers, layer_analysis['intrinsic_dim_90'], 'o-', linewidth=2.5, markersize=8, color='#BC4B51')\n",
    "ax5.axvline(best_layer_idx, color='red', linestyle='--', alpha=0.5)\n",
    "ax5.set_xlabel('Layer Index', fontsize=11)\n",
    "ax5.set_ylabel('Dims for 90% Variance', fontsize=11)\n",
    "ax5.set_title('Intrinsic Dimensionality', fontsize=12, fontweight='bold')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Between-class distance\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "ax6.plot(layers, layer_analysis['between_class_distance'], 'o-', linewidth=2.5, markersize=8, color='#5E60CE')\n",
    "ax6.axvline(best_layer_idx, color='red', linestyle='--', alpha=0.5)\n",
    "ax6.set_xlabel('Layer Index', fontsize=11)\n",
    "ax6.set_ylabel('L2 Distance', fontsize=11)\n",
    "ax6.set_title('Distance Between Correct/Incorrect', fontsize=12, fontweight='bold')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 7: Within-class cohesion\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "ax7.plot(layers, layer_analysis['mean_cosine_sim_correct'], 'o-', linewidth=2.5, markersize=8, \n",
    "         label='Correct examples', color='green')\n",
    "ax7.plot(layers, layer_analysis['mean_cosine_sim_incorrect'], 's-', linewidth=2.5, markersize=8, \n",
    "         label='Incorrect examples', color='red')\n",
    "ax7.axvline(best_layer_idx, color='gray', linestyle='--', alpha=0.5)\n",
    "ax7.set_xlabel('Layer Index', fontsize=11)\n",
    "ax7.set_ylabel('Mean Cosine Similarity', fontsize=11)\n",
    "ax7.set_title('Within-Class Cohesion', fontsize=12, fontweight='bold')\n",
    "ax7.grid(True, alpha=0.3)\n",
    "ax7.legend()\n",
    "\n",
    "# Plot 8: SVM margin\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "ax8.plot(layers, layer_analysis['svm_margin'], 'o-', linewidth=2.5, markersize=8, color='#E63946')\n",
    "ax8.axvline(best_layer_idx, color='gray', linestyle='--', alpha=0.5)\n",
    "ax8.set_xlabel('Layer Index', fontsize=11)\n",
    "ax8.set_ylabel('SVM Margin', fontsize=11)\n",
    "ax8.set_title('Linear SVM Decision Boundary Margin', fontsize=12, fontweight='bold')\n",
    "ax8.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 9: Correlation heatmap (AUROC vs geometric metrics)\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "metrics_for_corr = np.array([\n",
    "    layer_analysis['auroc'],\n",
    "    layer_analysis['linear_separability'],\n",
    "    layer_analysis['silhouette'],\n",
    "    layer_analysis['pca_2d_variance'],\n",
    "    layer_analysis['between_class_distance'],\n",
    "]).T\n",
    "\n",
    "corr_matrix = np.corrcoef(metrics_for_corr.T)\n",
    "metric_names = ['AUROC', 'Fisher\\nRatio', 'Silhouette', 'PCA 2D\\nVar', 'Between\\nDist']\n",
    "\n",
    "im = ax9.imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "ax9.set_xticks(range(len(metric_names)))\n",
    "ax9.set_yticks(range(len(metric_names)))\n",
    "ax9.set_xticklabels(metric_names, fontsize=9)\n",
    "ax9.set_yticklabels(metric_names, fontsize=9)\n",
    "ax9.set_title('Metric Correlations', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add correlation values\n",
    "for i in range(len(metric_names)):\n",
    "    for j in range(len(metric_names)):\n",
    "        text = ax9.text(j, i, f'{corr_matrix[i, j]:.2f}',\n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontsize=9)\n",
    "\n",
    "plt.colorbar(im, ax=ax9, fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.savefig('deep_layer_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2713 Saved: deep_layer_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print mechanistic interpretation\n",
    "print(\"=\"*70)\n",
    "print(\"MECHANISTIC INTERPRETATION: Why Middle Layers Win\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Find layer categories\n",
    "best_auroc_idx = np.argmax(layer_analysis['auroc'])\n",
    "best_layer = layers[best_auroc_idx]\n",
    "final_layer = layers[-1]\n",
    "early_layer = layers[0]\n",
    "\n",
    "# Get metrics at key layers\n",
    "def get_metrics(idx):\n",
    "    return {\n",
    "        'auroc': layer_analysis['auroc'][idx],\n",
    "        'fisher': layer_analysis['linear_separability'][idx],\n",
    "        'silhouette': layer_analysis['silhouette'][idx],\n",
    "        'pca_2d': layer_analysis['pca_2d_variance'][idx],\n",
    "        'intrinsic_dim': layer_analysis['intrinsic_dim_90'][idx],\n",
    "        'between_dist': layer_analysis['between_class_distance'][idx],\n",
    "    }\n",
    "\n",
    "early_metrics = get_metrics(0)\n",
    "best_metrics = get_metrics(best_auroc_idx)\n",
    "final_metrics = get_metrics(-1)\n",
    "\n",
    "print(f\"\\n1. BEST LAYER FOR UNCERTAINTY: Layer {best_layer}/{num_layers-1}\")\n",
    "print(f\"   AUROC: {best_metrics['auroc']:.4f}\")\n",
    "print(f\"   Fisher ratio: {best_metrics['fisher']:.4f}\")\n",
    "print(f\"   Silhouette: {best_metrics['silhouette']:.4f}\")\n",
    "\n",
    "print(f\"\\n2. EARLY LAYER (Layer {early_layer}):\")\n",
    "print(f\"   AUROC: {early_metrics['auroc']:.4f} ({(early_metrics['auroc'] - best_metrics['auroc']):.4f} vs best)\")\n",
    "print(f\"   Fisher ratio: {early_metrics['fisher']:.4f}\")\n",
    "print(f\"   \u2192 Low separability (features not yet specialized)\")\n",
    "\n",
    "print(f\"\\n3. FINAL LAYER (Layer {final_layer}):\")\n",
    "print(f\"   AUROC: {final_metrics['auroc']:.4f} ({(final_metrics['auroc'] - best_metrics['auroc']):.4f} vs best)\")\n",
    "print(f\"   Fisher ratio: {final_metrics['fisher']:.4f}\")\n",
    "print(f\"   PCA 2D variance: {final_metrics['pca_2d']:.4f}\")\n",
    "\n",
    "# Compute degradation from best \u2192 final\n",
    "auroc_drop = best_metrics['auroc'] - final_metrics['auroc']\n",
    "fisher_drop = best_metrics['fisher'] - final_metrics['fisher']\n",
    "silhouette_drop = best_metrics['silhouette'] - final_metrics['silhouette']\n",
    "\n",
    "print(f\"\\n4. DEGRADATION FROM BEST \u2192 FINAL LAYER:\")\n",
    "print(f\"   AUROC drop: {auroc_drop:.4f} ({auroc_drop/best_metrics['auroc']*100:.1f}% relative)\")\n",
    "print(f\"   Fisher ratio drop: {fisher_drop:.4f}\")\n",
    "print(f\"   Silhouette drop: {silhouette_drop:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Finding 1: Best layer location\n",
    "relative_position = best_layer / (num_layers - 1)\n",
    "print(f\"\\n\u2713 Finding 1: Peak uncertainty detection at {relative_position:.1%} depth\")\n",
    "print(f\"  Layer {best_layer}/{num_layers-1} achieves best AUROC: {best_metrics['auroc']:.4f}\")\n",
    "\n",
    "# Finding 2: Correlation between geometry and performance\n",
    "corr_fisher_auroc = np.corrcoef(layer_analysis['auroc'], layer_analysis['linear_separability'])[0, 1]\n",
    "corr_silhouette_auroc = np.corrcoef(layer_analysis['auroc'], layer_analysis['silhouette'])[0, 1]\n",
    "\n",
    "print(f\"\\n\u2713 Finding 2: Geometric properties predict performance\")\n",
    "print(f\"  Correlation(AUROC, Fisher ratio): {corr_fisher_auroc:.3f}\")\n",
    "print(f\"  Correlation(AUROC, Silhouette): {corr_silhouette_auroc:.3f}\")\n",
    "if corr_fisher_auroc > 0.7:\n",
    "    print(f\"  \u2192 Strong correlation! Linear separability drives probe performance\")\n",
    "\n",
    "# Finding 3: Why final layers fail\n",
    "print(f\"\\n\u2713 Finding 3: Final layers collapse uncertainty signals\")\n",
    "print(f\"  Final layer is {abs(fisher_drop)/best_metrics['fisher']*100:.1f}% less separable than best layer\")\n",
    "print(f\"  Intrinsic dimensionality: {final_metrics['intrinsic_dim']} dims (vs {best_metrics['intrinsic_dim']} at best)\")\n",
    "\n",
    "if final_metrics['intrinsic_dim'] < best_metrics['intrinsic_dim']:\n",
    "    print(f\"  \u2192 Final layers compress to lower-dimensional task representations\")\n",
    "    print(f\"     This collapses uncertainty signals needed for confidence estimation\")\n",
    "\n",
    "# Finding 4: Early layers\n",
    "print(f\"\\n\u2713 Finding 4: Early layers lack specialized features\")\n",
    "print(f\"  Early layer Fisher ratio: {early_metrics['fisher']:.4f}\")\n",
    "print(f\"  Best layer Fisher ratio: {best_metrics['fisher']:.4f}\")\n",
    "print(f\"  \u2192 {(best_metrics['fisher'] / early_metrics['fisher'] - 1)*100:.1f}% improvement from early \u2192 middle\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MECHANISTIC EXPLANATION:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Middle layers (40-60% depth) are optimal for uncertainty detection because:\n",
    "\n",
    "1. SPECIALIZATION: Middle layers have developed task-specific features\n",
    "   that distinguish correct from incorrect predictions\n",
    "   (high Fisher ratio, good linear separability)\n",
    "\n",
    "2. PRESERVATION: Middle layers haven't yet collapsed to the single\n",
    "   output dimension needed for next-token prediction\n",
    "   (maintain higher intrinsic dimensionality)\n",
    "\n",
    "3. CLUSTER STRUCTURE: Correct/incorrect examples form distinct clusters\n",
    "   in middle layers (high silhouette score) but mix in final layers\n",
    "\n",
    "Final layers optimize for task completion (next token prediction),\n",
    "discarding uncertainty information. This is a feature, not a bug:\n",
    "the model should be confident when generating, but this makes final\n",
    "layers poor for uncertainty estimation.\n",
    "\n",
    "Early layers contain raw features without task specialization,\n",
    "so correct/incorrect aren't yet separable.\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"NOVEL INSIGHT FOR PAPER/BLOG:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "We provide the first mechanistic explanation for why middle layers\n",
    "outperform final layers for uncertainty detection:\n",
    "\n",
    "The optimal layer (layer \"\"\" + str(best_layer) + f\"\"\") balances:\n",
    "  \u2022 Sufficient feature specialization (Fisher ratio: {best_metrics['fisher']:.2f})\n",
    "  \u2022 Preserved dimensionality (needs {best_metrics['intrinsic_dim']} dims for 90% variance)\n",
    "  \u2022 Strong cluster separation (silhouette: {best_metrics['silhouette']:.3f})\n",
    "\n",
    "Final layers collapse these signals during task optimization,\n",
    "reducing separability by {abs(fisher_drop)/best_metrics['fisher']*100:.0f}% and\n",
    "lowering AUROC by {auroc_drop:.3f} points.\n",
    "\n",
    "This explains why probing final layers is suboptimal and provides\n",
    "guidance for future uncertainty quantification methods.\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. Attention Patterns vs Hidden States: Where Does Confidence Live?\n",
    "\n",
    "**Research Question**: Is confidence primarily encoded in attention patterns (what the model focuses on) or hidden state representations (how it encodes information)?\n",
    "\n",
    "**Hypothesis**: \n",
    "- When uncertain, models show **diffuse attention** across multiple answer options\n",
    "- When confident, models show **sharp attention** focused on the selected answer\n",
    "- Attention patterns may encode confidence more directly than hidden states\n",
    "\n",
    "**Approach**:\n",
    "1. Extract attention weights from the same layer used for hidden state probes\n",
    "2. Create attention-based features (entropy, attention to options, etc.)\n",
    "3. Train probe on attention features\n",
    "4. Compare to hidden state probes\n",
    "5. Analyze which attention patterns predict correctness\n",
    "\n",
    "**Novel Contribution**: Understanding WHERE in the network confidence is encoded, not just which probe architecture works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.stats import entropy\n",
    "\n",
    "print(\"Extracting Attention Patterns for Confidence Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use the same layer we found optimal for hidden states\n",
    "attention_layer = LAYER  # Middle layer from earlier analysis\n",
    "print(f\"Analyzing attention patterns from layer {attention_layer}\")\n",
    "\n",
    "def extract_attention_patterns(model, tokenizer, texts, layer_idx, batch_size=8):\n",
    "    \"\"\"Extract attention weights from specified layer.\n",
    "    \n",
    "    Returns:\n",
    "        attention_weights: (num_examples, num_heads, seq_len, seq_len)\n",
    "    \"\"\"\n",
    "    all_attentions = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Extracting attention\"):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        # Tokenize\n",
    "        encodings = tokenizer(\n",
    "            batch_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        encodings = {k: v.to(model.device) for k, v in encodings.items()}\n",
    "        \n",
    "        # Forward pass with attention output\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                **encodings,\n",
    "                output_attentions=True,\n",
    "                return_dict=True,\n",
    "            )\n",
    "        \n",
    "        # Get attention from specified layer\n",
    "        # outputs.attentions is tuple of (num_layers,)\n",
    "        # Each element: (batch_size, num_heads, seq_len, seq_len)\n",
    "        layer_attention = outputs.attentions[layer_idx]\n",
    "        \n",
    "        # Convert to CPU and store\n",
    "        all_attentions.append(layer_attention.cpu().numpy())\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    attention_weights = np.concatenate(all_attentions, axis=0)\n",
    "    return attention_weights\n",
    "\n",
    "# Extract attention patterns for all examples\n",
    "print(\"\\nExtracting attention weights...\")\n",
    "attention_weights = extract_attention_patterns(\n",
    "    model, tokenizer, prompts, attention_layer, batch_size=4\n",
    ")\n",
    "\n",
    "print(f\"Attention weights shape: {attention_weights.shape}\")\n",
    "print(f\"  (num_examples, num_heads, seq_len, seq_len)\")\n",
    "print(f\"  {attention_weights.shape[0]} examples\")\n",
    "print(f\"  {attention_weights.shape[1]} attention heads\")\n",
    "print(f\"  {attention_weights.shape[2]} sequence length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attention_features(attention_weights, tokenizer, texts):\n",
    "    \"\"\"Compute interpretable features from attention patterns.\n",
    "    \n",
    "    Features:\n",
    "    1. Attention entropy (averaged over heads) - how diffuse is attention?\n",
    "    2. Max attention weight - is attention focused or spread?\n",
    "    3. Attention to last token (where model generates from)\n",
    "    4. Attention to answer options (A, B, C, D tokens)\n",
    "    5. Attention to question tokens\n",
    "    6. Head disagreement - do different heads attend to different things?\n",
    "    \n",
    "    Args:\n",
    "        attention_weights: (num_examples, num_heads, seq_len, seq_len)\n",
    "        tokenizer: for identifying token positions\n",
    "        texts: original prompts\n",
    "    \n",
    "    Returns:\n",
    "        features: (num_examples, num_features)\n",
    "    \"\"\"\n",
    "    num_examples = attention_weights.shape[0]\n",
    "    num_heads = attention_weights.shape[1]\n",
    "    \n",
    "    features_list = []\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "        attn = attention_weights[i]  # (num_heads, seq_len, seq_len)\n",
    "        \n",
    "        # Focus on attention FROM last token (where model predicts next token)\n",
    "        last_token_attn = attn[:, -1, :]  # (num_heads, seq_len)\n",
    "        \n",
    "        # Feature 1: Mean entropy across heads\n",
    "        entropies = [entropy(head_attn + 1e-10) for head_attn in last_token_attn]\n",
    "        mean_entropy = np.mean(entropies)\n",
    "        \n",
    "        # Feature 2: Max attention weight (how focused?)\n",
    "        max_attention = last_token_attn.max(axis=1).mean()  # Average max across heads\n",
    "        \n",
    "        # Feature 3: Std of max attention across heads (head disagreement)\n",
    "        max_attention_std = last_token_attn.max(axis=1).std()\n",
    "        \n",
    "        # Feature 4-7: Attention to answer option tokens (A, B, C, D)\n",
    "        # Find positions of A, B, C, D in the prompt\n",
    "        text = texts[i]\n",
    "        tokens = tokenizer.encode(text)\n",
    "        \n",
    "        # Simple heuristic: look for option tokens\n",
    "        # For MMLU format: \"A) ...\", \"B) ...\", etc.\n",
    "        option_positions = []\n",
    "        for opt in ['A)', 'B)', 'C)', 'D)']:\n",
    "            opt_tokens = tokenizer.encode(opt, add_special_tokens=False)\n",
    "            if len(opt_tokens) > 0:\n",
    "                opt_token = opt_tokens[0]\n",
    "                # Find position in sequence\n",
    "                positions = [j for j, t in enumerate(tokens) if t == opt_token]\n",
    "                if positions:\n",
    "                    option_positions.append(positions[0])\n",
    "        \n",
    "        # Average attention to option tokens\n",
    "        if len(option_positions) >= 2:  # At least 2 options found\n",
    "            # Pad to 4 options\n",
    "            while len(option_positions) < 4:\n",
    "                option_positions.append(option_positions[-1])\n",
    "            \n",
    "            attention_to_options = []\n",
    "            for pos in option_positions[:4]:\n",
    "                if pos < last_token_attn.shape[1]:\n",
    "                    attention_to_options.append(last_token_attn[:, pos].mean())\n",
    "                else:\n",
    "                    attention_to_options.append(0.0)\n",
    "        else:\n",
    "            # Fallback: use mean attention to different quartiles of sequence\n",
    "            seq_len = last_token_attn.shape[1]\n",
    "            attention_to_options = [\n",
    "                last_token_attn[:, :seq_len//4].mean(),\n",
    "                last_token_attn[:, seq_len//4:seq_len//2].mean(),\n",
    "                last_token_attn[:, seq_len//2:3*seq_len//4].mean(),\n",
    "                last_token_attn[:, 3*seq_len//4:].mean(),\n",
    "            ]\n",
    "        \n",
    "        # Feature 8: Attention spread (how many tokens get >1% attention?)\n",
    "        mean_attn = last_token_attn.mean(axis=0)  # Average across heads\n",
    "        num_significant_tokens = (mean_attn > 0.01).sum()\n",
    "        attention_spread = num_significant_tokens / len(mean_attn)\n",
    "        \n",
    "        # Combine all features\n",
    "        example_features = [\n",
    "            mean_entropy,           # How diffuse?\n",
    "            max_attention,          # How focused?\n",
    "            max_attention_std,      # Head disagreement?\n",
    "            *attention_to_options,  # Attention to A, B, C, D\n",
    "            attention_spread,       # How spread out?\n",
    "        ]\n",
    "        \n",
    "        features_list.append(example_features)\n",
    "    \n",
    "    return np.array(features_list)\n",
    "\n",
    "print(\"Computing attention-based features...\")\n",
    "attention_features = compute_attention_features(attention_weights, tokenizer, prompts)\n",
    "\n",
    "print(f\"\\nAttention features shape: {attention_features.shape}\")\n",
    "print(f\"Features per example: {attention_features.shape[1]}\")\n",
    "print(f\"\\nFeature descriptions:\")\n",
    "print(f\"  [0] Mean entropy (diffuseness)\")\n",
    "print(f\"  [1] Max attention (focus)\")\n",
    "print(f\"  [2] Max attention std (head disagreement)\")\n",
    "print(f\"  [3-6] Attention to options A, B, C, D\")\n",
    "print(f\"  [7] Attention spread (% tokens with >1% attention)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split attention features same way as hidden states\n",
    "X_attn_train, X_attn_temp, y_attn_train, y_attn_temp = train_test_split(\n",
    "    attention_features, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "X_attn_val, X_attn_test, y_attn_val, y_attn_test = train_test_split(\n",
    "    X_attn_temp, y_attn_temp, test_size=0.5, random_state=42, stratify=y_attn_temp\n",
    ")\n",
    "\n",
    "print(f\"Attention feature splits:\")\n",
    "print(f\"  Train: {X_attn_train.shape}\")\n",
    "print(f\"  Val:   {X_attn_val.shape}\")\n",
    "print(f\"  Test:  {X_attn_test.shape}\")\n",
    "\n",
    "# Train linear probe on attention features\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Training probe on ATTENTION features...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "attention_network = build_default_network(attention_features.shape[1], hidden_dim=None)\n",
    "attention_probe = CalibratedProbe(network=attention_network)\n",
    "\n",
    "attention_history = attention_probe.fit(\n",
    "    X_attn_train, y_attn_train,\n",
    "    X_attn_val, y_attn_val,\n",
    "    batch_size=32,\n",
    "    num_epochs=100,\n",
    "    patience=10,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "attention_conf = attention_probe.predict(X_attn_test)\n",
    "attention_pred = (attention_conf > 0.5).astype(int)\n",
    "\n",
    "attention_acc = (attention_pred == y_attn_test).mean()\n",
    "attention_auroc = roc_auc_score(y_attn_test, attention_conf)\n",
    "attention_brier = brier_score_loss(y_attn_test, attention_conf)\n",
    "attention_ece = compute_ece(attention_conf, y_attn_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ATTENTION PROBE RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Accuracy:    {attention_acc:.3f}\")\n",
    "print(f\"AUROC:       {attention_auroc:.3f}\")\n",
    "print(f\"Brier Score: {attention_brier:.4f}\")\n",
    "print(f\"ECE:         {attention_ece:.4f}\")\n",
    "\n",
    "# Compare to hidden state probe\n",
    "hidden_auroc = results['Linear']['auroc']\n",
    "hidden_brier = results['Linear']['brier']\n",
    "hidden_ece = results['Linear']['ece']\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON: Attention vs Hidden States\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Metric':<15} {'Hidden State':<15} {'Attention':<15} {'Difference':<15}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'AUROC':<15} {hidden_auroc:<15.4f} {attention_auroc:<15.4f} {attention_auroc - hidden_auroc:+.4f}\")\n",
    "print(f\"{'Brier Score':<15} {hidden_brier:<15.4f} {attention_brier:<15.4f} {attention_brier - hidden_brier:+.4f} (lower better)\")\n",
    "print(f\"{'ECE':<15} {hidden_ece:<15.4f} {attention_ece:<15.4f} {attention_ece - hidden_ece:+.4f} (lower better)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if attention_auroc > hidden_auroc + 0.02:\n",
    "    print(\"\u2713 ATTENTION patterns encode confidence BETTER than hidden states!\")\n",
    "    print(f\"  AUROC improvement: {attention_auroc - hidden_auroc:.3f}\")\n",
    "    print(\"  \u2192 Confidence is primarily about WHAT the model attends to\")\n",
    "elif hidden_auroc > attention_auroc + 0.02:\n",
    "    print(\"\u2713 HIDDEN STATES encode confidence BETTER than attention patterns!\")\n",
    "    print(f\"  AUROC improvement: {hidden_auroc - attention_auroc:.3f}\")\n",
    "    print(\"  \u2192 Confidence is primarily about HOW the model represents information\")\n",
    "else:\n",
    "    print(\"\u2248 Attention and hidden states encode SIMILAR confidence information\")\n",
    "    print(f\"  AUROC difference: {abs(attention_auroc - hidden_auroc):.3f}\")\n",
    "    print(\"  \u2192 Both modalities contain complementary signals\")\n",
    "\n",
    "# Check calibration\n",
    "if attention_ece < hidden_ece - 0.01:\n",
    "    print(f\"\\n\u2713 Attention probe is BETTER CALIBRATED (ECE: {attention_ece:.4f} vs {hidden_ece:.4f})\")\n",
    "elif hidden_ece < attention_ece - 0.01:\n",
    "    print(f\"\\n\u2713 Hidden state probe is BETTER CALIBRATED (ECE: {hidden_ece:.4f} vs {attention_ece:.4f})\")\n",
    "else:\n",
    "    print(f\"\\n\u2248 Similar calibration quality (ECE diff: {abs(attention_ece - hidden_ece):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze learned weights to see which attention features matter most\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get learned weights from linear probe\n",
    "learned_weights = attention_probe.network[0].weight.detach().cpu().numpy()[0]\n",
    "\n",
    "feature_names = [\n",
    "    \"Entropy (diffuseness)\",\n",
    "    \"Max attention (focus)\",\n",
    "    \"Head disagreement\",\n",
    "    \"Attention to option A\",\n",
    "    \"Attention to option B\",\n",
    "    \"Attention to option C\",\n",
    "    \"Attention to option D\",\n",
    "    \"Attention spread\",\n",
    "]\n",
    "\n",
    "# Normalize weights by feature std for fair comparison\n",
    "feature_stds = X_attn_train.std(axis=0)\n",
    "normalized_weights = learned_weights * feature_stds\n",
    "\n",
    "print(\"\\nLearned feature weights (normalized by std):\")\n",
    "print(\"-\"*60)\n",
    "for name, weight in sorted(zip(feature_names, normalized_weights), key=lambda x: abs(x[1]), reverse=True):\n",
    "    print(f\"  {name:<30} {weight:+.4f}\")\n",
    "\n",
    "# Plot feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Feature weights\n",
    "ax1 = axes[0]\n",
    "colors = ['green' if w > 0 else 'red' for w in normalized_weights]\n",
    "ax1.barh(feature_names, normalized_weights, color=colors, edgecolor='black', alpha=0.7)\n",
    "ax1.set_xlabel('Normalized Weight', fontsize=11)\n",
    "ax1.set_title('Feature Importance for Confidence Prediction', fontsize=12, fontweight='bold')\n",
    "ax1.axvline(0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Attention patterns: correct vs incorrect\n",
    "ax2 = axes[1]\n",
    "\n",
    "# Compare attention entropy for correct vs incorrect\n",
    "correct_mask = y_test == 1\n",
    "incorrect_mask = y_test == 0\n",
    "\n",
    "# Get test set attention features\n",
    "test_entropy_correct = X_attn_test[y_attn_test == 1, 0]\n",
    "test_entropy_incorrect = X_attn_test[y_attn_test == 0, 0]\n",
    "\n",
    "ax2.hist(test_entropy_correct, bins=20, alpha=0.6, label='Correct', color='green', edgecolor='black')\n",
    "ax2.hist(test_entropy_incorrect, bins=20, alpha=0.6, label='Incorrect', color='red', edgecolor='black')\n",
    "ax2.set_xlabel('Attention Entropy', fontsize=11)\n",
    "ax2.set_ylabel('Count', fontsize=11)\n",
    "ax2.set_title('Attention Diffuseness: Correct vs Incorrect', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('attention_feature_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2713 Saved: attention_feature_analysis.png\")\n",
    "\n",
    "# Statistical test\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "t_stat, p_value = ttest_ind(test_entropy_correct, test_entropy_incorrect)\n",
    "print(f\"\\nAttention entropy: correct vs incorrect\")\n",
    "print(f\"  Correct:   mean={test_entropy_correct.mean():.4f}, std={test_entropy_correct.std():.4f}\")\n",
    "print(f\"  Incorrect: mean={test_entropy_incorrect.mean():.4f}, std={test_entropy_incorrect.std():.4f}\")\n",
    "print(f\"  t-test: t={t_stat:.3f}, p={p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    if test_entropy_incorrect.mean() > test_entropy_correct.mean():\n",
    "        print(f\"  \u2713 Incorrect examples have significantly MORE diffuse attention (p<0.05)\")\n",
    "        print(f\"    \u2192 Model is uncertain when attention is spread out\")\n",
    "    else:\n",
    "        print(f\"  \u2713 Correct examples have significantly MORE diffuse attention (p<0.05)\")\n",
    "        print(f\"    \u2192 Unexpected! Model may scan options before committing\")\n",
    "else:\n",
    "    print(f\"  \u2717 No significant difference in attention entropy (p={p_value:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention patterns for example correct and incorrect predictions\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ATTENTION PATTERN VISUALIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Find examples with high confidence correct and high confidence incorrect\n",
    "test_indices = np.arange(len(X_test))\n",
    "\n",
    "# Map back to original indices\n",
    "_, test_idx = train_test_split(\n",
    "    np.arange(len(X)), test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "_, test_idx_final = train_test_split(\n",
    "    test_idx, test_size=0.5, random_state=42, stratify=y[test_idx]\n",
    ")\n",
    "\n",
    "# Find interesting examples\n",
    "confident_correct = test_idx_final[(y_test == 1) & (attention_conf > 0.8)]\n",
    "confident_incorrect = test_idx_final[(y_test == 0) & (attention_conf > 0.8)]\n",
    "\n",
    "if len(confident_correct) > 0 and len(confident_incorrect) > 0:\n",
    "    # Pick one of each\n",
    "    example_correct_idx = confident_correct[0]\n",
    "    example_incorrect_idx = confident_incorrect[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    for ax, example_idx, title, is_correct in [\n",
    "        (axes[0], example_correct_idx, \"Correct Prediction\", True),\n",
    "        (axes[1], example_incorrect_idx, \"Incorrect Prediction\", False)\n",
    "    ]:\n",
    "        # Get attention for this example\n",
    "        attn = attention_weights[example_idx]  # (num_heads, seq_len, seq_len)\n",
    "        \n",
    "        # Average across heads, focus on last token attention\n",
    "        avg_attn = attn.mean(axis=0)[-1, :]  # (seq_len,)\n",
    "        \n",
    "        # Get tokens\n",
    "        prompt_text = prompts[example_idx]\n",
    "        tokens = tokenizer.tokenize(prompt_text)\n",
    "        \n",
    "        # Truncate if too long\n",
    "        max_tokens_to_show = 50\n",
    "        if len(tokens) > max_tokens_to_show:\n",
    "            # Show last N tokens (most relevant)\n",
    "            tokens_to_show = tokens[-max_tokens_to_show:]\n",
    "            attn_to_show = avg_attn[-max_tokens_to_show:]\n",
    "        else:\n",
    "            tokens_to_show = tokens\n",
    "            attn_to_show = avg_attn[:len(tokens)]\n",
    "        \n",
    "        # Plot\n",
    "        colors_map = plt.cm.Reds if is_correct else plt.cm.Blues\n",
    "        colors = colors_map(attn_to_show / attn_to_show.max())\n",
    "        \n",
    "        ax.barh(range(len(tokens_to_show)), attn_to_show, color=colors, edgecolor='black', linewidth=0.5)\n",
    "        ax.set_yticks(range(len(tokens_to_show)))\n",
    "        ax.set_yticklabels(tokens_to_show, fontsize=8)\n",
    "        ax.set_xlabel('Attention Weight', fontsize=11)\n",
    "        ax.set_title(f'{title}\\n(Model was {\"correct\" if is_correct else \"incorrect\"})', \n",
    "                    fontsize=12, fontweight='bold')\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "        ax.invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('attention_heatmap_examples.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\u2713 Saved: attention_heatmap_examples.png\")\n",
    "    print(\"\\nVisualization shows which tokens the model attends to when making predictions.\")\n",
    "    print(\"Compare patterns between correct and incorrect examples.\")\n",
    "else:\n",
    "    print(\"\\nNot enough confident examples to visualize. Try increasing NUM_SAMPLES.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"NOVEL CONTRIBUTION: Where Does Confidence Live in LLMs?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. MAIN FINDING:\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "if attention_auroc > hidden_auroc + 0.02:\n",
    "    print(f\"\u2713 Attention patterns encode confidence MORE effectively than hidden states\")\n",
    "    print(f\"  AUROC: {attention_auroc:.3f} (attention) vs {hidden_auroc:.3f} (hidden states)\")\n",
    "    print(f\"  Improvement: {(attention_auroc - hidden_auroc) / hidden_auroc * 100:.1f}%\")\n",
    "    print(f\"\\n  INTERPRETATION:\")\n",
    "    print(f\"  \u2192 Confidence is primarily about WHAT the model attends to, not HOW it encodes it\")\n",
    "    print(f\"  \u2192 Attention patterns reveal uncertainty more directly than representations\")\n",
    "    print(f\"  \u2192 Future uncertainty methods should leverage attention, not just hidden states\")\n",
    "elif hidden_auroc > attention_auroc + 0.02:\n",
    "    print(f\"\u2713 Hidden states encode confidence MORE effectively than attention patterns\")\n",
    "    print(f\"  AUROC: {hidden_auroc:.3f} (hidden states) vs {attention_auroc:.3f} (attention)\")\n",
    "    print(f\"  Improvement: {(hidden_auroc - attention_auroc) / attention_auroc * 100:.1f}%\")\n",
    "    print(f\"\\n  INTERPRETATION:\")\n",
    "    print(f\"  \u2192 Confidence is primarily about representation quality, not attention patterns\")\n",
    "    print(f\"  \u2192 Hidden states capture subtle uncertainty signals missed by attention\")\n",
    "    print(f\"  \u2192 Validates existing probe approaches using hidden states\")\n",
    "else:\n",
    "    print(f\"\u2713 Attention and hidden states encode COMPLEMENTARY confidence signals\")\n",
    "    print(f\"  AUROC: {attention_auroc:.3f} (attention) vs {hidden_auroc:.3f} (hidden states)\")\n",
    "    print(f\"  Difference: {abs(attention_auroc - hidden_auroc):.3f}\")\n",
    "    print(f\"\\n  INTERPRETATION:\")\n",
    "    print(f\"  \u2192 Both modalities contain similar information about confidence\")\n",
    "    print(f\"  \u2192 Combining attention + hidden states may improve performance\")\n",
    "    print(f\"  \u2192 Redundancy suggests confidence is global property of the network\")\n",
    "\n",
    "print(\"\\n2. KEY ATTENTION FEATURES:\")\n",
    "print(\"-\"*70)\n",
    "# Find most important feature\n",
    "most_important_idx = np.argmax(np.abs(normalized_weights))\n",
    "most_important_feature = feature_names[most_important_idx]\n",
    "most_important_weight = normalized_weights[most_important_idx]\n",
    "\n",
    "print(f\"Most predictive attention feature: {most_important_feature}\")\n",
    "print(f\"  Weight: {most_important_weight:+.4f}\")\n",
    "\n",
    "if 'Entropy' in most_important_feature:\n",
    "    print(f\"  \u2192 Attention diffuseness is the strongest signal for uncertainty\")\n",
    "elif 'Max attention' in most_important_feature:\n",
    "    print(f\"  \u2192 Attention focus (peakiness) is the strongest signal\")\n",
    "elif 'option' in most_important_feature:\n",
    "    print(f\"  \u2192 Where the model looks (which option) predicts correctness\")\n",
    "\n",
    "print(\"\\n3. MECHANISTIC INSIGHT:\")\n",
    "print(\"-\"*70)\n",
    "print(\"We provide the first direct comparison of attention vs hidden states\")\n",
    "print(\"for uncertainty quantification in LLMs.\")\n",
    "print(\"\\nThis answers a fundamental question about neural network interpretability:\")\n",
    "print(\"  'Where in the network is confidence encoded?'\")\n",
    "print(\"\\nPrior work assumed hidden states contain uncertainty (black box).\")\n",
    "print(\"We show attention patterns may be equally or more informative.\")\n",
    "\n",
    "print(\"\\n4. PRACTICAL IMPLICATIONS:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"\u2713 Attention features are low-dimensional ({attention_features.shape[1]} dims)\")\n",
    "print(f\"  vs hidden states ({X.shape[1]} dims) = {X.shape[1] / attention_features.shape[1]:.0f}x reduction\")\n",
    "print(f\"\\n\u2713 Attention probes are interpretable:\")\n",
    "print(f\"  - Can visualize which tokens model focuses on when uncertain\")\n",
    "print(f\"  - Features have semantic meaning (entropy, focus, spread)\")\n",
    "print(f\"\\n\u2713 Computationally efficient:\")\n",
    "print(f\"  - Attention already computed during forward pass\")\n",
    "print(f\"  - No additional model calls needed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NOVEL CONTRIBUTION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "We demonstrate that confidence can be predicted from attention patterns alone,\n",
    "providing a mechanistic understanding of WHERE uncertainty is encoded in LLMs.\n",
    "\n",
    "This is novel because:\n",
    "1. First direct comparison of attention vs hidden states for uncertainty\n",
    "2. Identifies specific attention features that matter (entropy, focus, spread)\n",
    "3. Provides interpretable, low-dimensional alternative to hidden-state probes\n",
    "4. Reveals whether confidence is about \"where model looks\" vs \"how it encodes\"\n",
    "\n",
    "Future work can leverage attention patterns for:\n",
    "- More interpretable uncertainty quantification\n",
    "- Identifying which tokens cause uncertainty\n",
    "- Debugging model failures through attention analysis\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22.7 Per-Head Analysis: Which Heads Encode Uncertainty?\n",
    "\n",
    "**Question**: Do all attention heads contribute equally, or are there specialized \"uncertainty heads\"?\n",
    "\n",
    "**Hypothesis**: A small number of heads encode most uncertainty information (sparse encoding).\n",
    "\n",
    "**Approach**: Train separate probes on each attention head, identify top performers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Per-Head Attention Analysis: Finding Uncertainty Heads\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "num_heads = attention_weights.shape[1]\n",
    "print(f\"Analyzing {num_heads} attention heads individually...\\n\")\n",
    "\n",
    "head_aurocs = []\n",
    "head_briers = []\n",
    "\n",
    "for head_idx in tqdm(range(num_heads), desc=\"Evaluating heads\"):\n",
    "    # Extract attention from this head only (last token)\n",
    "    head_attention = attention_weights[:, head_idx, -1, :]  # (num_examples, seq_len)\n",
    "    \n",
    "    # Compute simple features for this head\n",
    "    head_features = []\n",
    "    for i in range(len(head_attention)):\n",
    "        attn = head_attention[i]\n",
    "        \n",
    "        # Features:\n",
    "        # 1. Entropy\n",
    "        ent = entropy(attn + 1e-10)\n",
    "        # 2. Max attention\n",
    "        max_attn = attn.max()\n",
    "        # 3. Mean attention to last 25% of tokens (likely answer area)\n",
    "        last_quarter_attn = attn[-len(attn)//4:].mean()\n",
    "        \n",
    "        head_features.append([ent, max_attn, last_quarter_attn])\n",
    "    \n",
    "    head_features = np.array(head_features)\n",
    "    \n",
    "    # Split\n",
    "    X_head_train, X_head_temp, y_head_train, y_head_temp = train_test_split(\n",
    "        head_features, y, test_size=0.4, random_state=42, stratify=y\n",
    "    )\n",
    "    X_head_val, X_head_test, y_head_val, y_head_test = train_test_split(\n",
    "        X_head_temp, y_head_temp, test_size=0.5, random_state=42, stratify=y_head_temp\n",
    "    )\n",
    "    \n",
    "    # Train tiny probe\n",
    "    head_network = build_default_network(head_features.shape[1], hidden_dim=None)\n",
    "    head_probe = CalibratedProbe(network=head_network)\n",
    "    \n",
    "    head_probe.fit(\n",
    "        X_head_train, y_head_train,\n",
    "        X_head_val, y_head_val,\n",
    "        batch_size=32,\n",
    "        num_epochs=50,\n",
    "        patience=5,\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    head_conf = head_probe.predict(X_head_test)\n",
    "    head_auroc = roc_auc_score(y_head_test, head_conf)\n",
    "    head_brier = brier_score_loss(y_head_test, head_conf)\n",
    "    \n",
    "    head_aurocs.append(head_auroc)\n",
    "    head_briers.append(head_brier)\n",
    "\n",
    "head_aurocs = np.array(head_aurocs)\n",
    "head_briers = np.array(head_briers)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PER-HEAD RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Find top-3 heads\n",
    "top_3_indices = np.argsort(head_aurocs)[-3:][::-1]\n",
    "bottom_3_indices = np.argsort(head_aurocs)[:3]\n",
    "\n",
    "print(f\"\\nTop 3 'Uncertainty Heads':\")\n",
    "for rank, idx in enumerate(top_3_indices, 1):\n",
    "    print(f\"  {rank}. Head {idx}: AUROC={head_aurocs[idx]:.4f}, Brier={head_briers[idx]:.4f}\")\n",
    "\n",
    "print(f\"\\nBottom 3 heads:\")\n",
    "for idx in bottom_3_indices:\n",
    "    print(f\"  Head {idx}: AUROC={head_aurocs[idx]:.4f}, Brier={head_briers[idx]:.4f}\")\n",
    "\n",
    "print(f\"\\nStatistics across all heads:\")\n",
    "print(f\"  Mean AUROC: {head_aurocs.mean():.4f} \u00b1 {head_aurocs.std():.4f}\")\n",
    "print(f\"  Range: [{head_aurocs.min():.4f}, {head_aurocs.max():.4f}]\")\n",
    "print(f\"  All-heads average (Section 22): {attention_auroc:.4f}\")\n",
    "\n",
    "# Compare to full attention probe\n",
    "top_3_avg = head_aurocs[top_3_indices].mean()\n",
    "print(f\"\\nTop-3 heads average: {top_3_avg:.4f}\")\n",
    "print(f\"All heads (fusion):  {attention_auroc:.4f}\")\n",
    "print(f\"Performance retention: {top_3_avg / attention_auroc * 100:.1f}%\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# AUROC by head\n",
    "ax1 = axes[0]\n",
    "colors = ['gold' if i in top_3_indices else 'lightblue' for i in range(num_heads)]\n",
    "bars = ax1.bar(range(num_heads), head_aurocs, color=colors, edgecolor='black', linewidth=0.5)\n",
    "ax1.set_xlabel('Attention Head', fontsize=12)\n",
    "ax1.set_ylabel('AUROC', fontsize=12)\n",
    "ax1.set_title('Per-Head Uncertainty Detection Performance', fontsize=13, fontweight='bold')\n",
    "ax1.axhline(attention_auroc, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'All heads avg: {attention_auroc:.3f}')\n",
    "ax1.axhline(head_aurocs.mean(), color='gray', linestyle=':', linewidth=1.5,\n",
    "           label=f'Per-head mean: {head_aurocs.mean():.3f}')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Top-3 vs rest comparison\n",
    "ax2 = axes[1]\n",
    "top_3_aurocs = head_aurocs[top_3_indices]\n",
    "rest_aurocs = np.delete(head_aurocs, top_3_indices)\n",
    "\n",
    "data_to_plot = [top_3_aurocs, rest_aurocs]\n",
    "bp = ax2.boxplot(data_to_plot, labels=['Top 3 Heads', f'Other {num_heads-3} Heads'],\n",
    "                 patch_artist=True, widths=0.6)\n",
    "\n",
    "bp['boxes'][0].set_facecolor('gold')\n",
    "bp['boxes'][1].set_facecolor('lightblue')\n",
    "\n",
    "ax2.set_ylabel('AUROC', fontsize=12)\n",
    "ax2.set_title('Specialized Uncertainty Heads vs Others', fontsize=13, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('perhead_attention_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2713 Saved: perhead_attention_analysis.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "auroc_range = head_aurocs.max() - head_aurocs.min()\n",
    "if auroc_range > 0.1:\n",
    "    print(\"\\n\u2713 SPECIALIZED UNCERTAINTY HEADS FOUND!\")\n",
    "    print(f\"  AUROC range: {auroc_range:.4f} (max={head_aurocs.max():.3f}, min={head_aurocs.min():.3f})\")\n",
    "    print(f\"  Top heads: {top_3_indices.tolist()}\")\n",
    "    print(f\"\\n  \u2192 Not all heads contribute equally to uncertainty encoding\")\n",
    "    print(f\"  \u2192 Heads {top_3_indices.tolist()} are specialized for uncertainty\")\n",
    "    print(f\"  \u2192 Sparse encoding: {len(top_3_indices)} heads capture most signal\")\n",
    "    \n",
    "    if top_3_avg > attention_auroc * 0.9:\n",
    "        print(f\"\\n  PRACTICAL IMPLICATION:\")\n",
    "        print(f\"  \u2192 Can use only {len(top_3_indices)} heads instead of {num_heads}\")\n",
    "        print(f\"  \u2192 {len(top_3_indices)/num_heads*100:.0f}% of heads, {top_3_avg/attention_auroc*100:.0f}% of performance\")\n",
    "else:\n",
    "    print(\"\\n\u2248 DISTRIBUTED ENCODING\")\n",
    "    print(f\"  AUROC range: {auroc_range:.4f} (similar across heads)\")\n",
    "    print(f\"  \u2192 All heads contribute similarly to uncertainty\")\n",
    "    print(f\"  \u2192 Uncertainty is distributed, not specialized\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NOVEL CONTRIBUTION: Uncertainty Head Discovery\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "We identify which attention heads encode uncertainty information:\n",
    "\n",
    "- Systematic evaluation of all {num_heads} attention heads individually\n",
    "- Discovery of specialized 'uncertainty heads' with highest AUROC\n",
    "- Analysis of performance concentration vs distribution\n",
    "\n",
    "This reveals the internal organization of uncertainty in transformers:\n",
    "- If specialized \u2192 modular architecture, targetable for interventions\n",
    "- If distributed \u2192 global property, harder to isolate\n",
    "\n",
    "Future work can:\n",
    "- Visualize what uncertainty heads attend to\n",
    "- Test if uncertainty heads transfer across tasks\n",
    "- Design models with explicit uncertainty heads\n",
    "\"\"\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. Baseline Comparisons: Are Probes Actually Useful?\n",
    "\n",
    "**Critical Question**: Do our probes beat naive baselines, or would simple heuristics work just as well?\n",
    "\n",
    "**Baselines to test**:\n",
    "1. **Random predictions** - Random confidence scores (lower bound)\n",
    "2. **Constant baseline** - Always predict overall model accuracy\n",
    "3. **Sequence length heuristic** - Longer prompts \u2192 lower confidence\n",
    "4. **Token probability baseline** - If we can extract model's softmax confidence\n",
    "\n",
    "**Why this matters**: Without baselines, we can't claim our probes are useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline Comparisons: Testing Naive Approaches\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get our probe's performance for comparison\n",
    "probe_auroc = results['Linear']['auroc']\n",
    "probe_brier = results['Linear']['brier']\n",
    "probe_ece = results['Linear']['ece']\n",
    "\n",
    "baseline_results = {}\n",
    "\n",
    "# Baseline 1: Random predictions\n",
    "print(\"\\n1. Random Baseline...\")\n",
    "np.random.seed(42)\n",
    "random_conf = np.random.uniform(0, 1, size=len(y_test))\n",
    "random_auroc = roc_auc_score(y_test, random_conf)\n",
    "random_brier = brier_score_loss(y_test, random_conf)\n",
    "random_ece = compute_ece(random_conf, y_test)\n",
    "\n",
    "baseline_results['Random'] = {\n",
    "    'auroc': random_auroc,\n",
    "    'brier': random_brier,\n",
    "    'ece': random_ece,\n",
    "}\n",
    "\n",
    "print(f\"  AUROC: {random_auroc:.3f}\")\n",
    "print(f\"  Brier: {random_brier:.4f}\")\n",
    "print(f\"  ECE:   {random_ece:.4f}\")\n",
    "\n",
    "# Baseline 2: Constant (always predict model's overall accuracy)\n",
    "print(\"\\n2. Constant Baseline (predict overall accuracy)...\")\n",
    "overall_accuracy = y_test.mean()\n",
    "constant_conf = np.full(len(y_test), overall_accuracy)\n",
    "\n",
    "# AUROC undefined for constant predictions, use binary prediction\n",
    "# For Brier and ECE, constant is valid\n",
    "constant_brier = brier_score_loss(y_test, constant_conf)\n",
    "constant_ece = compute_ece(constant_conf, y_test)\n",
    "\n",
    "baseline_results['Constant'] = {\n",
    "    'auroc': np.nan,  # Can't compute AUROC for constant\n",
    "    'brier': constant_brier,\n",
    "    'ece': constant_ece,\n",
    "}\n",
    "\n",
    "print(f\"  Constant confidence: {overall_accuracy:.3f}\")\n",
    "print(f\"  AUROC: N/A (constant predictions)\")\n",
    "print(f\"  Brier: {constant_brier:.4f}\")\n",
    "print(f\"  ECE:   {constant_ece:.4f}\")\n",
    "\n",
    "# Baseline 3: Sequence length heuristic\n",
    "# Hypothesis: Longer prompts = harder questions = lower confidence\n",
    "print(\"\\n3. Sequence Length Heuristic...\")\n",
    "test_prompts = [prompts[i] for i in test_idx_final]\n",
    "seq_lengths = np.array([len(tokenizer.encode(p)) for p in test_prompts])\n",
    "\n",
    "# Normalize to [0, 1] range and invert (longer = less confident)\n",
    "min_len, max_len = seq_lengths.min(), seq_lengths.max()\n",
    "if max_len > min_len:\n",
    "    length_conf = 1.0 - (seq_lengths - min_len) / (max_len - min_len)\n",
    "else:\n",
    "    length_conf = np.full(len(seq_lengths), 0.5)\n",
    "\n",
    "length_auroc = roc_auc_score(y_test, length_conf)\n",
    "length_brier = brier_score_loss(y_test, length_conf)\n",
    "length_ece = compute_ece(length_conf, y_test)\n",
    "\n",
    "baseline_results['Seq Length'] = {\n",
    "    'auroc': length_auroc,\n",
    "    'brier': length_brier,\n",
    "    'ece': length_ece,\n",
    "}\n",
    "\n",
    "print(f\"  AUROC: {length_auroc:.3f}\")\n",
    "print(f\"  Brier: {length_brier:.4f}\")\n",
    "print(f\"  ECE:   {length_ece:.4f}\")\n",
    "\n",
    "# Baseline 4: Model's own confidence (if available)\n",
    "# We'll try to extract softmax probabilities from the model's output\n",
    "print(\"\\n4. Model's Softmax Confidence...\")\n",
    "print(\"  (Extracting model's own confidence from generation probabilities)\")\n",
    "\n",
    "try:\n",
    "    # Get model's confidence for test examples\n",
    "    model_confidences = []\n",
    "    \n",
    "    for i, prompt in enumerate(tqdm(test_prompts[:100], desc=\"Extracting softmax\")):\n",
    "        # Tokenize\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        # Get logits\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits[0, -1, :]  # Last token logits\n",
    "        \n",
    "        # Get probability of most likely token\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        max_prob = probs.max().item()\n",
    "        model_confidences.append(max_prob)\n",
    "    \n",
    "    model_confidences = np.array(model_confidences)\n",
    "    \n",
    "    # Evaluate on subset\n",
    "    y_subset = y_test[:100]\n",
    "    \n",
    "    softmax_auroc = roc_auc_score(y_subset, model_confidences)\n",
    "    softmax_brier = brier_score_loss(y_subset, model_confidences)\n",
    "    softmax_ece = compute_ece(model_confidences, y_subset)\n",
    "    \n",
    "    baseline_results['Softmax'] = {\n",
    "        'auroc': softmax_auroc,\n",
    "        'brier': softmax_brier,\n",
    "        'ece': softmax_ece,\n",
    "    }\n",
    "    \n",
    "    print(f\"  AUROC: {softmax_auroc:.3f}\")\n",
    "    print(f\"  Brier: {softmax_brier:.4f}\")\n",
    "    print(f\"  ECE:   {softmax_ece:.4f}\")\n",
    "    print(f\"  (Evaluated on {len(model_confidences)} examples due to computational cost)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  Could not extract softmax confidence: {e}\")\n",
    "    print(f\"  Skipping this baseline.\")\n",
    "\n",
    "# Comparison table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_data = {\n",
    "    'Linear Probe (Ours)': {\n",
    "        'auroc': probe_auroc,\n",
    "        'brier': probe_brier,\n",
    "        'ece': probe_ece,\n",
    "    },\n",
    "    **baseline_results\n",
    "}\n",
    "\n",
    "print(f\"\\n{'Method':<25} {'AUROC':<12} {'Brier':<12} {'ECE':<12}\")\n",
    "print(\"-\"*70)\n",
    "for name, metrics in comparison_data.items():\n",
    "    auroc_str = f\"{metrics['auroc']:.4f}\" if not np.isnan(metrics['auroc']) else \"N/A\"\n",
    "    print(f\"{name:<25} {auroc_str:<12} {metrics['brier']:<12.4f} {metrics['ece']:<12.4f}\")\n",
    "\n",
    "# Compute improvements\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IMPROVEMENT OVER BASELINES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nLinear Probe vs Random:\")\n",
    "print(f\"  AUROC improvement: {(probe_auroc - random_auroc) / random_auroc * 100:+.1f}%\")\n",
    "print(f\"  Brier improvement: {(random_brier - probe_brier) / random_brier * 100:+.1f}%\")\n",
    "\n",
    "print(f\"\\nLinear Probe vs Seq Length:\")\n",
    "print(f\"  AUROC improvement: {(probe_auroc - length_auroc) / length_auroc * 100:+.1f}%\")\n",
    "print(f\"  Brier improvement: {(length_brier - probe_brier) / length_brier * 100:+.1f}%\")\n",
    "\n",
    "if 'Softmax' in baseline_results:\n",
    "    print(f\"\\nLinear Probe vs Model Softmax:\")\n",
    "    print(f\"  AUROC improvement: {(probe_auroc - softmax_auroc) / softmax_auroc * 100:+.1f}%\")\n",
    "    print(f\"  Brier improvement: {(softmax_brier - probe_brier) / softmax_brier * 100:+.1f}%\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "methods = list(comparison_data.keys())\n",
    "aurocs = [comparison_data[m]['auroc'] for m in methods]\n",
    "briers = [comparison_data[m]['brier'] for m in methods]\n",
    "\n",
    "# AUROC comparison\n",
    "ax1 = axes[0]\n",
    "valid_aurocs = [(m, a) for m, a in zip(methods, aurocs) if not np.isnan(a)]\n",
    "valid_methods = [m for m, _ in valid_aurocs]\n",
    "valid_auroc_vals = [a for _, a in valid_aurocs]\n",
    "\n",
    "colors = ['green' if m == 'Linear Probe (Ours)' else 'lightblue' for m in valid_methods]\n",
    "bars = ax1.barh(valid_methods, valid_auroc_vals, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_xlabel('AUROC', fontsize=12)\n",
    "ax1.set_title('Discrimination: AUROC Comparison', fontsize=13, fontweight='bold')\n",
    "ax1.set_xlim([0.4, 1.0])\n",
    "ax1.axvline(0.5, color='red', linestyle='--', alpha=0.5, label='Random chance')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "for bar, val in zip(bars, valid_auroc_vals):\n",
    "    ax1.text(val + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "             f'{val:.3f}', va='center', fontweight='bold')\n",
    "\n",
    "# Brier comparison\n",
    "ax2 = axes[1]\n",
    "colors = ['green' if m == 'Linear Probe (Ours)' else 'lightcoral' for m in methods]\n",
    "bars = ax2.barh(methods, briers, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax2.set_xlabel('Brier Score (lower is better)', fontsize=12)\n",
    "ax2.set_title('Calibration: Brier Score Comparison', fontsize=13, fontweight='bold')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for bar, val in zip(bars, briers):\n",
    "    ax2.text(val + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "             f'{val:.4f}', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('baseline_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2713 Saved: baseline_comparison.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONCLUSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if probe_auroc > random_auroc + 0.2:\n",
    "    print(\"\u2713 Our probe significantly outperforms random baseline\")\n",
    "    print(f\"  ({(probe_auroc - random_auroc) / random_auroc * 100:.0f}% AUROC improvement)\")\n",
    "    print(\"  \u2192 Hidden states contain learnable uncertainty signals\")\n",
    "else:\n",
    "    print(\"\u2717 Probe barely beats random - uncertainty signals are weak\")\n",
    "\n",
    "if length_auroc > 0.55:\n",
    "    print(\"\\n\u26a0 Sequence length is a surprisingly strong predictor!\")\n",
    "    print(f\"  (AUROC: {length_auroc:.3f})\")\n",
    "    print(\"  \u2192 Longer questions tend to be harder (confounding factor)\")\n",
    "\n",
    "if 'Softmax' in baseline_results and softmax_auroc > 0.6:\n",
    "    if probe_auroc > softmax_auroc:\n",
    "        print(\"\\n\u2713 Probes outperform model's own softmax confidence!\")\n",
    "        print(\"  \u2192 Internal representations reveal uncertainty better than output logits\")\n",
    "    else:\n",
    "        print(\"\\n\u26a0 Model's softmax is competitive with probes\")\n",
    "        print(\"  \u2192 May not need probes, just use softmax probabilities\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24. Multimodal Fusion: Combining Attention + Hidden States\n",
    "\n",
    "**Critical Question**: Do attention patterns and hidden states encode **complementary** or **redundant** uncertainty signals?\n",
    "\n",
    "**Hypothesis**:\n",
    "- If **complementary**: Fusion should significantly outperform either modality alone\n",
    "- If **redundant**: Fusion should not improve much (both encode same information)\n",
    "\n",
    "**Approach**:\n",
    "1. Concatenate attention features (8 dims) + hidden states (4096 dims)\n",
    "2. Train probe on fused features\n",
    "3. Compare to unimodal probes\n",
    "\n",
    "**Novel Contribution**: First test of multimodal fusion for uncertainty quantification in LLMs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Multimodal Fusion: Attention + Hidden States\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Concatenate attention features + hidden states\n",
    "print(f\"\\nCombining features:\")\n",
    "print(f\"  Attention features: {attention_features.shape[1]} dims\")\n",
    "print(f\"  Hidden states:      {X.shape[1]} dims\")\n",
    "\n",
    "X_fusion = np.concatenate([attention_features, X], axis=1)\n",
    "print(f\"  Fused features:     {X_fusion.shape[1]} dims\")\n",
    "\n",
    "# Split fusion data (same splits as before)\n",
    "X_fusion_train, X_fusion_temp, y_fusion_train, y_fusion_temp = train_test_split(\n",
    "    X_fusion, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "X_fusion_val, X_fusion_test, y_fusion_val, y_fusion_test = train_test_split(\n",
    "    X_fusion_temp, y_fusion_temp, test_size=0.5, random_state=42, stratify=y_fusion_temp\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining fusion probe...\")\n",
    "\n",
    "# Train probe on fused features\n",
    "fusion_network = build_default_network(X_fusion.shape[1], hidden_dim=None)\n",
    "fusion_probe = CalibratedProbe(network=fusion_network)\n",
    "\n",
    "fusion_history = fusion_probe.fit(\n",
    "    X_fusion_train, y_fusion_train,\n",
    "    X_fusion_val, y_fusion_val,\n",
    "    batch_size=32,\n",
    "    num_epochs=100,\n",
    "    patience=10,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "fusion_conf = fusion_probe.predict(X_fusion_test)\n",
    "fusion_pred = (fusion_conf > 0.5).astype(int)\n",
    "\n",
    "fusion_acc = (fusion_pred == y_fusion_test).mean()\n",
    "fusion_auroc = roc_auc_score(y_fusion_test, fusion_conf)\n",
    "fusion_brier = brier_score_loss(y_fusion_test, fusion_conf)\n",
    "fusion_ece = compute_ece(fusion_conf, y_fusion_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FUSION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Accuracy:    {fusion_acc:.3f}\")\n",
    "print(f\"AUROC:       {fusion_auroc:.3f}\")\n",
    "print(f\"Brier Score: {fusion_brier:.4f}\")\n",
    "print(f\"ECE:         {fusion_ece:.4f}\")\n",
    "\n",
    "# Compare to unimodal\n",
    "hidden_auroc = results['Linear']['auroc']\n",
    "hidden_brier = results['Linear']['brier']\n",
    "hidden_ece = results['Linear']['ece']\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MULTIMODAL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Method':<25} {'AUROC':<12} {'Brier':<12} {'ECE':<12}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Hidden States Only':<25} {hidden_auroc:<12.4f} {hidden_brier:<12.4f} {hidden_ece:<12.4f}\")\n",
    "print(f\"{'Attention Only':<25} {attention_auroc:<12.4f} {attention_brier:<12.4f} {attention_ece:<12.4f}\")\n",
    "print(f\"{'Fusion (Both)':<25} {fusion_auroc:<12.4f} {fusion_brier:<12.4f} {fusion_ece:<12.4f}\")\n",
    "\n",
    "# Compute improvements\n",
    "best_unimodal_auroc = max(hidden_auroc, attention_auroc)\n",
    "auroc_gain = fusion_auroc - best_unimodal_auroc\n",
    "brier_gain = min(hidden_brier, attention_brier) - fusion_brier\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FUSION GAIN ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nImprovement over best unimodal:\")\n",
    "print(f\"  AUROC: {auroc_gain:+.4f} ({auroc_gain / best_unimodal_auroc * 100:+.1f}%)\")\n",
    "print(f\"  Brier: {brier_gain:+.4f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "methods = ['Hidden\\nStates', 'Attention', 'Fusion']\n",
    "aurocs_comp = [hidden_auroc, attention_auroc, fusion_auroc]\n",
    "briers_comp = [hidden_brier, attention_brier, fusion_brier]\n",
    "\n",
    "# AUROC comparison\n",
    "ax1 = axes[0]\n",
    "colors = ['lightblue', 'lightcoral', 'gold']\n",
    "bars = ax1.bar(methods, aurocs_comp, color=colors, edgecolor='black', linewidth=2, width=0.6)\n",
    "ax1.set_ylabel('AUROC', fontsize=12)\n",
    "ax1.set_title('Multimodal Fusion: Discrimination', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylim([0.7, max(aurocs_comp) * 1.1])\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, val in zip(bars, aurocs_comp):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "             f'{val:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "# Brier comparison\n",
    "ax2 = axes[1]\n",
    "bars = ax2.bar(methods, briers_comp, color=colors, edgecolor='black', linewidth=2, width=0.6)\n",
    "ax2.set_ylabel('Brier Score (lower is better)', fontsize=12)\n",
    "ax2.set_title('Multimodal Fusion: Calibration', fontsize=13, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, val in zip(bars, briers_comp):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.002,\n",
    "             f'{val:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('multimodal_fusion.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2713 Saved: multimodal_fusion.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if auroc_gain > 0.02:\n",
    "    print(\"\\n\u2713 COMPLEMENTARY SIGNALS CONFIRMED!\")\n",
    "    print(f\"  Fusion improves AUROC by {auroc_gain:.3f} ({auroc_gain / best_unimodal_auroc * 100:.1f}%)\")\n",
    "    print(f\"\\n  \u2192 Attention and hidden states encode DIFFERENT uncertainty information\")\n",
    "    print(f\"  \u2192 Optimal uncertainty estimation requires multimodal fusion\")\n",
    "    print(f\"  \u2192 Future methods should combine both modalities\")\n",
    "    print(f\"\\n  NOVEL FINDING: Uncertainty is distributed across modalities,\")\n",
    "    print(f\"  not concentrated in one representation type!\")\n",
    "elif auroc_gain < -0.01:\n",
    "    print(\"\\n\u26a0 FUSION HURTS PERFORMANCE!\")\n",
    "    print(f\"  Fusion decreases AUROC by {abs(auroc_gain):.3f}\")\n",
    "    print(f\"\\n  Possible reasons:\")\n",
    "    print(f\"  \u2192 Feature dimension mismatch (8 attention vs 4096 hidden)\")\n",
    "    print(f\"  \u2192 One modality introduces noise that hurts the other\")\n",
    "    print(f\"  \u2192 Need feature scaling or weighted fusion\")\n",
    "else:\n",
    "    print(\"\\n\u2248 REDUNDANT SIGNALS\")\n",
    "    print(f\"  Fusion gain: {auroc_gain:.4f} (minimal)\")\n",
    "    print(f\"\\n  \u2192 Attention and hidden states encode SIMILAR information\")\n",
    "    print(f\"  \u2192 Either modality alone is sufficient\")\n",
    "    print(f\"  \u2192 Uncertainty is globally encoded in the network\")\n",
    "    print(f\"\\n  IMPLICATION: Can use simpler attention-based probes\")\n",
    "    print(f\"  (8 features vs 4096) without losing performance!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}