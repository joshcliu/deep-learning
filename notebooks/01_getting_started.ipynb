{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with LLM Confidence Probing\n",
    "\n",
    "This notebook demonstrates the basic usage of the framework:\n",
    "1. Loading models with quantization\n",
    "2. Extracting hidden states\n",
    "3. Computing calibration metrics\n",
    "4. Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from src.models import ModelLoader, HiddenStateExtractor\n",
    "from src.evaluation import CalibrationMetrics, plot_reliability_diagram\n",
    "from src.utils import setup_logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging(log_level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model\n",
    "\n",
    "Load a model with 8-bit quantization to reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model loader\n",
    "loader = ModelLoader(\"meta-llama/Llama-3.1-8B\")\n",
    "\n",
    "# Get model info\n",
    "info = loader.get_model_info()\n",
    "print(f\"Model: {info['name']}\")\n",
    "print(f\"Layers: {info['num_layers']}\")\n",
    "print(f\"Hidden dim: {info['hidden_dim']}\")\n",
    "print(f\"Optimal layers: {info['optimal_layers']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "# Note: This requires GPU with at least 16GB VRAM\n",
    "model, tokenizer = loader.load(quantization=\"8bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Hidden States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample texts\n",
    "texts = [\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"The Earth orbits around the Moon.\",\n",
    "    \"Python is a programming language.\",\n",
    "    \"The sun rises in the west.\",\n",
    "    \"Water freezes at 0 degrees Celsius.\",\n",
    "]\n",
    "\n",
    "# Ground truth labels (1 = correct, 0 = incorrect)\n",
    "labels = np.array([1, 0, 1, 0, 1])\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = HiddenStateExtractor(model, tokenizer)\n",
    "\n",
    "# Extract hidden states from middle layer\n",
    "hiddens = extractor.extract(\n",
    "    texts=texts,\n",
    "    layers=[16],  # Middle layer\n",
    "    cache_dir=\"../cache/demo\",\n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "print(f\"Hidden states shape: {hiddens.shape}\")\n",
    "print(f\"(num_texts={hiddens.shape[0]}, num_layers={hiddens.shape[1]}, hidden_dim={hiddens.shape[2]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train a Simple Probe\n",
    "\n",
    "For this demo, we'll use scikit-learn's LogisticRegression as a simple linear probe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare data\n",
    "X = hiddens[:, 0, :]  # Use first (only) layer\n",
    "y = labels\n",
    "\n",
    "# Split (in practice, use more data)\n",
    "# For demo purposes with limited data, we'll just train on all\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(f\"Training accuracy: {clf.score(X, y):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Get Predictions and Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "predictions = clf.predict(X)\n",
    "confidences = clf.predict_proba(X)[:, 1]  # Probability of class 1\n",
    "\n",
    "# Display results\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"  Prediction: {predictions[i]} | Confidence: {confidences[i]:.3f} | True: {labels[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compute Calibration Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics\n",
    "metrics = CalibrationMetrics(predictions, confidences, labels)\n",
    "\n",
    "# Compute all metrics\n",
    "results = metrics.compute_all()\n",
    "\n",
    "print(\"Calibration Metrics:\")\n",
    "print(f\"  Accuracy: {results['accuracy']:.4f}\")\n",
    "print(f\"  ECE (Expected Calibration Error): {results['ece']:.4f}\")\n",
    "print(f\"  Brier Score: {results['brier']:.4f}\")\n",
    "print(f\"  AUROC: {results['auroc']:.4f}\")\n",
    "print(f\"  AUPR: {results['aupr']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reliability diagram\n",
    "fig = plot_reliability_diagram(\n",
    "    confidences,\n",
    "    labels,\n",
    "    num_bins=5,  # Use fewer bins for small dataset\n",
    "    save_path=\"../outputs/demo_reliability.png\",\n",
    "    show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Load larger datasets (MMLU, TriviaQA)\n",
    "- Train proper train/val/test splits\n",
    "- Experiment with different layers\n",
    "- Try different probe architectures\n",
    "- Apply post-hoc calibration (temperature scaling)\n",
    "- Analyze selective prediction performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
